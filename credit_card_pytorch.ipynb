{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3a95f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "#sklearn for preprocessing and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score\n",
    "#matplotlib and seaborn to graph\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7ca53f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "#check to make sure cuda working\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current device:\", torch.cuda.current_device())\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0bb202d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "#load in dataset\n",
    "df = pd.read_csv('creditcard_fraud_detection.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5285e33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b3790ef1-0d06-4535-9872-55e488e00301",
       "rows": [
        [
         "Time",
         "0"
        ],
        [
         "V1",
         "0"
        ],
        [
         "V2",
         "0"
        ],
        [
         "V3",
         "0"
        ],
        [
         "V4",
         "0"
        ],
        [
         "V5",
         "0"
        ],
        [
         "V6",
         "0"
        ],
        [
         "V7",
         "0"
        ],
        [
         "V8",
         "0"
        ],
        [
         "V9",
         "0"
        ],
        [
         "V10",
         "0"
        ],
        [
         "V11",
         "0"
        ],
        [
         "V12",
         "0"
        ],
        [
         "V13",
         "0"
        ],
        [
         "V14",
         "0"
        ],
        [
         "V15",
         "0"
        ],
        [
         "V16",
         "0"
        ],
        [
         "V17",
         "0"
        ],
        [
         "V18",
         "0"
        ],
        [
         "V19",
         "0"
        ],
        [
         "V20",
         "0"
        ],
        [
         "V21",
         "0"
        ],
        [
         "V22",
         "0"
        ],
        [
         "V23",
         "0"
        ],
        [
         "V24",
         "0"
        ],
        [
         "V25",
         "0"
        ],
        [
         "V26",
         "0"
        ],
        [
         "V27",
         "0"
        ],
        [
         "V28",
         "0"
        ],
        [
         "Amount",
         "0"
        ],
        [
         "Class",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 31
       }
      },
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check nas\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c4ad7e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001727485630620034\n"
     ]
    }
   ],
   "source": [
    "#calculate proportion of fraud in dataset\n",
    "print(sum(df['Class'])/len(df))\n",
    "#dataset is sparse, much more non fraud than fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bf658c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess and split for train test\n",
    "\n",
    "#take log of amount\n",
    "epsilon = 1e-7\n",
    "df['Log_Amount'] = np.log(df['Amount'] + epsilon)\n",
    "\n",
    "#X is everything but \"Class\", and untransformed amount and time columns\n",
    "X = df.drop(['Class', 'Amount', 'Time'], axis = 1).values\n",
    "#y is class (0 = no fraud, 1 = fraud)\n",
    "y= df['Class'].values\n",
    "\n",
    "scalar = StandardScaler()\n",
    "#PCA features are already scaled, but time and amount aren't\n",
    "X_scaled = scalar.fit_transform(X)\n",
    "\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size= 0.2, random_state= 50, \n",
    "    #stratify y since dataset is sparse and we want to ensureki\n",
    "    stratify= y\n",
    "    )\n",
    "\n",
    "#create validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "20e42ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrap dataset in classes for pytorch\n",
    "class CreditFraudDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        #convert np arrays to tensors\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    #return len dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    #return item of X, y at specific index\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 2048\n",
    "\n",
    "#wrap datasets\n",
    "train_dataset = CreditFraudDataset(X_train, y_train)\n",
    "val_dataset   = CreditFraudDataset(X_val, y_val)\n",
    "test_dataset  = CreditFraudDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b5375f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FraudNet(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=29, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "    (8): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (9): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.3, inplace=False)\n",
      "    (12): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#set up neural net\n",
    "class FraudNet(nn.Module):\n",
    "    def __init__(self, input_dim, dropout=0.3):  # dropout is now a hyperparameter\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "\n",
    "            #layer 1\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "\n",
    "            #layer 2\n",
    "            nn.Linear(64,64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            #layer 3\n",
    "            nn.Linear(64,32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            #only one output logit, for fraud or not\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x: (batch_size, input_dim)\n",
    "        logits = self.net(x).squeeze(1)  #(batch_size,)\n",
    "        return logits\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "#init a temporary model just to inspect the architecture\n",
    "tmp_model = FraudNet(input_dim)\n",
    "print(tmp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "25f6766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up device\n",
    "#todo: set up cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "90f1af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up bce for model\n",
    "#count number of each class\n",
    "class_counts = np.bincount(y_train)\n",
    "neg, pos = class_counts[0], class_counts[1]\n",
    "#set weights\n",
    "pos_weight = torch.tensor([neg / pos], dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "06ae0afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base fraud rate: 0.0017281485220215498\n",
      "Initial output bias (logit): -6.358975018556549\n"
     ]
    }
   ],
   "source": [
    "#bias initilization\n",
    "base_rate = pos / (neg + pos)\n",
    "\n",
    "epsilon = 1e-7\n",
    "base_rate = min(max(base_rate, epsilon), 1 - epsilon)\n",
    "bias_init = math.log(base_rate / (1.0 - base_rate))\n",
    "\n",
    "print(\"Base fraud rate:\", base_rate)\n",
    "print(\"Initial output bias (logit):\", bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "affbb494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function wrapper to initialize training loop with different hyperparameters\n",
    "def train_eval_one_config(lr, dropout, weight_decay=0.0):\n",
    "    #take hyperparameters as arguments, return best score and best model\n",
    "    \n",
    "    #initialize loaders here, batch size is a hyperparameter so use that\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    #set up model\n",
    "    model = FraudNet(input_dim, dropout=dropout).to(device)\n",
    "\n",
    "    #bias initialization\n",
    "    with torch.no_grad():\n",
    "        model.net[-1].bias.fill_(bias_init)\n",
    "\n",
    "    #set up bce for model\n",
    "    #use BCE to weight fraud more in the model. Model treats missed fraud transactions more harshly in loss function\n",
    "    #take learning rate and weight decay as arguments\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    best_val_pr_auc = -np.inf\n",
    "    best_state_dict = None\n",
    "\n",
    "    #set max epochs and patience\n",
    "    num_epochs = 100\n",
    "    \n",
    "    #early stopping made performance worse, removing it for now\n",
    "    patience   = 10           #stop if val PR-AUC doesn't improve for 5 epochs\n",
    "    epochs_no_improve = 0   #epochs without model improving pr auc\n",
    "\n",
    "    #run training loop for each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        #train\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X_batch)               #output scores as logits instead of probabilities for bce\n",
    "            loss = criterion(logits, y_batch)     #calc loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        #evaluate on validation set for each epoch\n",
    "        model.eval()\n",
    "        all_logits = []\n",
    "        all_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                logits = model(X_batch)\n",
    "                all_logits.append(logits.cpu())\n",
    "                all_targets.append(y_batch)\n",
    "\n",
    "        all_logits = torch.cat(all_logits)\n",
    "        all_targets = torch.cat(all_targets)\n",
    "\n",
    "        #converts logits to p\n",
    "        probs = torch.sigmoid(all_logits).numpy()\n",
    "        targets = all_targets.numpy()\n",
    "\n",
    "        #calculate roc auc score\n",
    "        #roc = roc_auc_score(targets, probs)\n",
    "        \n",
    "        #auc pr score (validation metric we care most about)\n",
    "        pr_auc = average_precision_score(targets, probs)\n",
    "\n",
    "        #track best validation PR-AUC for this config\n",
    "        if pr_auc > best_val_pr_auc:\n",
    "            best_val_pr_auc = pr_auc\n",
    "            best_state_dict = model.state_dict()\n",
    "            #if model is improvement, reset counter\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            #else increment counter\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            #if we hit patience threshold, break\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "        \n",
    "\n",
    "        #print output for epoch (optional, you can comment this out if it's too verbose)\n",
    "        print(f\"  Epoch {epoch+1:02d} | Loss: {epoch_loss:.4f} | Val PR-AUC: {pr_auc:.4f}\")\n",
    "\n",
    "    return best_val_pr_auc, best_state_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "66e4687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter \"ranges\" for random search\n",
    "#we'll *sample* from these instead of trying every combination\n",
    "def sample_hparams():\n",
    "    #learning rate: sample log-uniform between 1e-4 and 3e-3\n",
    "    log_lr_min = math.log10(1e-4)\n",
    "    log_lr_max = math.log10(3e-3)\n",
    "    log_lr = random.uniform(log_lr_min, log_lr_max)\n",
    "    lr = 10 ** log_lr\n",
    "\n",
    "    #dropout: uniform between 0.1 and 0.5\n",
    "    dropout = random.uniform(0.1, 0.6)\n",
    "\n",
    "    #weight decay: small set of options (including no weight decay)\n",
    "    weight_decay = random.choice([0.0, 1e-5, 1e-4])\n",
    "\n",
    "    return {\n",
    "        \"lr\": lr,\n",
    "        \"dropout\": dropout,\n",
    "        \"weight_decay\": weight_decay\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3956d284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Trial 1/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.002623\n",
      "  dropout     = 0.329\n",
      "  weight_decay= 0.0001\n",
      "  Epoch 01 | Loss: 1.1820 | Val PR-AUC: 0.6921\n",
      "  Epoch 02 | Loss: 0.5822 | Val PR-AUC: 0.6656\n",
      "  Epoch 03 | Loss: 0.4229 | Val PR-AUC: 0.6968\n",
      "  Epoch 04 | Loss: 0.3137 | Val PR-AUC: 0.7077\n",
      "  Epoch 05 | Loss: 0.2712 | Val PR-AUC: 0.7088\n",
      "  Epoch 06 | Loss: 0.2955 | Val PR-AUC: 0.7087\n",
      "  Epoch 07 | Loss: 0.2615 | Val PR-AUC: 0.7130\n",
      "  Epoch 08 | Loss: 0.2783 | Val PR-AUC: 0.7009\n",
      "  Epoch 09 | Loss: 0.2960 | Val PR-AUC: 0.7032\n",
      "  Epoch 10 | Loss: 0.2389 | Val PR-AUC: 0.7142\n",
      "  Epoch 11 | Loss: 0.2217 | Val PR-AUC: 0.7184\n",
      "  Epoch 12 | Loss: 0.2222 | Val PR-AUC: 0.7066\n",
      "  Epoch 13 | Loss: 0.2342 | Val PR-AUC: 0.6964\n",
      "  Epoch 14 | Loss: 0.2049 | Val PR-AUC: 0.7016\n",
      "  Epoch 15 | Loss: 0.2120 | Val PR-AUC: 0.7131\n",
      "  Epoch 16 | Loss: 0.1984 | Val PR-AUC: 0.7035\n",
      "  Epoch 17 | Loss: 0.2150 | Val PR-AUC: 0.6993\n",
      "  Epoch 18 | Loss: 0.2471 | Val PR-AUC: 0.7009\n",
      "  Epoch 19 | Loss: 0.1796 | Val PR-AUC: 0.7060\n",
      "  Epoch 20 | Loss: 0.2021 | Val PR-AUC: 0.7164\n",
      "Early stopping at epoch 21\n",
      "Best val PR-AUC for this trial: 0.7184\n",
      "\n",
      "=== Trial 2/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000406\n",
      "  dropout     = 0.155\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 2.2241 | Val PR-AUC: 0.6049\n",
      "  Epoch 02 | Loss: 0.9416 | Val PR-AUC: 0.6219\n",
      "  Epoch 03 | Loss: 0.7407 | Val PR-AUC: 0.6426\n",
      "  Epoch 04 | Loss: 0.6365 | Val PR-AUC: 0.6434\n",
      "  Epoch 05 | Loss: 0.5164 | Val PR-AUC: 0.6558\n",
      "  Epoch 06 | Loss: 0.4658 | Val PR-AUC: 0.6636\n",
      "  Epoch 07 | Loss: 0.3914 | Val PR-AUC: 0.6699\n",
      "  Epoch 08 | Loss: 0.3504 | Val PR-AUC: 0.6831\n",
      "  Epoch 09 | Loss: 0.3261 | Val PR-AUC: 0.6759\n",
      "  Epoch 10 | Loss: 0.2939 | Val PR-AUC: 0.6960\n",
      "  Epoch 11 | Loss: 0.2700 | Val PR-AUC: 0.6906\n",
      "  Epoch 12 | Loss: 0.2397 | Val PR-AUC: 0.7025\n",
      "  Epoch 13 | Loss: 0.2270 | Val PR-AUC: 0.7056\n",
      "  Epoch 14 | Loss: 0.2020 | Val PR-AUC: 0.6984\n",
      "  Epoch 15 | Loss: 0.2107 | Val PR-AUC: 0.6958\n",
      "  Epoch 16 | Loss: 0.1937 | Val PR-AUC: 0.7017\n",
      "  Epoch 17 | Loss: 0.1677 | Val PR-AUC: 0.6987\n",
      "  Epoch 18 | Loss: 0.1723 | Val PR-AUC: 0.6903\n",
      "  Epoch 19 | Loss: 0.1639 | Val PR-AUC: 0.6961\n",
      "  Epoch 20 | Loss: 0.1584 | Val PR-AUC: 0.6994\n",
      "  Epoch 21 | Loss: 0.1941 | Val PR-AUC: 0.6862\n",
      "  Epoch 22 | Loss: 0.1576 | Val PR-AUC: 0.6787\n",
      "Early stopping at epoch 23\n",
      "Best val PR-AUC for this trial: 0.7056\n",
      "\n",
      "=== Trial 3/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.001354\n",
      "  dropout     = 0.498\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 2.9993 | Val PR-AUC: 0.6642\n",
      "  Epoch 02 | Loss: 0.9739 | Val PR-AUC: 0.6935\n",
      "  Epoch 03 | Loss: 0.6542 | Val PR-AUC: 0.6971\n",
      "  Epoch 04 | Loss: 0.6001 | Val PR-AUC: 0.6863\n",
      "  Epoch 05 | Loss: 0.5181 | Val PR-AUC: 0.6844\n",
      "  Epoch 06 | Loss: 0.4570 | Val PR-AUC: 0.6970\n",
      "  Epoch 07 | Loss: 0.4516 | Val PR-AUC: 0.7094\n",
      "  Epoch 08 | Loss: 0.4069 | Val PR-AUC: 0.7088\n",
      "  Epoch 09 | Loss: 0.4416 | Val PR-AUC: 0.6991\n",
      "  Epoch 10 | Loss: 0.3835 | Val PR-AUC: 0.6939\n",
      "  Epoch 11 | Loss: 0.3372 | Val PR-AUC: 0.6913\n",
      "  Epoch 12 | Loss: 0.3626 | Val PR-AUC: 0.6925\n",
      "  Epoch 13 | Loss: 0.3612 | Val PR-AUC: 0.6970\n",
      "  Epoch 14 | Loss: 0.3765 | Val PR-AUC: 0.6952\n",
      "  Epoch 15 | Loss: 0.3809 | Val PR-AUC: 0.6941\n",
      "  Epoch 16 | Loss: 0.3050 | Val PR-AUC: 0.6979\n",
      "Early stopping at epoch 17\n",
      "Best val PR-AUC for this trial: 0.7094\n",
      "\n",
      "=== Trial 4/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000602\n",
      "  dropout     = 0.222\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 2.8192 | Val PR-AUC: 0.6435\n",
      "  Epoch 02 | Loss: 0.9663 | Val PR-AUC: 0.6579\n",
      "  Epoch 03 | Loss: 0.7560 | Val PR-AUC: 0.6496\n",
      "  Epoch 04 | Loss: 0.6365 | Val PR-AUC: 0.6562\n",
      "  Epoch 05 | Loss: 0.5322 | Val PR-AUC: 0.6254\n",
      "  Epoch 06 | Loss: 0.5071 | Val PR-AUC: 0.6388\n",
      "  Epoch 07 | Loss: 0.3940 | Val PR-AUC: 0.6429\n",
      "  Epoch 08 | Loss: 0.3809 | Val PR-AUC: 0.6283\n",
      "  Epoch 09 | Loss: 0.3026 | Val PR-AUC: 0.6876\n",
      "  Epoch 10 | Loss: 0.3206 | Val PR-AUC: 0.7025\n",
      "  Epoch 11 | Loss: 0.3307 | Val PR-AUC: 0.7013\n",
      "  Epoch 12 | Loss: 0.2969 | Val PR-AUC: 0.6868\n",
      "  Epoch 13 | Loss: 0.2396 | Val PR-AUC: 0.7109\n",
      "  Epoch 14 | Loss: 0.2071 | Val PR-AUC: 0.7168\n",
      "  Epoch 15 | Loss: 0.2243 | Val PR-AUC: 0.6992\n",
      "  Epoch 16 | Loss: 0.2171 | Val PR-AUC: 0.7012\n",
      "  Epoch 17 | Loss: 0.2026 | Val PR-AUC: 0.7089\n",
      "  Epoch 18 | Loss: 0.1954 | Val PR-AUC: 0.7006\n",
      "  Epoch 19 | Loss: 0.1853 | Val PR-AUC: 0.6904\n",
      "  Epoch 20 | Loss: 0.2188 | Val PR-AUC: 0.7010\n",
      "  Epoch 21 | Loss: 0.1851 | Val PR-AUC: 0.7091\n",
      "  Epoch 22 | Loss: 0.1572 | Val PR-AUC: 0.7131\n",
      "  Epoch 23 | Loss: 0.1968 | Val PR-AUC: 0.7004\n",
      "Early stopping at epoch 24\n",
      "Best val PR-AUC for this trial: 0.7168\n",
      "\n",
      "=== Trial 5/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000110\n",
      "  dropout     = 0.555\n",
      "  weight_decay= 0.0001\n",
      "  Epoch 01 | Loss: 6.4931 | Val PR-AUC: 0.4173\n",
      "  Epoch 02 | Loss: 5.4506 | Val PR-AUC: 0.5544\n",
      "  Epoch 03 | Loss: 4.1242 | Val PR-AUC: 0.5986\n",
      "  Epoch 04 | Loss: 3.3878 | Val PR-AUC: 0.6116\n",
      "  Epoch 05 | Loss: 2.8140 | Val PR-AUC: 0.6225\n",
      "  Epoch 06 | Loss: 2.2925 | Val PR-AUC: 0.6362\n",
      "  Epoch 07 | Loss: 2.1054 | Val PR-AUC: 0.6449\n",
      "  Epoch 08 | Loss: 1.6949 | Val PR-AUC: 0.6001\n",
      "  Epoch 09 | Loss: 1.6256 | Val PR-AUC: 0.6094\n",
      "  Epoch 10 | Loss: 1.5191 | Val PR-AUC: 0.6182\n",
      "  Epoch 11 | Loss: 1.4223 | Val PR-AUC: 0.6264\n",
      "  Epoch 12 | Loss: 1.4278 | Val PR-AUC: 0.6342\n",
      "  Epoch 13 | Loss: 1.4346 | Val PR-AUC: 0.6322\n",
      "  Epoch 14 | Loss: 1.2679 | Val PR-AUC: 0.6281\n",
      "  Epoch 15 | Loss: 1.2690 | Val PR-AUC: 0.6350\n",
      "  Epoch 16 | Loss: 1.1538 | Val PR-AUC: 0.6358\n",
      "Early stopping at epoch 17\n",
      "Best val PR-AUC for this trial: 0.6449\n",
      "\n",
      "=== Trial 6/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000173\n",
      "  dropout     = 0.294\n",
      "  weight_decay= 0.0001\n",
      "  Epoch 01 | Loss: 3.5189 | Val PR-AUC: 0.5401\n",
      "  Epoch 02 | Loss: 1.6952 | Val PR-AUC: 0.5802\n",
      "  Epoch 03 | Loss: 1.1582 | Val PR-AUC: 0.5915\n",
      "  Epoch 04 | Loss: 0.9961 | Val PR-AUC: 0.6134\n",
      "  Epoch 05 | Loss: 0.9296 | Val PR-AUC: 0.6273\n",
      "  Epoch 06 | Loss: 0.7619 | Val PR-AUC: 0.6274\n",
      "  Epoch 07 | Loss: 0.7497 | Val PR-AUC: 0.5979\n",
      "  Epoch 08 | Loss: 0.6686 | Val PR-AUC: 0.6035\n",
      "  Epoch 09 | Loss: 0.6503 | Val PR-AUC: 0.6117\n",
      "  Epoch 10 | Loss: 0.5761 | Val PR-AUC: 0.6096\n",
      "  Epoch 11 | Loss: 0.5468 | Val PR-AUC: 0.6242\n",
      "  Epoch 12 | Loss: 0.5488 | Val PR-AUC: 0.6370\n",
      "  Epoch 13 | Loss: 0.5361 | Val PR-AUC: 0.6288\n",
      "  Epoch 14 | Loss: 0.4904 | Val PR-AUC: 0.6392\n",
      "  Epoch 15 | Loss: 0.5083 | Val PR-AUC: 0.6323\n",
      "  Epoch 16 | Loss: 0.4331 | Val PR-AUC: 0.6642\n",
      "  Epoch 17 | Loss: 0.4424 | Val PR-AUC: 0.6344\n",
      "  Epoch 18 | Loss: 0.4037 | Val PR-AUC: 0.6662\n",
      "  Epoch 19 | Loss: 0.3924 | Val PR-AUC: 0.6770\n",
      "  Epoch 20 | Loss: 0.3447 | Val PR-AUC: 0.6749\n",
      "  Epoch 21 | Loss: 0.3757 | Val PR-AUC: 0.6793\n",
      "  Epoch 22 | Loss: 0.3761 | Val PR-AUC: 0.6829\n",
      "  Epoch 23 | Loss: 0.3808 | Val PR-AUC: 0.6881\n",
      "  Epoch 24 | Loss: 0.3600 | Val PR-AUC: 0.6631\n",
      "  Epoch 25 | Loss: 0.3777 | Val PR-AUC: 0.6827\n",
      "  Epoch 26 | Loss: 0.2820 | Val PR-AUC: 0.6898\n",
      "  Epoch 27 | Loss: 0.3383 | Val PR-AUC: 0.6967\n",
      "  Epoch 28 | Loss: 0.3212 | Val PR-AUC: 0.7035\n",
      "  Epoch 29 | Loss: 0.3277 | Val PR-AUC: 0.7051\n",
      "  Epoch 30 | Loss: 0.3399 | Val PR-AUC: 0.7066\n",
      "  Epoch 31 | Loss: 0.3012 | Val PR-AUC: 0.7063\n",
      "  Epoch 32 | Loss: 0.2687 | Val PR-AUC: 0.7083\n",
      "  Epoch 33 | Loss: 0.2738 | Val PR-AUC: 0.7095\n",
      "  Epoch 34 | Loss: 0.2906 | Val PR-AUC: 0.7072\n",
      "  Epoch 35 | Loss: 0.2849 | Val PR-AUC: 0.7109\n",
      "  Epoch 36 | Loss: 0.2618 | Val PR-AUC: 0.7017\n",
      "  Epoch 37 | Loss: 0.2758 | Val PR-AUC: 0.7081\n",
      "  Epoch 38 | Loss: 0.2477 | Val PR-AUC: 0.6961\n",
      "  Epoch 39 | Loss: 0.2562 | Val PR-AUC: 0.6942\n",
      "  Epoch 40 | Loss: 0.2381 | Val PR-AUC: 0.7071\n",
      "  Epoch 41 | Loss: 0.2637 | Val PR-AUC: 0.7077\n",
      "  Epoch 42 | Loss: 0.2396 | Val PR-AUC: 0.7055\n",
      "  Epoch 43 | Loss: 0.2432 | Val PR-AUC: 0.7022\n",
      "  Epoch 44 | Loss: 0.2353 | Val PR-AUC: 0.7056\n",
      "Early stopping at epoch 45\n",
      "Best val PR-AUC for this trial: 0.7109\n",
      "\n",
      "=== Trial 7/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000571\n",
      "  dropout     = 0.464\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 4.7170 | Val PR-AUC: 0.6294\n",
      "  Epoch 02 | Loss: 1.6954 | Val PR-AUC: 0.6557\n",
      "  Epoch 03 | Loss: 1.1165 | Val PR-AUC: 0.6634\n",
      "  Epoch 04 | Loss: 0.9884 | Val PR-AUC: 0.6780\n",
      "  Epoch 05 | Loss: 0.7267 | Val PR-AUC: 0.6890\n",
      "  Epoch 06 | Loss: 0.6349 | Val PR-AUC: 0.6857\n",
      "  Epoch 07 | Loss: 0.6283 | Val PR-AUC: 0.6856\n",
      "  Epoch 08 | Loss: 0.5758 | Val PR-AUC: 0.6921\n",
      "  Epoch 09 | Loss: 0.5349 | Val PR-AUC: 0.6947\n",
      "  Epoch 10 | Loss: 0.4984 | Val PR-AUC: 0.6653\n",
      "  Epoch 11 | Loss: 0.4650 | Val PR-AUC: 0.6706\n",
      "  Epoch 12 | Loss: 0.5005 | Val PR-AUC: 0.6659\n",
      "  Epoch 13 | Loss: 0.4418 | Val PR-AUC: 0.6845\n",
      "  Epoch 14 | Loss: 0.4165 | Val PR-AUC: 0.6851\n",
      "  Epoch 15 | Loss: 0.3902 | Val PR-AUC: 0.7050\n",
      "  Epoch 16 | Loss: 0.4323 | Val PR-AUC: 0.6743\n",
      "  Epoch 17 | Loss: 0.3522 | Val PR-AUC: 0.7069\n",
      "  Epoch 18 | Loss: 0.3287 | Val PR-AUC: 0.7159\n",
      "  Epoch 19 | Loss: 0.3863 | Val PR-AUC: 0.7218\n",
      "  Epoch 20 | Loss: 0.3320 | Val PR-AUC: 0.7191\n",
      "  Epoch 21 | Loss: 0.3417 | Val PR-AUC: 0.7212\n",
      "  Epoch 22 | Loss: 0.3429 | Val PR-AUC: 0.7169\n",
      "  Epoch 23 | Loss: 0.2928 | Val PR-AUC: 0.7147\n",
      "  Epoch 24 | Loss: 0.2870 | Val PR-AUC: 0.7255\n",
      "  Epoch 25 | Loss: 0.2985 | Val PR-AUC: 0.7260\n",
      "  Epoch 26 | Loss: 0.3527 | Val PR-AUC: 0.7254\n",
      "  Epoch 27 | Loss: 0.3376 | Val PR-AUC: 0.7241\n",
      "  Epoch 28 | Loss: 0.3466 | Val PR-AUC: 0.7236\n",
      "  Epoch 29 | Loss: 0.2880 | Val PR-AUC: 0.7206\n",
      "  Epoch 30 | Loss: 0.2791 | Val PR-AUC: 0.7216\n",
      "  Epoch 31 | Loss: 0.3061 | Val PR-AUC: 0.7277\n",
      "  Epoch 32 | Loss: 0.2885 | Val PR-AUC: 0.7260\n",
      "  Epoch 33 | Loss: 0.2793 | Val PR-AUC: 0.7256\n",
      "  Epoch 34 | Loss: 0.2519 | Val PR-AUC: 0.7209\n",
      "  Epoch 35 | Loss: 0.2668 | Val PR-AUC: 0.7262\n",
      "  Epoch 36 | Loss: 0.2693 | Val PR-AUC: 0.7261\n",
      "  Epoch 37 | Loss: 0.2677 | Val PR-AUC: 0.7215\n",
      "  Epoch 38 | Loss: 0.2496 | Val PR-AUC: 0.7195\n",
      "  Epoch 39 | Loss: 0.2349 | Val PR-AUC: 0.7214\n",
      "  Epoch 40 | Loss: 0.2675 | Val PR-AUC: 0.7213\n",
      "Early stopping at epoch 41\n",
      "Best val PR-AUC for this trial: 0.7277\n",
      "\n",
      "=== Trial 8/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000539\n",
      "  dropout     = 0.580\n",
      "  weight_decay= 0.0001\n",
      "  Epoch 01 | Loss: 3.6104 | Val PR-AUC: 0.5804\n",
      "  Epoch 02 | Loss: 1.7050 | Val PR-AUC: 0.5842\n",
      "  Epoch 03 | Loss: 1.2251 | Val PR-AUC: 0.6424\n",
      "  Epoch 04 | Loss: 0.9680 | Val PR-AUC: 0.6624\n",
      "  Epoch 05 | Loss: 0.9104 | Val PR-AUC: 0.6577\n",
      "  Epoch 06 | Loss: 0.8123 | Val PR-AUC: 0.6804\n",
      "  Epoch 07 | Loss: 0.8066 | Val PR-AUC: 0.6776\n",
      "  Epoch 08 | Loss: 0.6210 | Val PR-AUC: 0.6755\n",
      "  Epoch 09 | Loss: 0.6689 | Val PR-AUC: 0.6527\n",
      "  Epoch 10 | Loss: 0.5984 | Val PR-AUC: 0.6598\n",
      "  Epoch 11 | Loss: 0.5538 | Val PR-AUC: 0.6665\n",
      "  Epoch 12 | Loss: 0.5649 | Val PR-AUC: 0.6731\n",
      "  Epoch 13 | Loss: 0.5148 | Val PR-AUC: 0.6862\n",
      "  Epoch 14 | Loss: 0.5091 | Val PR-AUC: 0.6981\n",
      "  Epoch 15 | Loss: 0.5629 | Val PR-AUC: 0.6831\n",
      "  Epoch 16 | Loss: 0.5260 | Val PR-AUC: 0.6983\n",
      "  Epoch 17 | Loss: 0.4944 | Val PR-AUC: 0.6984\n",
      "  Epoch 18 | Loss: 0.4575 | Val PR-AUC: 0.7068\n",
      "  Epoch 19 | Loss: 0.4101 | Val PR-AUC: 0.7031\n",
      "  Epoch 20 | Loss: 0.5076 | Val PR-AUC: 0.7155\n",
      "  Epoch 21 | Loss: 0.4426 | Val PR-AUC: 0.7106\n",
      "  Epoch 22 | Loss: 0.4999 | Val PR-AUC: 0.7182\n",
      "  Epoch 23 | Loss: 0.4419 | Val PR-AUC: 0.7112\n",
      "  Epoch 24 | Loss: 0.4153 | Val PR-AUC: 0.7110\n",
      "  Epoch 25 | Loss: 0.4376 | Val PR-AUC: 0.7135\n",
      "  Epoch 26 | Loss: 0.4740 | Val PR-AUC: 0.7177\n",
      "  Epoch 27 | Loss: 0.3675 | Val PR-AUC: 0.7196\n",
      "  Epoch 28 | Loss: 0.4392 | Val PR-AUC: 0.7160\n",
      "  Epoch 29 | Loss: 0.4020 | Val PR-AUC: 0.7182\n",
      "  Epoch 30 | Loss: 0.4568 | Val PR-AUC: 0.7177\n",
      "  Epoch 31 | Loss: 0.3813 | Val PR-AUC: 0.7169\n",
      "  Epoch 32 | Loss: 0.3283 | Val PR-AUC: 0.7177\n",
      "  Epoch 33 | Loss: 0.3341 | Val PR-AUC: 0.7122\n",
      "  Epoch 34 | Loss: 0.3870 | Val PR-AUC: 0.7176\n",
      "  Epoch 35 | Loss: 0.3508 | Val PR-AUC: 0.7090\n",
      "  Epoch 36 | Loss: 0.3490 | Val PR-AUC: 0.7099\n",
      "Early stopping at epoch 37\n",
      "Best val PR-AUC for this trial: 0.7196\n",
      "\n",
      "=== Trial 9/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000161\n",
      "  dropout     = 0.408\n",
      "  weight_decay= 1e-05\n",
      "  Epoch 01 | Loss: 4.6408 | Val PR-AUC: 0.5083\n",
      "  Epoch 02 | Loss: 2.7897 | Val PR-AUC: 0.6174\n",
      "  Epoch 03 | Loss: 1.9830 | Val PR-AUC: 0.5943\n",
      "  Epoch 04 | Loss: 1.4389 | Val PR-AUC: 0.6237\n",
      "  Epoch 05 | Loss: 1.3296 | Val PR-AUC: 0.6406\n",
      "  Epoch 06 | Loss: 1.0848 | Val PR-AUC: 0.6444\n",
      "  Epoch 07 | Loss: 0.9686 | Val PR-AUC: 0.6609\n",
      "  Epoch 08 | Loss: 0.9558 | Val PR-AUC: 0.6703\n",
      "  Epoch 09 | Loss: 0.8823 | Val PR-AUC: 0.6725\n",
      "  Epoch 10 | Loss: 0.8779 | Val PR-AUC: 0.6797\n",
      "  Epoch 11 | Loss: 0.7461 | Val PR-AUC: 0.6810\n",
      "  Epoch 12 | Loss: 0.7296 | Val PR-AUC: 0.6837\n",
      "  Epoch 13 | Loss: 0.7249 | Val PR-AUC: 0.6819\n",
      "  Epoch 14 | Loss: 0.7073 | Val PR-AUC: 0.6884\n",
      "  Epoch 15 | Loss: 0.6772 | Val PR-AUC: 0.6849\n",
      "  Epoch 16 | Loss: 0.6403 | Val PR-AUC: 0.6879\n",
      "  Epoch 17 | Loss: 0.6242 | Val PR-AUC: 0.6910\n",
      "  Epoch 18 | Loss: 0.5903 | Val PR-AUC: 0.6910\n",
      "  Epoch 19 | Loss: 0.5834 | Val PR-AUC: 0.6900\n",
      "  Epoch 20 | Loss: 0.5396 | Val PR-AUC: 0.6828\n",
      "  Epoch 21 | Loss: 0.5325 | Val PR-AUC: 0.6735\n",
      "  Epoch 22 | Loss: 0.5142 | Val PR-AUC: 0.6650\n",
      "  Epoch 23 | Loss: 0.5134 | Val PR-AUC: 0.6768\n",
      "  Epoch 24 | Loss: 0.4852 | Val PR-AUC: 0.5776\n",
      "  Epoch 25 | Loss: 0.4752 | Val PR-AUC: 0.6851\n",
      "  Epoch 26 | Loss: 0.4675 | Val PR-AUC: 0.6791\n",
      "  Epoch 27 | Loss: 0.5097 | Val PR-AUC: 0.6753\n",
      "Early stopping at epoch 28\n",
      "Best val PR-AUC for this trial: 0.6910\n",
      "\n",
      "=== Trial 10/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.001831\n",
      "  dropout     = 0.475\n",
      "  weight_decay= 0.0001\n",
      "  Epoch 01 | Loss: 2.7939 | Val PR-AUC: 0.6894\n",
      "  Epoch 02 | Loss: 0.8457 | Val PR-AUC: 0.7019\n",
      "  Epoch 03 | Loss: 0.6000 | Val PR-AUC: 0.6923\n",
      "  Epoch 04 | Loss: 0.5545 | Val PR-AUC: 0.6979\n",
      "  Epoch 05 | Loss: 0.4870 | Val PR-AUC: 0.7038\n",
      "  Epoch 06 | Loss: 0.4327 | Val PR-AUC: 0.7060\n",
      "  Epoch 07 | Loss: 0.3810 | Val PR-AUC: 0.6977\n",
      "  Epoch 08 | Loss: 0.3714 | Val PR-AUC: 0.7128\n",
      "  Epoch 09 | Loss: 0.3928 | Val PR-AUC: 0.7111\n",
      "  Epoch 10 | Loss: 0.3732 | Val PR-AUC: 0.7080\n",
      "  Epoch 11 | Loss: 0.3213 | Val PR-AUC: 0.7090\n",
      "  Epoch 12 | Loss: 0.3870 | Val PR-AUC: 0.7016\n",
      "  Epoch 13 | Loss: 0.2987 | Val PR-AUC: 0.7174\n",
      "  Epoch 14 | Loss: 0.3482 | Val PR-AUC: 0.7123\n",
      "  Epoch 15 | Loss: 0.3208 | Val PR-AUC: 0.7079\n",
      "  Epoch 16 | Loss: 0.2795 | Val PR-AUC: 0.7180\n",
      "  Epoch 17 | Loss: 0.2895 | Val PR-AUC: 0.7086\n",
      "  Epoch 18 | Loss: 0.2793 | Val PR-AUC: 0.7167\n",
      "  Epoch 19 | Loss: 0.2730 | Val PR-AUC: 0.7236\n",
      "  Epoch 20 | Loss: 0.2893 | Val PR-AUC: 0.7072\n",
      "  Epoch 21 | Loss: 0.2681 | Val PR-AUC: 0.7198\n",
      "  Epoch 22 | Loss: 0.2748 | Val PR-AUC: 0.7243\n",
      "  Epoch 23 | Loss: 0.2685 | Val PR-AUC: 0.7240\n",
      "  Epoch 24 | Loss: 0.2198 | Val PR-AUC: 0.7329\n",
      "  Epoch 25 | Loss: 0.2272 | Val PR-AUC: 0.7130\n",
      "  Epoch 26 | Loss: 0.2222 | Val PR-AUC: 0.7216\n",
      "  Epoch 27 | Loss: 0.2386 | Val PR-AUC: 0.7202\n",
      "  Epoch 28 | Loss: 0.2564 | Val PR-AUC: 0.7160\n",
      "  Epoch 29 | Loss: 0.2117 | Val PR-AUC: 0.7080\n",
      "  Epoch 30 | Loss: 0.2378 | Val PR-AUC: 0.7062\n",
      "  Epoch 31 | Loss: 0.2451 | Val PR-AUC: 0.7022\n",
      "  Epoch 32 | Loss: 0.2302 | Val PR-AUC: 0.7074\n",
      "  Epoch 33 | Loss: 0.2543 | Val PR-AUC: 0.7030\n",
      "Early stopping at epoch 34\n",
      "Best val PR-AUC for this trial: 0.7329\n",
      "\n",
      "=== Trial 11/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000104\n",
      "  dropout     = 0.253\n",
      "  weight_decay= 0.0001\n",
      "  Epoch 01 | Loss: 5.3443 | Val PR-AUC: 0.4412\n",
      "  Epoch 02 | Loss: 3.5559 | Val PR-AUC: 0.5488\n",
      "  Epoch 03 | Loss: 2.2690 | Val PR-AUC: 0.6019\n",
      "  Epoch 04 | Loss: 1.6269 | Val PR-AUC: 0.6249\n",
      "  Epoch 05 | Loss: 1.3691 | Val PR-AUC: 0.5969\n",
      "  Epoch 06 | Loss: 1.2021 | Val PR-AUC: 0.6095\n",
      "  Epoch 07 | Loss: 1.0296 | Val PR-AUC: 0.5973\n",
      "  Epoch 08 | Loss: 0.9443 | Val PR-AUC: 0.6289\n",
      "  Epoch 09 | Loss: 0.8677 | Val PR-AUC: 0.6286\n",
      "  Epoch 10 | Loss: 0.8388 | Val PR-AUC: 0.6237\n",
      "  Epoch 11 | Loss: 0.8043 | Val PR-AUC: 0.6300\n",
      "  Epoch 12 | Loss: 0.7125 | Val PR-AUC: 0.6286\n",
      "  Epoch 13 | Loss: 0.6733 | Val PR-AUC: 0.6243\n",
      "  Epoch 14 | Loss: 0.6700 | Val PR-AUC: 0.6371\n",
      "  Epoch 15 | Loss: 0.6533 | Val PR-AUC: 0.6214\n",
      "  Epoch 16 | Loss: 0.6005 | Val PR-AUC: 0.6083\n",
      "  Epoch 17 | Loss: 0.5934 | Val PR-AUC: 0.6124\n",
      "  Epoch 18 | Loss: 0.6091 | Val PR-AUC: 0.6141\n",
      "  Epoch 19 | Loss: 0.5619 | Val PR-AUC: 0.6227\n",
      "  Epoch 20 | Loss: 0.5388 | Val PR-AUC: 0.6197\n",
      "  Epoch 21 | Loss: 0.5472 | Val PR-AUC: 0.6226\n",
      "  Epoch 22 | Loss: 0.5311 | Val PR-AUC: 0.6185\n",
      "  Epoch 23 | Loss: 0.5070 | Val PR-AUC: 0.6084\n",
      "Early stopping at epoch 24\n",
      "Best val PR-AUC for this trial: 0.6371\n",
      "\n",
      "=== Trial 12/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.001771\n",
      "  dropout     = 0.403\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 2.0534 | Val PR-AUC: 0.6880\n",
      "  Epoch 02 | Loss: 0.7163 | Val PR-AUC: 0.6810\n",
      "  Epoch 03 | Loss: 0.5465 | Val PR-AUC: 0.6770\n",
      "  Epoch 04 | Loss: 0.4705 | Val PR-AUC: 0.6980\n",
      "  Epoch 05 | Loss: 0.4324 | Val PR-AUC: 0.7051\n",
      "  Epoch 06 | Loss: 0.3653 | Val PR-AUC: 0.7162\n",
      "  Epoch 07 | Loss: 0.3610 | Val PR-AUC: 0.6930\n",
      "  Epoch 08 | Loss: 0.3302 | Val PR-AUC: 0.7042\n",
      "  Epoch 09 | Loss: 0.3054 | Val PR-AUC: 0.7075\n",
      "  Epoch 10 | Loss: 0.3306 | Val PR-AUC: 0.7016\n",
      "  Epoch 11 | Loss: 0.2519 | Val PR-AUC: 0.7071\n",
      "  Epoch 12 | Loss: 0.3055 | Val PR-AUC: 0.7116\n",
      "  Epoch 13 | Loss: 0.2677 | Val PR-AUC: 0.7139\n",
      "  Epoch 14 | Loss: 0.2793 | Val PR-AUC: 0.7186\n",
      "  Epoch 15 | Loss: 0.2667 | Val PR-AUC: 0.7099\n",
      "  Epoch 16 | Loss: 0.2262 | Val PR-AUC: 0.7080\n",
      "  Epoch 17 | Loss: 0.2447 | Val PR-AUC: 0.7170\n",
      "  Epoch 18 | Loss: 0.2446 | Val PR-AUC: 0.7022\n",
      "  Epoch 19 | Loss: 0.2297 | Val PR-AUC: 0.7118\n",
      "  Epoch 20 | Loss: 0.2408 | Val PR-AUC: 0.7110\n",
      "  Epoch 21 | Loss: 0.2573 | Val PR-AUC: 0.7106\n",
      "  Epoch 22 | Loss: 0.2363 | Val PR-AUC: 0.7128\n",
      "  Epoch 23 | Loss: 0.2305 | Val PR-AUC: 0.7154\n",
      "Early stopping at epoch 24\n",
      "Best val PR-AUC for this trial: 0.7186\n",
      "\n",
      "=== Trial 13/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000646\n",
      "  dropout     = 0.564\n",
      "  weight_decay= 1e-05\n",
      "  Epoch 01 | Loss: 4.0768 | Val PR-AUC: 0.6546\n",
      "  Epoch 02 | Loss: 1.5173 | Val PR-AUC: 0.6460\n",
      "  Epoch 03 | Loss: 1.1165 | Val PR-AUC: 0.6717\n",
      "  Epoch 04 | Loss: 0.8287 | Val PR-AUC: 0.6805\n",
      "  Epoch 05 | Loss: 0.7850 | Val PR-AUC: 0.6822\n",
      "  Epoch 06 | Loss: 0.7479 | Val PR-AUC: 0.6979\n",
      "  Epoch 07 | Loss: 0.6256 | Val PR-AUC: 0.6934\n",
      "  Epoch 08 | Loss: 0.6329 | Val PR-AUC: 0.6924\n",
      "  Epoch 09 | Loss: 0.5167 | Val PR-AUC: 0.6893\n",
      "  Epoch 10 | Loss: 0.5746 | Val PR-AUC: 0.6944\n",
      "  Epoch 11 | Loss: 0.4951 | Val PR-AUC: 0.6982\n",
      "  Epoch 12 | Loss: 0.4846 | Val PR-AUC: 0.7002\n",
      "  Epoch 13 | Loss: 0.4703 | Val PR-AUC: 0.7041\n",
      "  Epoch 14 | Loss: 0.4666 | Val PR-AUC: 0.7081\n",
      "  Epoch 15 | Loss: 0.4941 | Val PR-AUC: 0.7125\n",
      "  Epoch 16 | Loss: 0.4885 | Val PR-AUC: 0.7092\n",
      "  Epoch 17 | Loss: 0.4658 | Val PR-AUC: 0.7112\n",
      "  Epoch 18 | Loss: 0.4602 | Val PR-AUC: 0.7129\n",
      "  Epoch 19 | Loss: 0.4137 | Val PR-AUC: 0.7138\n",
      "  Epoch 20 | Loss: 0.4748 | Val PR-AUC: 0.7142\n",
      "  Epoch 21 | Loss: 0.4158 | Val PR-AUC: 0.7146\n",
      "  Epoch 22 | Loss: 0.3751 | Val PR-AUC: 0.7116\n",
      "  Epoch 23 | Loss: 0.3832 | Val PR-AUC: 0.7004\n",
      "  Epoch 24 | Loss: 0.4226 | Val PR-AUC: 0.7120\n",
      "  Epoch 25 | Loss: 0.3987 | Val PR-AUC: 0.7175\n",
      "  Epoch 26 | Loss: 0.4022 | Val PR-AUC: 0.7036\n",
      "  Epoch 27 | Loss: 0.3599 | Val PR-AUC: 0.7089\n",
      "  Epoch 28 | Loss: 0.4398 | Val PR-AUC: 0.7052\n",
      "  Epoch 29 | Loss: 0.3309 | Val PR-AUC: 0.7092\n",
      "  Epoch 30 | Loss: 0.3851 | Val PR-AUC: 0.7047\n",
      "  Epoch 31 | Loss: 0.3208 | Val PR-AUC: 0.7119\n",
      "  Epoch 32 | Loss: 0.3573 | Val PR-AUC: 0.7068\n",
      "  Epoch 33 | Loss: 0.3178 | Val PR-AUC: 0.7144\n",
      "  Epoch 34 | Loss: 0.3520 | Val PR-AUC: 0.7098\n",
      "Early stopping at epoch 35\n",
      "Best val PR-AUC for this trial: 0.7175\n",
      "\n",
      "=== Trial 14/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.002091\n",
      "  dropout     = 0.333\n",
      "  weight_decay= 0.0001\n",
      "  Epoch 01 | Loss: 1.5445 | Val PR-AUC: 0.6563\n",
      "  Epoch 02 | Loss: 0.5585 | Val PR-AUC: 0.6748\n",
      "  Epoch 03 | Loss: 0.4602 | Val PR-AUC: 0.7053\n",
      "  Epoch 04 | Loss: 0.3831 | Val PR-AUC: 0.6942\n",
      "  Epoch 05 | Loss: 0.3356 | Val PR-AUC: 0.7182\n",
      "  Epoch 06 | Loss: 0.2931 | Val PR-AUC: 0.7127\n",
      "  Epoch 07 | Loss: 0.2533 | Val PR-AUC: 0.7156\n",
      "  Epoch 08 | Loss: 0.2733 | Val PR-AUC: 0.7068\n",
      "  Epoch 09 | Loss: 0.2578 | Val PR-AUC: 0.7118\n",
      "  Epoch 10 | Loss: 0.2302 | Val PR-AUC: 0.7044\n",
      "  Epoch 11 | Loss: 0.2294 | Val PR-AUC: 0.7056\n",
      "  Epoch 12 | Loss: 0.2082 | Val PR-AUC: 0.7165\n",
      "  Epoch 13 | Loss: 0.2118 | Val PR-AUC: 0.6998\n",
      "  Epoch 14 | Loss: 0.2210 | Val PR-AUC: 0.6960\n",
      "Early stopping at epoch 15\n",
      "Best val PR-AUC for this trial: 0.7182\n",
      "\n",
      "=== Trial 15/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.001611\n",
      "  dropout     = 0.336\n",
      "  weight_decay= 1e-05\n",
      "  Epoch 01 | Loss: 1.4063 | Val PR-AUC: 0.6964\n",
      "  Epoch 02 | Loss: 0.5885 | Val PR-AUC: 0.6565\n",
      "  Epoch 03 | Loss: 0.4698 | Val PR-AUC: 0.6935\n",
      "  Epoch 04 | Loss: 0.3897 | Val PR-AUC: 0.6983\n",
      "  Epoch 05 | Loss: 0.3485 | Val PR-AUC: 0.7094\n",
      "  Epoch 06 | Loss: 0.2868 | Val PR-AUC: 0.7105\n",
      "  Epoch 07 | Loss: 0.3184 | Val PR-AUC: 0.7112\n",
      "  Epoch 08 | Loss: 0.2713 | Val PR-AUC: 0.7109\n",
      "  Epoch 09 | Loss: 0.2666 | Val PR-AUC: 0.7104\n",
      "  Epoch 10 | Loss: 0.2511 | Val PR-AUC: 0.7187\n",
      "  Epoch 11 | Loss: 0.2249 | Val PR-AUC: 0.7107\n",
      "  Epoch 12 | Loss: 0.2298 | Val PR-AUC: 0.7163\n",
      "  Epoch 13 | Loss: 0.2010 | Val PR-AUC: 0.7178\n",
      "  Epoch 14 | Loss: 0.2341 | Val PR-AUC: 0.7216\n",
      "  Epoch 15 | Loss: 0.2017 | Val PR-AUC: 0.7158\n",
      "  Epoch 16 | Loss: 0.2115 | Val PR-AUC: 0.7183\n",
      "  Epoch 17 | Loss: 0.2122 | Val PR-AUC: 0.7141\n",
      "  Epoch 18 | Loss: 0.1754 | Val PR-AUC: 0.7097\n",
      "  Epoch 19 | Loss: 0.1888 | Val PR-AUC: 0.7099\n",
      "  Epoch 20 | Loss: 0.1853 | Val PR-AUC: 0.7083\n",
      "  Epoch 21 | Loss: 0.1821 | Val PR-AUC: 0.7046\n",
      "  Epoch 22 | Loss: 0.1711 | Val PR-AUC: 0.7179\n",
      "  Epoch 23 | Loss: 0.1988 | Val PR-AUC: 0.7181\n",
      "Early stopping at epoch 24\n",
      "Best val PR-AUC for this trial: 0.7216\n",
      "\n",
      "=== Trial 16/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000136\n",
      "  dropout     = 0.253\n",
      "  weight_decay= 0.0001\n",
      "  Epoch 01 | Loss: 4.3784 | Val PR-AUC: 0.6073\n",
      "  Epoch 02 | Loss: 2.4422 | Val PR-AUC: 0.6471\n",
      "  Epoch 03 | Loss: 1.7879 | Val PR-AUC: 0.6642\n",
      "  Epoch 04 | Loss: 1.3423 | Val PR-AUC: 0.6187\n",
      "  Epoch 05 | Loss: 1.1373 | Val PR-AUC: 0.6230\n",
      "  Epoch 06 | Loss: 0.9399 | Val PR-AUC: 0.6382\n",
      "  Epoch 07 | Loss: 0.9556 | Val PR-AUC: 0.6482\n",
      "  Epoch 08 | Loss: 0.7793 | Val PR-AUC: 0.6565\n",
      "  Epoch 09 | Loss: 0.7356 | Val PR-AUC: 0.6543\n",
      "  Epoch 10 | Loss: 0.7217 | Val PR-AUC: 0.6569\n",
      "  Epoch 11 | Loss: 0.6641 | Val PR-AUC: 0.6614\n",
      "  Epoch 12 | Loss: 0.5950 | Val PR-AUC: 0.6638\n",
      "  Epoch 13 | Loss: 0.6271 | Val PR-AUC: 0.6658\n",
      "  Epoch 14 | Loss: 0.5471 | Val PR-AUC: 0.6694\n",
      "  Epoch 15 | Loss: 0.5705 | Val PR-AUC: 0.6609\n",
      "  Epoch 16 | Loss: 0.5161 | Val PR-AUC: 0.6679\n",
      "  Epoch 17 | Loss: 0.5687 | Val PR-AUC: 0.6779\n",
      "  Epoch 18 | Loss: 0.4992 | Val PR-AUC: 0.6651\n",
      "  Epoch 19 | Loss: 0.4783 | Val PR-AUC: 0.6697\n",
      "  Epoch 20 | Loss: 0.4642 | Val PR-AUC: 0.6392\n",
      "  Epoch 21 | Loss: 0.4641 | Val PR-AUC: 0.6766\n",
      "  Epoch 22 | Loss: 0.4141 | Val PR-AUC: 0.6789\n",
      "  Epoch 23 | Loss: 0.3966 | Val PR-AUC: 0.6815\n",
      "  Epoch 24 | Loss: 0.4013 | Val PR-AUC: 0.6851\n",
      "  Epoch 25 | Loss: 0.3815 | Val PR-AUC: 0.6738\n",
      "  Epoch 26 | Loss: 0.3874 | Val PR-AUC: 0.6860\n",
      "  Epoch 27 | Loss: 0.3417 | Val PR-AUC: 0.6987\n",
      "  Epoch 28 | Loss: 0.3035 | Val PR-AUC: 0.6997\n",
      "  Epoch 29 | Loss: 0.3417 | Val PR-AUC: 0.6905\n",
      "  Epoch 30 | Loss: 0.3716 | Val PR-AUC: 0.7012\n",
      "  Epoch 31 | Loss: 0.3307 | Val PR-AUC: 0.7043\n",
      "  Epoch 32 | Loss: 0.3211 | Val PR-AUC: 0.7017\n",
      "  Epoch 33 | Loss: 0.2956 | Val PR-AUC: 0.7129\n",
      "  Epoch 34 | Loss: 0.2902 | Val PR-AUC: 0.7143\n",
      "  Epoch 35 | Loss: 0.2691 | Val PR-AUC: 0.7153\n",
      "  Epoch 36 | Loss: 0.2567 | Val PR-AUC: 0.7142\n",
      "  Epoch 37 | Loss: 0.2371 | Val PR-AUC: 0.7188\n",
      "  Epoch 38 | Loss: 0.3034 | Val PR-AUC: 0.7216\n",
      "  Epoch 39 | Loss: 0.2312 | Val PR-AUC: 0.7148\n",
      "  Epoch 40 | Loss: 0.2686 | Val PR-AUC: 0.7219\n",
      "  Epoch 41 | Loss: 0.2581 | Val PR-AUC: 0.7183\n",
      "  Epoch 42 | Loss: 0.2387 | Val PR-AUC: 0.7160\n",
      "  Epoch 43 | Loss: 0.2427 | Val PR-AUC: 0.7184\n",
      "  Epoch 44 | Loss: 0.2595 | Val PR-AUC: 0.7227\n",
      "  Epoch 45 | Loss: 0.2765 | Val PR-AUC: 0.7196\n",
      "  Epoch 46 | Loss: 0.2478 | Val PR-AUC: 0.7204\n",
      "  Epoch 47 | Loss: 0.2159 | Val PR-AUC: 0.7082\n",
      "  Epoch 48 | Loss: 0.2382 | Val PR-AUC: 0.7145\n",
      "  Epoch 49 | Loss: 0.2491 | Val PR-AUC: 0.7167\n",
      "  Epoch 50 | Loss: 0.2160 | Val PR-AUC: 0.7188\n",
      "  Epoch 51 | Loss: 0.2239 | Val PR-AUC: 0.7232\n",
      "  Epoch 52 | Loss: 0.2221 | Val PR-AUC: 0.7188\n",
      "  Epoch 53 | Loss: 0.2237 | Val PR-AUC: 0.7001\n",
      "  Epoch 54 | Loss: 0.2218 | Val PR-AUC: 0.7149\n",
      "  Epoch 55 | Loss: 0.2166 | Val PR-AUC: 0.7142\n",
      "  Epoch 56 | Loss: 0.2095 | Val PR-AUC: 0.7022\n",
      "  Epoch 57 | Loss: 0.2028 | Val PR-AUC: 0.7032\n",
      "  Epoch 58 | Loss: 0.2289 | Val PR-AUC: 0.7152\n",
      "  Epoch 59 | Loss: 0.2340 | Val PR-AUC: 0.7140\n",
      "  Epoch 60 | Loss: 0.2219 | Val PR-AUC: 0.7160\n",
      "Early stopping at epoch 61\n",
      "Best val PR-AUC for this trial: 0.7232\n",
      "\n",
      "=== Trial 17/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.001208\n",
      "  dropout     = 0.598\n",
      "  weight_decay= 1e-05\n",
      "  Epoch 01 | Loss: 3.8854 | Val PR-AUC: 0.6092\n",
      "  Epoch 02 | Loss: 1.3361 | Val PR-AUC: 0.6816\n",
      "  Epoch 03 | Loss: 0.8486 | Val PR-AUC: 0.6956\n",
      "  Epoch 04 | Loss: 0.8415 | Val PR-AUC: 0.6943\n",
      "  Epoch 05 | Loss: 0.6342 | Val PR-AUC: 0.7005\n",
      "  Epoch 06 | Loss: 0.5908 | Val PR-AUC: 0.7032\n",
      "  Epoch 07 | Loss: 0.5490 | Val PR-AUC: 0.7075\n",
      "  Epoch 08 | Loss: 0.5284 | Val PR-AUC: 0.7004\n",
      "  Epoch 09 | Loss: 0.4852 | Val PR-AUC: 0.7037\n",
      "  Epoch 10 | Loss: 0.5295 | Val PR-AUC: 0.7094\n",
      "  Epoch 11 | Loss: 0.5107 | Val PR-AUC: 0.7139\n",
      "  Epoch 12 | Loss: 0.5639 | Val PR-AUC: 0.7144\n",
      "  Epoch 13 | Loss: 0.4563 | Val PR-AUC: 0.7041\n",
      "  Epoch 14 | Loss: 0.4840 | Val PR-AUC: 0.7104\n",
      "  Epoch 15 | Loss: 0.4057 | Val PR-AUC: 0.7038\n",
      "  Epoch 16 | Loss: 0.4746 | Val PR-AUC: 0.7045\n",
      "  Epoch 17 | Loss: 0.4412 | Val PR-AUC: 0.7176\n",
      "  Epoch 18 | Loss: 0.4633 | Val PR-AUC: 0.7174\n",
      "  Epoch 19 | Loss: 0.3423 | Val PR-AUC: 0.7096\n",
      "  Epoch 20 | Loss: 0.3881 | Val PR-AUC: 0.7079\n",
      "  Epoch 21 | Loss: 0.3638 | Val PR-AUC: 0.7075\n",
      "  Epoch 22 | Loss: 0.3279 | Val PR-AUC: 0.7121\n",
      "  Epoch 23 | Loss: 0.3801 | Val PR-AUC: 0.7073\n",
      "  Epoch 24 | Loss: 0.3079 | Val PR-AUC: 0.7130\n",
      "  Epoch 25 | Loss: 0.3855 | Val PR-AUC: 0.6868\n",
      "  Epoch 26 | Loss: 0.3149 | Val PR-AUC: 0.7163\n",
      "Early stopping at epoch 27\n",
      "Best val PR-AUC for this trial: 0.7176\n",
      "\n",
      "=== Trial 18/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000384\n",
      "  dropout     = 0.106\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 3.0497 | Val PR-AUC: 0.5985\n",
      "  Epoch 02 | Loss: 1.0997 | Val PR-AUC: 0.6321\n",
      "  Epoch 03 | Loss: 0.7960 | Val PR-AUC: 0.6345\n",
      "  Epoch 04 | Loss: 0.6523 | Val PR-AUC: 0.6136\n",
      "  Epoch 05 | Loss: 0.5489 | Val PR-AUC: 0.6206\n",
      "  Epoch 06 | Loss: 0.4950 | Val PR-AUC: 0.6168\n",
      "  Epoch 07 | Loss: 0.4431 | Val PR-AUC: 0.6257\n",
      "  Epoch 08 | Loss: 0.3672 | Val PR-AUC: 0.6279\n",
      "  Epoch 09 | Loss: 0.3575 | Val PR-AUC: 0.6602\n",
      "  Epoch 10 | Loss: 0.2890 | Val PR-AUC: 0.6841\n",
      "  Epoch 11 | Loss: 0.2896 | Val PR-AUC: 0.6883\n",
      "  Epoch 12 | Loss: 0.2285 | Val PR-AUC: 0.6654\n",
      "  Epoch 13 | Loss: 0.2090 | Val PR-AUC: 0.6944\n",
      "  Epoch 14 | Loss: 0.2018 | Val PR-AUC: 0.6893\n",
      "  Epoch 15 | Loss: 0.1813 | Val PR-AUC: 0.6893\n",
      "  Epoch 16 | Loss: 0.1979 | Val PR-AUC: 0.7081\n",
      "  Epoch 17 | Loss: 0.1677 | Val PR-AUC: 0.6997\n",
      "  Epoch 18 | Loss: 0.1388 | Val PR-AUC: 0.7019\n",
      "  Epoch 19 | Loss: 0.1425 | Val PR-AUC: 0.6983\n",
      "  Epoch 20 | Loss: 0.1354 | Val PR-AUC: 0.6922\n",
      "  Epoch 21 | Loss: 0.1351 | Val PR-AUC: 0.6748\n",
      "  Epoch 22 | Loss: 0.1554 | Val PR-AUC: 0.6833\n",
      "  Epoch 23 | Loss: 0.1461 | Val PR-AUC: 0.7007\n",
      "  Epoch 24 | Loss: 0.1369 | Val PR-AUC: 0.6985\n",
      "  Epoch 25 | Loss: 0.1301 | Val PR-AUC: 0.6757\n",
      "Early stopping at epoch 26\n",
      "Best val PR-AUC for this trial: 0.7081\n",
      "\n",
      "=== Trial 19/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000368\n",
      "  dropout     = 0.482\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 5.9380 | Val PR-AUC: 0.4978\n",
      "  Epoch 02 | Loss: 2.7512 | Val PR-AUC: 0.5914\n",
      "  Epoch 03 | Loss: 1.6149 | Val PR-AUC: 0.6201\n",
      "  Epoch 04 | Loss: 1.1955 | Val PR-AUC: 0.6468\n",
      "  Epoch 05 | Loss: 1.0197 | Val PR-AUC: 0.6546\n",
      "  Epoch 06 | Loss: 0.8425 | Val PR-AUC: 0.6544\n",
      "  Epoch 07 | Loss: 0.7784 | Val PR-AUC: 0.6496\n",
      "  Epoch 08 | Loss: 0.6730 | Val PR-AUC: 0.6689\n",
      "  Epoch 09 | Loss: 0.7250 | Val PR-AUC: 0.6584\n",
      "  Epoch 10 | Loss: 0.6925 | Val PR-AUC: 0.6675\n",
      "  Epoch 11 | Loss: 0.6113 | Val PR-AUC: 0.6665\n",
      "  Epoch 12 | Loss: 0.6046 | Val PR-AUC: 0.6669\n",
      "  Epoch 13 | Loss: 0.5665 | Val PR-AUC: 0.6663\n",
      "  Epoch 14 | Loss: 0.5423 | Val PR-AUC: 0.6699\n",
      "  Epoch 15 | Loss: 0.5355 | Val PR-AUC: 0.6780\n",
      "  Epoch 16 | Loss: 0.5200 | Val PR-AUC: 0.6685\n",
      "  Epoch 17 | Loss: 0.4622 | Val PR-AUC: 0.6802\n",
      "  Epoch 18 | Loss: 0.4908 | Val PR-AUC: 0.6234\n",
      "  Epoch 19 | Loss: 0.4129 | Val PR-AUC: 0.6524\n",
      "  Epoch 20 | Loss: 0.4869 | Val PR-AUC: 0.6877\n",
      "  Epoch 21 | Loss: 0.4815 | Val PR-AUC: 0.6921\n",
      "  Epoch 22 | Loss: 0.3872 | Val PR-AUC: 0.6744\n",
      "  Epoch 23 | Loss: 0.4277 | Val PR-AUC: 0.6901\n",
      "  Epoch 24 | Loss: 0.4322 | Val PR-AUC: 0.6926\n",
      "  Epoch 25 | Loss: 0.3968 | Val PR-AUC: 0.7003\n",
      "  Epoch 26 | Loss: 0.3557 | Val PR-AUC: 0.7018\n",
      "  Epoch 27 | Loss: 0.3750 | Val PR-AUC: 0.7136\n",
      "  Epoch 28 | Loss: 0.4536 | Val PR-AUC: 0.7102\n",
      "  Epoch 29 | Loss: 0.3728 | Val PR-AUC: 0.7079\n",
      "  Epoch 30 | Loss: 0.3751 | Val PR-AUC: 0.7059\n",
      "  Epoch 31 | Loss: 0.3695 | Val PR-AUC: 0.7139\n",
      "  Epoch 32 | Loss: 0.3680 | Val PR-AUC: 0.7098\n",
      "  Epoch 33 | Loss: 0.3525 | Val PR-AUC: 0.7084\n",
      "  Epoch 34 | Loss: 0.3504 | Val PR-AUC: 0.7178\n",
      "  Epoch 35 | Loss: 0.3117 | Val PR-AUC: 0.7138\n",
      "  Epoch 36 | Loss: 0.3579 | Val PR-AUC: 0.7111\n",
      "  Epoch 37 | Loss: 0.3067 | Val PR-AUC: 0.7134\n",
      "  Epoch 38 | Loss: 0.3093 | Val PR-AUC: 0.7136\n",
      "  Epoch 39 | Loss: 0.3598 | Val PR-AUC: 0.7115\n",
      "  Epoch 40 | Loss: 0.3665 | Val PR-AUC: 0.7157\n",
      "  Epoch 41 | Loss: 0.3478 | Val PR-AUC: 0.7132\n",
      "  Epoch 42 | Loss: 0.3014 | Val PR-AUC: 0.7164\n",
      "  Epoch 43 | Loss: 0.3125 | Val PR-AUC: 0.7145\n",
      "Early stopping at epoch 44\n",
      "Best val PR-AUC for this trial: 0.7178\n",
      "\n",
      "=== Trial 20/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000577\n",
      "  dropout     = 0.187\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 2.1734 | Val PR-AUC: 0.6357\n",
      "  Epoch 02 | Loss: 0.8316 | Val PR-AUC: 0.6498\n",
      "  Epoch 03 | Loss: 0.6532 | Val PR-AUC: 0.6453\n",
      "  Epoch 04 | Loss: 0.5357 | Val PR-AUC: 0.6126\n",
      "  Epoch 05 | Loss: 0.4656 | Val PR-AUC: 0.6542\n",
      "  Epoch 06 | Loss: 0.3679 | Val PR-AUC: 0.6761\n",
      "  Epoch 07 | Loss: 0.3591 | Val PR-AUC: 0.6325\n",
      "  Epoch 08 | Loss: 0.2744 | Val PR-AUC: 0.6820\n",
      "  Epoch 09 | Loss: 0.2544 | Val PR-AUC: 0.6947\n",
      "  Epoch 10 | Loss: 0.2660 | Val PR-AUC: 0.6955\n",
      "  Epoch 11 | Loss: 0.2675 | Val PR-AUC: 0.6974\n",
      "  Epoch 12 | Loss: 0.2144 | Val PR-AUC: 0.7034\n",
      "  Epoch 13 | Loss: 0.2098 | Val PR-AUC: 0.7026\n",
      "  Epoch 14 | Loss: 0.1888 | Val PR-AUC: 0.6988\n",
      "  Epoch 15 | Loss: 0.2043 | Val PR-AUC: 0.7007\n",
      "  Epoch 16 | Loss: 0.1888 | Val PR-AUC: 0.6877\n",
      "  Epoch 17 | Loss: 0.1710 | Val PR-AUC: 0.6987\n",
      "  Epoch 18 | Loss: 0.1726 | Val PR-AUC: 0.7027\n",
      "  Epoch 19 | Loss: 0.1745 | Val PR-AUC: 0.6995\n",
      "  Epoch 20 | Loss: 0.1557 | Val PR-AUC: 0.6994\n",
      "  Epoch 21 | Loss: 0.1605 | Val PR-AUC: 0.6934\n",
      "Early stopping at epoch 22\n",
      "Best val PR-AUC for this trial: 0.7034\n",
      "\n",
      "=== Trial 21/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000147\n",
      "  dropout     = 0.572\n",
      "  weight_decay= 0.0001\n",
      "  Epoch 01 | Loss: 4.0948 | Val PR-AUC: 0.4314\n",
      "  Epoch 02 | Loss: 3.1539 | Val PR-AUC: 0.5115\n",
      "  Epoch 03 | Loss: 2.5582 | Val PR-AUC: 0.5738\n",
      "  Epoch 04 | Loss: 1.9829 | Val PR-AUC: 0.6039\n",
      "  Epoch 05 | Loss: 1.7969 | Val PR-AUC: 0.5742\n",
      "  Epoch 06 | Loss: 1.5806 | Val PR-AUC: 0.5812\n",
      "  Epoch 07 | Loss: 1.3608 | Val PR-AUC: 0.5999\n",
      "  Epoch 08 | Loss: 1.3646 | Val PR-AUC: 0.5976\n",
      "  Epoch 09 | Loss: 1.1768 | Val PR-AUC: 0.6276\n",
      "  Epoch 10 | Loss: 1.0784 | Val PR-AUC: 0.6301\n",
      "  Epoch 11 | Loss: 0.9866 | Val PR-AUC: 0.6432\n",
      "  Epoch 12 | Loss: 0.9902 | Val PR-AUC: 0.6585\n",
      "  Epoch 13 | Loss: 0.9052 | Val PR-AUC: 0.6594\n",
      "  Epoch 14 | Loss: 0.8956 | Val PR-AUC: 0.6684\n",
      "  Epoch 15 | Loss: 0.8884 | Val PR-AUC: 0.6750\n",
      "  Epoch 16 | Loss: 0.8330 | Val PR-AUC: 0.6753\n",
      "  Epoch 17 | Loss: 0.7808 | Val PR-AUC: 0.6840\n",
      "  Epoch 18 | Loss: 0.7616 | Val PR-AUC: 0.6811\n",
      "  Epoch 19 | Loss: 0.7534 | Val PR-AUC: 0.6813\n",
      "  Epoch 20 | Loss: 0.6586 | Val PR-AUC: 0.6843\n",
      "  Epoch 21 | Loss: 0.6629 | Val PR-AUC: 0.6834\n",
      "  Epoch 22 | Loss: 0.6885 | Val PR-AUC: 0.6811\n",
      "  Epoch 23 | Loss: 0.6271 | Val PR-AUC: 0.6827\n",
      "  Epoch 24 | Loss: 0.6930 | Val PR-AUC: 0.6794\n",
      "  Epoch 25 | Loss: 0.6138 | Val PR-AUC: 0.6855\n",
      "  Epoch 26 | Loss: 0.6413 | Val PR-AUC: 0.6888\n",
      "  Epoch 27 | Loss: 0.6171 | Val PR-AUC: 0.6891\n",
      "  Epoch 28 | Loss: 0.5760 | Val PR-AUC: 0.6905\n",
      "  Epoch 29 | Loss: 0.5927 | Val PR-AUC: 0.6913\n",
      "  Epoch 30 | Loss: 0.6521 | Val PR-AUC: 0.6855\n",
      "  Epoch 31 | Loss: 0.5836 | Val PR-AUC: 0.6855\n",
      "  Epoch 32 | Loss: 0.5954 | Val PR-AUC: 0.6940\n",
      "  Epoch 33 | Loss: 0.5559 | Val PR-AUC: 0.6883\n",
      "  Epoch 34 | Loss: 0.5480 | Val PR-AUC: 0.6937\n",
      "  Epoch 35 | Loss: 0.5063 | Val PR-AUC: 0.6973\n",
      "  Epoch 36 | Loss: 0.5329 | Val PR-AUC: 0.6892\n",
      "  Epoch 37 | Loss: 0.5803 | Val PR-AUC: 0.7025\n",
      "  Epoch 38 | Loss: 0.5256 | Val PR-AUC: 0.6968\n",
      "  Epoch 39 | Loss: 0.5451 | Val PR-AUC: 0.6997\n",
      "  Epoch 40 | Loss: 0.5181 | Val PR-AUC: 0.6982\n",
      "  Epoch 41 | Loss: 0.5786 | Val PR-AUC: 0.6936\n",
      "  Epoch 42 | Loss: 0.5076 | Val PR-AUC: 0.6895\n",
      "  Epoch 43 | Loss: 0.5126 | Val PR-AUC: 0.6925\n",
      "  Epoch 44 | Loss: 0.5067 | Val PR-AUC: 0.7018\n",
      "  Epoch 45 | Loss: 0.4819 | Val PR-AUC: 0.7003\n",
      "  Epoch 46 | Loss: 0.4960 | Val PR-AUC: 0.7003\n",
      "Early stopping at epoch 47\n",
      "Best val PR-AUC for this trial: 0.7025\n",
      "\n",
      "=== Trial 22/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.001315\n",
      "  dropout     = 0.365\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 2.0207 | Val PR-AUC: 0.6682\n",
      "  Epoch 02 | Loss: 0.7065 | Val PR-AUC: 0.6860\n",
      "  Epoch 03 | Loss: 0.5455 | Val PR-AUC: 0.6887\n",
      "  Epoch 04 | Loss: 0.5116 | Val PR-AUC: 0.6933\n",
      "  Epoch 05 | Loss: 0.4188 | Val PR-AUC: 0.7043\n",
      "  Epoch 06 | Loss: 0.3416 | Val PR-AUC: 0.7110\n",
      "  Epoch 07 | Loss: 0.3556 | Val PR-AUC: 0.7041\n",
      "  Epoch 08 | Loss: 0.3009 | Val PR-AUC: 0.7098\n",
      "  Epoch 09 | Loss: 0.2866 | Val PR-AUC: 0.7113\n",
      "  Epoch 10 | Loss: 0.2825 | Val PR-AUC: 0.7049\n",
      "  Epoch 11 | Loss: 0.2650 | Val PR-AUC: 0.7131\n",
      "  Epoch 12 | Loss: 0.2679 | Val PR-AUC: 0.6990\n",
      "  Epoch 13 | Loss: 0.2789 | Val PR-AUC: 0.7163\n",
      "  Epoch 14 | Loss: 0.2606 | Val PR-AUC: 0.7054\n",
      "  Epoch 15 | Loss: 0.2880 | Val PR-AUC: 0.7024\n",
      "  Epoch 16 | Loss: 0.2554 | Val PR-AUC: 0.7050\n",
      "  Epoch 17 | Loss: 0.2606 | Val PR-AUC: 0.7044\n",
      "  Epoch 18 | Loss: 0.2383 | Val PR-AUC: 0.7114\n",
      "  Epoch 19 | Loss: 0.2251 | Val PR-AUC: 0.7081\n",
      "  Epoch 20 | Loss: 0.2240 | Val PR-AUC: 0.7158\n",
      "  Epoch 21 | Loss: 0.2364 | Val PR-AUC: 0.7111\n",
      "  Epoch 22 | Loss: 0.2100 | Val PR-AUC: 0.7076\n",
      "  Epoch 23 | Loss: 0.2495 | Val PR-AUC: 0.7195\n",
      "  Epoch 24 | Loss: 0.2283 | Val PR-AUC: 0.7305\n",
      "  Epoch 25 | Loss: 0.2139 | Val PR-AUC: 0.7108\n",
      "  Epoch 26 | Loss: 0.2119 | Val PR-AUC: 0.7162\n",
      "  Epoch 27 | Loss: 0.1819 | Val PR-AUC: 0.7194\n",
      "  Epoch 28 | Loss: 0.2142 | Val PR-AUC: 0.7220\n",
      "  Epoch 29 | Loss: 0.2224 | Val PR-AUC: 0.7177\n",
      "  Epoch 30 | Loss: 0.1867 | Val PR-AUC: 0.7191\n",
      "  Epoch 31 | Loss: 0.1665 | Val PR-AUC: 0.7086\n",
      "  Epoch 32 | Loss: 0.1836 | Val PR-AUC: 0.7102\n",
      "  Epoch 33 | Loss: 0.1685 | Val PR-AUC: 0.6997\n",
      "Early stopping at epoch 34\n",
      "Best val PR-AUC for this trial: 0.7305\n",
      "\n",
      "=== Trial 23/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.001729\n",
      "  dropout     = 0.111\n",
      "  weight_decay= 1e-05\n",
      "  Epoch 01 | Loss: 0.9197 | Val PR-AUC: 0.6219\n",
      "  Epoch 02 | Loss: 0.4135 | Val PR-AUC: 0.5253\n",
      "  Epoch 03 | Loss: 0.3084 | Val PR-AUC: 0.6742\n",
      "  Epoch 04 | Loss: 0.2502 | Val PR-AUC: 0.6745\n",
      "  Epoch 05 | Loss: 0.2044 | Val PR-AUC: 0.7116\n",
      "  Epoch 06 | Loss: 0.2047 | Val PR-AUC: 0.6791\n",
      "  Epoch 07 | Loss: 0.1588 | Val PR-AUC: 0.7104\n",
      "  Epoch 08 | Loss: 0.1518 | Val PR-AUC: 0.7132\n",
      "  Epoch 09 | Loss: 0.1631 | Val PR-AUC: 0.7101\n",
      "  Epoch 10 | Loss: 0.1686 | Val PR-AUC: 0.6778\n",
      "  Epoch 11 | Loss: 0.1373 | Val PR-AUC: 0.6875\n",
      "  Epoch 12 | Loss: 0.1121 | Val PR-AUC: 0.6909\n",
      "  Epoch 13 | Loss: 0.1173 | Val PR-AUC: 0.7002\n",
      "  Epoch 14 | Loss: 0.1177 | Val PR-AUC: 0.7103\n",
      "  Epoch 15 | Loss: 0.1255 | Val PR-AUC: 0.7109\n",
      "  Epoch 16 | Loss: 0.1219 | Val PR-AUC: 0.6926\n",
      "  Epoch 17 | Loss: 0.1075 | Val PR-AUC: 0.7044\n",
      "Early stopping at epoch 18\n",
      "Best val PR-AUC for this trial: 0.7132\n",
      "\n",
      "=== Trial 24/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000453\n",
      "  dropout     = 0.563\n",
      "  weight_decay= 0.0001\n",
      "  Epoch 01 | Loss: 4.5011 | Val PR-AUC: 0.5808\n",
      "  Epoch 02 | Loss: 2.0183 | Val PR-AUC: 0.6023\n",
      "  Epoch 03 | Loss: 1.3944 | Val PR-AUC: 0.6370\n",
      "  Epoch 04 | Loss: 1.0837 | Val PR-AUC: 0.6523\n",
      "  Epoch 05 | Loss: 0.8415 | Val PR-AUC: 0.6595\n",
      "  Epoch 06 | Loss: 0.8393 | Val PR-AUC: 0.6668\n",
      "  Epoch 07 | Loss: 0.6837 | Val PR-AUC: 0.6710\n",
      "  Epoch 08 | Loss: 0.6987 | Val PR-AUC: 0.6771\n",
      "  Epoch 09 | Loss: 0.6492 | Val PR-AUC: 0.6620\n",
      "  Epoch 10 | Loss: 0.6228 | Val PR-AUC: 0.6536\n",
      "  Epoch 11 | Loss: 0.5545 | Val PR-AUC: 0.6787\n",
      "  Epoch 12 | Loss: 0.5475 | Val PR-AUC: 0.6716\n",
      "  Epoch 13 | Loss: 0.5622 | Val PR-AUC: 0.6763\n",
      "  Epoch 14 | Loss: 0.4935 | Val PR-AUC: 0.6783\n",
      "  Epoch 15 | Loss: 0.5224 | Val PR-AUC: 0.6821\n",
      "  Epoch 16 | Loss: 0.4675 | Val PR-AUC: 0.6803\n",
      "  Epoch 17 | Loss: 0.4621 | Val PR-AUC: 0.6835\n",
      "  Epoch 18 | Loss: 0.4975 | Val PR-AUC: 0.6919\n",
      "  Epoch 19 | Loss: 0.4665 | Val PR-AUC: 0.7072\n",
      "  Epoch 20 | Loss: 0.5343 | Val PR-AUC: 0.7026\n",
      "  Epoch 21 | Loss: 0.5033 | Val PR-AUC: 0.7099\n",
      "  Epoch 22 | Loss: 0.4511 | Val PR-AUC: 0.7169\n",
      "  Epoch 23 | Loss: 0.4312 | Val PR-AUC: 0.7173\n",
      "  Epoch 24 | Loss: 0.3760 | Val PR-AUC: 0.7158\n",
      "  Epoch 25 | Loss: 0.4806 | Val PR-AUC: 0.7100\n",
      "  Epoch 26 | Loss: 0.4224 | Val PR-AUC: 0.7134\n",
      "  Epoch 27 | Loss: 0.4218 | Val PR-AUC: 0.7115\n",
      "  Epoch 28 | Loss: 0.3701 | Val PR-AUC: 0.7130\n",
      "  Epoch 29 | Loss: 0.4266 | Val PR-AUC: 0.7117\n",
      "  Epoch 30 | Loss: 0.3538 | Val PR-AUC: 0.7117\n",
      "  Epoch 31 | Loss: 0.4089 | Val PR-AUC: 0.7205\n",
      "  Epoch 32 | Loss: 0.3811 | Val PR-AUC: 0.7204\n",
      "  Epoch 33 | Loss: 0.3890 | Val PR-AUC: 0.7168\n",
      "  Epoch 34 | Loss: 0.3677 | Val PR-AUC: 0.7111\n",
      "  Epoch 35 | Loss: 0.3561 | Val PR-AUC: 0.7153\n",
      "  Epoch 36 | Loss: 0.3309 | Val PR-AUC: 0.7121\n",
      "  Epoch 37 | Loss: 0.3532 | Val PR-AUC: 0.7126\n",
      "  Epoch 38 | Loss: 0.3184 | Val PR-AUC: 0.7079\n",
      "  Epoch 39 | Loss: 0.3327 | Val PR-AUC: 0.7166\n",
      "  Epoch 40 | Loss: 0.3255 | Val PR-AUC: 0.7080\n",
      "  Epoch 41 | Loss: 0.3269 | Val PR-AUC: 0.7208\n",
      "  Epoch 42 | Loss: 0.2955 | Val PR-AUC: 0.7096\n",
      "  Epoch 43 | Loss: 0.3306 | Val PR-AUC: 0.7079\n",
      "  Epoch 44 | Loss: 0.3421 | Val PR-AUC: 0.7146\n",
      "  Epoch 45 | Loss: 0.3610 | Val PR-AUC: 0.7139\n",
      "  Epoch 46 | Loss: 0.3645 | Val PR-AUC: 0.7128\n",
      "  Epoch 47 | Loss: 0.3545 | Val PR-AUC: 0.7164\n",
      "  Epoch 48 | Loss: 0.2940 | Val PR-AUC: 0.7198\n",
      "  Epoch 49 | Loss: 0.3060 | Val PR-AUC: 0.7187\n",
      "  Epoch 50 | Loss: 0.3234 | Val PR-AUC: 0.7192\n",
      "Early stopping at epoch 51\n",
      "Best val PR-AUC for this trial: 0.7208\n",
      "\n",
      "=== Trial 25/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000155\n",
      "  dropout     = 0.217\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 4.8138 | Val PR-AUC: 0.5063\n",
      "  Epoch 02 | Loss: 2.2249 | Val PR-AUC: 0.5896\n",
      "  Epoch 03 | Loss: 1.4943 | Val PR-AUC: 0.5797\n",
      "  Epoch 04 | Loss: 1.0667 | Val PR-AUC: 0.5902\n",
      "  Epoch 05 | Loss: 1.0383 | Val PR-AUC: 0.6108\n",
      "  Epoch 06 | Loss: 0.9283 | Val PR-AUC: 0.6000\n",
      "  Epoch 07 | Loss: 0.8154 | Val PR-AUC: 0.6128\n",
      "  Epoch 08 | Loss: 0.8069 | Val PR-AUC: 0.6160\n",
      "  Epoch 09 | Loss: 0.7531 | Val PR-AUC: 0.6165\n",
      "  Epoch 10 | Loss: 0.6938 | Val PR-AUC: 0.6250\n",
      "  Epoch 11 | Loss: 0.6719 | Val PR-AUC: 0.6229\n",
      "  Epoch 12 | Loss: 0.6647 | Val PR-AUC: 0.6168\n",
      "  Epoch 13 | Loss: 0.5997 | Val PR-AUC: 0.6220\n",
      "  Epoch 14 | Loss: 0.5361 | Val PR-AUC: 0.6342\n",
      "  Epoch 15 | Loss: 0.5372 | Val PR-AUC: 0.6354\n",
      "  Epoch 16 | Loss: 0.5080 | Val PR-AUC: 0.6434\n",
      "  Epoch 17 | Loss: 0.4868 | Val PR-AUC: 0.6310\n",
      "  Epoch 18 | Loss: 0.4708 | Val PR-AUC: 0.6496\n",
      "  Epoch 19 | Loss: 0.4625 | Val PR-AUC: 0.6519\n",
      "  Epoch 20 | Loss: 0.4120 | Val PR-AUC: 0.6662\n",
      "  Epoch 21 | Loss: 0.3906 | Val PR-AUC: 0.6667\n",
      "  Epoch 22 | Loss: 0.3799 | Val PR-AUC: 0.6573\n",
      "  Epoch 23 | Loss: 0.3578 | Val PR-AUC: 0.6499\n",
      "  Epoch 24 | Loss: 0.3645 | Val PR-AUC: 0.6690\n",
      "  Epoch 25 | Loss: 0.3336 | Val PR-AUC: 0.6721\n",
      "  Epoch 26 | Loss: 0.3261 | Val PR-AUC: 0.6737\n",
      "  Epoch 27 | Loss: 0.2861 | Val PR-AUC: 0.6747\n",
      "  Epoch 28 | Loss: 0.3039 | Val PR-AUC: 0.6841\n",
      "  Epoch 29 | Loss: 0.2775 | Val PR-AUC: 0.6867\n",
      "  Epoch 30 | Loss: 0.2626 | Val PR-AUC: 0.6914\n",
      "  Epoch 31 | Loss: 0.2522 | Val PR-AUC: 0.6962\n",
      "  Epoch 32 | Loss: 0.2777 | Val PR-AUC: 0.6928\n",
      "  Epoch 33 | Loss: 0.2621 | Val PR-AUC: 0.6927\n",
      "  Epoch 34 | Loss: 0.2557 | Val PR-AUC: 0.6977\n",
      "  Epoch 35 | Loss: 0.2468 | Val PR-AUC: 0.6938\n",
      "  Epoch 36 | Loss: 0.2401 | Val PR-AUC: 0.6901\n",
      "  Epoch 37 | Loss: 0.2159 | Val PR-AUC: 0.6945\n",
      "  Epoch 38 | Loss: 0.2096 | Val PR-AUC: 0.7045\n",
      "  Epoch 39 | Loss: 0.2158 | Val PR-AUC: 0.7045\n",
      "  Epoch 40 | Loss: 0.2294 | Val PR-AUC: 0.7058\n",
      "  Epoch 41 | Loss: 0.2426 | Val PR-AUC: 0.7067\n",
      "  Epoch 42 | Loss: 0.2272 | Val PR-AUC: 0.7003\n",
      "  Epoch 43 | Loss: 0.2009 | Val PR-AUC: 0.7114\n",
      "  Epoch 44 | Loss: 0.2500 | Val PR-AUC: 0.7105\n",
      "  Epoch 45 | Loss: 0.1961 | Val PR-AUC: 0.7092\n",
      "  Epoch 46 | Loss: 0.2116 | Val PR-AUC: 0.7079\n",
      "  Epoch 47 | Loss: 0.2023 | Val PR-AUC: 0.7149\n",
      "  Epoch 48 | Loss: 0.2273 | Val PR-AUC: 0.7142\n",
      "  Epoch 49 | Loss: 0.2041 | Val PR-AUC: 0.7031\n",
      "  Epoch 50 | Loss: 0.2059 | Val PR-AUC: 0.7064\n",
      "  Epoch 51 | Loss: 0.2216 | Val PR-AUC: 0.7063\n",
      "  Epoch 52 | Loss: 0.2051 | Val PR-AUC: 0.7091\n",
      "  Epoch 53 | Loss: 0.1953 | Val PR-AUC: 0.7131\n",
      "  Epoch 54 | Loss: 0.1978 | Val PR-AUC: 0.7054\n",
      "  Epoch 55 | Loss: 0.1917 | Val PR-AUC: 0.7034\n",
      "  Epoch 56 | Loss: 0.2001 | Val PR-AUC: 0.7091\n",
      "Early stopping at epoch 57\n",
      "Best val PR-AUC for this trial: 0.7149\n",
      "\n",
      "=== Trial 26/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000164\n",
      "  dropout     = 0.128\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 3.3736 | Val PR-AUC: 0.5972\n",
      "  Epoch 02 | Loss: 1.6468 | Val PR-AUC: 0.5780\n",
      "  Epoch 03 | Loss: 1.2875 | Val PR-AUC: 0.6196\n",
      "  Epoch 04 | Loss: 1.0833 | Val PR-AUC: 0.6133\n",
      "  Epoch 05 | Loss: 0.9469 | Val PR-AUC: 0.6157\n",
      "  Epoch 06 | Loss: 0.7993 | Val PR-AUC: 0.6174\n",
      "  Epoch 07 | Loss: 0.7098 | Val PR-AUC: 0.6118\n",
      "  Epoch 08 | Loss: 0.6548 | Val PR-AUC: 0.6161\n",
      "  Epoch 09 | Loss: 0.6013 | Val PR-AUC: 0.6148\n",
      "  Epoch 10 | Loss: 0.5918 | Val PR-AUC: 0.6129\n",
      "  Epoch 11 | Loss: 0.5772 | Val PR-AUC: 0.6283\n",
      "  Epoch 12 | Loss: 0.5436 | Val PR-AUC: 0.5855\n",
      "  Epoch 13 | Loss: 0.4899 | Val PR-AUC: 0.6323\n",
      "  Epoch 14 | Loss: 0.4762 | Val PR-AUC: 0.6244\n",
      "  Epoch 15 | Loss: 0.4582 | Val PR-AUC: 0.6408\n",
      "  Epoch 16 | Loss: 0.4665 | Val PR-AUC: 0.6212\n",
      "  Epoch 17 | Loss: 0.4111 | Val PR-AUC: 0.6384\n",
      "  Epoch 18 | Loss: 0.4350 | Val PR-AUC: 0.6289\n",
      "  Epoch 19 | Loss: 0.3876 | Val PR-AUC: 0.6586\n",
      "  Epoch 20 | Loss: 0.4071 | Val PR-AUC: 0.6510\n",
      "  Epoch 21 | Loss: 0.3726 | Val PR-AUC: 0.6462\n",
      "  Epoch 22 | Loss: 0.3781 | Val PR-AUC: 0.6451\n",
      "  Epoch 23 | Loss: 0.3689 | Val PR-AUC: 0.6361\n",
      "  Epoch 24 | Loss: 0.3543 | Val PR-AUC: 0.6504\n",
      "  Epoch 25 | Loss: 0.3513 | Val PR-AUC: 0.6461\n",
      "  Epoch 26 | Loss: 0.3410 | Val PR-AUC: 0.6601\n",
      "  Epoch 27 | Loss: 0.3853 | Val PR-AUC: 0.6612\n",
      "  Epoch 28 | Loss: 0.3429 | Val PR-AUC: 0.6563\n",
      "  Epoch 29 | Loss: 0.3172 | Val PR-AUC: 0.6578\n",
      "  Epoch 30 | Loss: 0.3459 | Val PR-AUC: 0.6512\n",
      "  Epoch 31 | Loss: 0.3323 | Val PR-AUC: 0.6553\n",
      "  Epoch 32 | Loss: 0.2797 | Val PR-AUC: 0.6584\n",
      "  Epoch 33 | Loss: 0.3202 | Val PR-AUC: 0.6539\n",
      "  Epoch 34 | Loss: 0.2996 | Val PR-AUC: 0.6598\n",
      "  Epoch 35 | Loss: 0.2626 | Val PR-AUC: 0.6607\n",
      "  Epoch 36 | Loss: 0.2840 | Val PR-AUC: 0.6652\n",
      "  Epoch 37 | Loss: 0.2390 | Val PR-AUC: 0.6667\n",
      "  Epoch 38 | Loss: 0.2427 | Val PR-AUC: 0.6758\n",
      "  Epoch 39 | Loss: 0.2360 | Val PR-AUC: 0.6655\n",
      "  Epoch 40 | Loss: 0.2380 | Val PR-AUC: 0.6807\n",
      "  Epoch 41 | Loss: 0.2543 | Val PR-AUC: 0.6785\n",
      "  Epoch 42 | Loss: 0.2442 | Val PR-AUC: 0.6796\n",
      "  Epoch 43 | Loss: 0.2406 | Val PR-AUC: 0.6792\n",
      "  Epoch 44 | Loss: 0.2352 | Val PR-AUC: 0.6742\n",
      "  Epoch 45 | Loss: 0.2192 | Val PR-AUC: 0.6833\n",
      "  Epoch 46 | Loss: 0.2231 | Val PR-AUC: 0.6779\n",
      "  Epoch 47 | Loss: 0.2333 | Val PR-AUC: 0.6938\n",
      "  Epoch 48 | Loss: 0.1886 | Val PR-AUC: 0.6891\n",
      "  Epoch 49 | Loss: 0.2130 | Val PR-AUC: 0.6878\n",
      "  Epoch 50 | Loss: 0.2142 | Val PR-AUC: 0.6798\n",
      "  Epoch 51 | Loss: 0.1999 | Val PR-AUC: 0.6854\n",
      "  Epoch 52 | Loss: 0.1721 | Val PR-AUC: 0.6877\n",
      "  Epoch 53 | Loss: 0.1759 | Val PR-AUC: 0.6877\n",
      "  Epoch 54 | Loss: 0.1820 | Val PR-AUC: 0.7006\n",
      "  Epoch 55 | Loss: 0.1561 | Val PR-AUC: 0.7021\n",
      "  Epoch 56 | Loss: 0.1610 | Val PR-AUC: 0.7036\n",
      "  Epoch 57 | Loss: 0.1639 | Val PR-AUC: 0.6972\n",
      "  Epoch 58 | Loss: 0.1912 | Val PR-AUC: 0.6935\n",
      "  Epoch 59 | Loss: 0.1443 | Val PR-AUC: 0.6955\n",
      "  Epoch 60 | Loss: 0.1490 | Val PR-AUC: 0.6996\n",
      "  Epoch 61 | Loss: 0.1597 | Val PR-AUC: 0.7054\n",
      "  Epoch 62 | Loss: 0.1401 | Val PR-AUC: 0.7084\n",
      "  Epoch 63 | Loss: 0.1656 | Val PR-AUC: 0.7059\n",
      "  Epoch 64 | Loss: 0.1551 | Val PR-AUC: 0.6917\n",
      "  Epoch 65 | Loss: 0.1519 | Val PR-AUC: 0.7158\n",
      "  Epoch 66 | Loss: 0.1584 | Val PR-AUC: 0.7084\n",
      "  Epoch 67 | Loss: 0.1531 | Val PR-AUC: 0.6986\n",
      "  Epoch 68 | Loss: 0.1461 | Val PR-AUC: 0.7072\n",
      "  Epoch 69 | Loss: 0.1331 | Val PR-AUC: 0.7086\n",
      "  Epoch 70 | Loss: 0.1470 | Val PR-AUC: 0.7021\n",
      "  Epoch 71 | Loss: 0.1460 | Val PR-AUC: 0.7053\n",
      "  Epoch 72 | Loss: 0.1438 | Val PR-AUC: 0.7055\n",
      "  Epoch 73 | Loss: 0.1376 | Val PR-AUC: 0.7060\n",
      "  Epoch 74 | Loss: 0.1350 | Val PR-AUC: 0.7124\n",
      "Early stopping at epoch 75\n",
      "Best val PR-AUC for this trial: 0.7158\n",
      "\n",
      "=== Trial 27/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000213\n",
      "  dropout     = 0.546\n",
      "  weight_decay= 1e-05\n",
      "  Epoch 01 | Loss: 4.4092 | Val PR-AUC: 0.5009\n",
      "  Epoch 02 | Loss: 2.8338 | Val PR-AUC: 0.6051\n",
      "  Epoch 03 | Loss: 1.6939 | Val PR-AUC: 0.6449\n",
      "  Epoch 04 | Loss: 1.4517 | Val PR-AUC: 0.6050\n",
      "  Epoch 05 | Loss: 1.1385 | Val PR-AUC: 0.6340\n",
      "  Epoch 06 | Loss: 1.0364 | Val PR-AUC: 0.6475\n",
      "  Epoch 07 | Loss: 0.9642 | Val PR-AUC: 0.6574\n",
      "  Epoch 08 | Loss: 0.8409 | Val PR-AUC: 0.6657\n",
      "  Epoch 09 | Loss: 0.9074 | Val PR-AUC: 0.6710\n",
      "  Epoch 10 | Loss: 0.7411 | Val PR-AUC: 0.6844\n",
      "  Epoch 11 | Loss: 0.7622 | Val PR-AUC: 0.6714\n",
      "  Epoch 12 | Loss: 0.7385 | Val PR-AUC: 0.6906\n",
      "  Epoch 13 | Loss: 0.7326 | Val PR-AUC: 0.6867\n",
      "  Epoch 14 | Loss: 0.6410 | Val PR-AUC: 0.6892\n",
      "  Epoch 15 | Loss: 0.6520 | Val PR-AUC: 0.6864\n",
      "  Epoch 16 | Loss: 0.6145 | Val PR-AUC: 0.6815\n",
      "  Epoch 17 | Loss: 0.6115 | Val PR-AUC: 0.6822\n",
      "  Epoch 18 | Loss: 0.5678 | Val PR-AUC: 0.6927\n",
      "  Epoch 19 | Loss: 0.6248 | Val PR-AUC: 0.6862\n",
      "  Epoch 20 | Loss: 0.5459 | Val PR-AUC: 0.6792\n",
      "  Epoch 21 | Loss: 0.5548 | Val PR-AUC: 0.6841\n",
      "  Epoch 22 | Loss: 0.5238 | Val PR-AUC: 0.6853\n",
      "  Epoch 23 | Loss: 0.5852 | Val PR-AUC: 0.6860\n",
      "  Epoch 24 | Loss: 0.5835 | Val PR-AUC: 0.6534\n",
      "  Epoch 25 | Loss: 0.4611 | Val PR-AUC: 0.6879\n",
      "  Epoch 26 | Loss: 0.5169 | Val PR-AUC: 0.6628\n",
      "  Epoch 27 | Loss: 0.4929 | Val PR-AUC: 0.6942\n",
      "  Epoch 28 | Loss: 0.5159 | Val PR-AUC: 0.6785\n",
      "  Epoch 29 | Loss: 0.4869 | Val PR-AUC: 0.6932\n",
      "  Epoch 30 | Loss: 0.4877 | Val PR-AUC: 0.6850\n",
      "  Epoch 31 | Loss: 0.4328 | Val PR-AUC: 0.6964\n",
      "  Epoch 32 | Loss: 0.4358 | Val PR-AUC: 0.6985\n",
      "  Epoch 33 | Loss: 0.4920 | Val PR-AUC: 0.6959\n",
      "  Epoch 34 | Loss: 0.4224 | Val PR-AUC: 0.6997\n",
      "  Epoch 35 | Loss: 0.3914 | Val PR-AUC: 0.6991\n",
      "  Epoch 36 | Loss: 0.4692 | Val PR-AUC: 0.7008\n",
      "  Epoch 37 | Loss: 0.4082 | Val PR-AUC: 0.7012\n",
      "  Epoch 38 | Loss: 0.4365 | Val PR-AUC: 0.6993\n",
      "  Epoch 39 | Loss: 0.4264 | Val PR-AUC: 0.6995\n",
      "  Epoch 40 | Loss: 0.4249 | Val PR-AUC: 0.7076\n",
      "  Epoch 41 | Loss: 0.4251 | Val PR-AUC: 0.7031\n",
      "  Epoch 42 | Loss: 0.3889 | Val PR-AUC: 0.6997\n",
      "  Epoch 43 | Loss: 0.3850 | Val PR-AUC: 0.7044\n",
      "  Epoch 44 | Loss: 0.4084 | Val PR-AUC: 0.7024\n",
      "  Epoch 45 | Loss: 0.3819 | Val PR-AUC: 0.6829\n",
      "  Epoch 46 | Loss: 0.3982 | Val PR-AUC: 0.7025\n",
      "  Epoch 47 | Loss: 0.3750 | Val PR-AUC: 0.6991\n",
      "  Epoch 48 | Loss: 0.3737 | Val PR-AUC: 0.7034\n",
      "  Epoch 49 | Loss: 0.3786 | Val PR-AUC: 0.6999\n",
      "  Epoch 50 | Loss: 0.3646 | Val PR-AUC: 0.7181\n",
      "  Epoch 51 | Loss: 0.3723 | Val PR-AUC: 0.7016\n",
      "  Epoch 52 | Loss: 0.4278 | Val PR-AUC: 0.7093\n",
      "  Epoch 53 | Loss: 0.3895 | Val PR-AUC: 0.7063\n",
      "  Epoch 54 | Loss: 0.3790 | Val PR-AUC: 0.7087\n",
      "  Epoch 55 | Loss: 0.3854 | Val PR-AUC: 0.7131\n",
      "  Epoch 56 | Loss: 0.3653 | Val PR-AUC: 0.7107\n",
      "  Epoch 57 | Loss: 0.3877 | Val PR-AUC: 0.7105\n",
      "  Epoch 58 | Loss: 0.3556 | Val PR-AUC: 0.7105\n",
      "  Epoch 59 | Loss: 0.3385 | Val PR-AUC: 0.7108\n",
      "Early stopping at epoch 60\n",
      "Best val PR-AUC for this trial: 0.7181\n",
      "\n",
      "=== Trial 28/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000147\n",
      "  dropout     = 0.232\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 2.7187 | Val PR-AUC: 0.5458\n",
      "  Epoch 02 | Loss: 1.3559 | Val PR-AUC: 0.5503\n",
      "  Epoch 03 | Loss: 1.0083 | Val PR-AUC: 0.5832\n",
      "  Epoch 04 | Loss: 0.9125 | Val PR-AUC: 0.5673\n",
      "  Epoch 05 | Loss: 0.8428 | Val PR-AUC: 0.5635\n",
      "  Epoch 06 | Loss: 0.7431 | Val PR-AUC: 0.5742\n",
      "  Epoch 07 | Loss: 0.6504 | Val PR-AUC: 0.5681\n",
      "  Epoch 08 | Loss: 0.5734 | Val PR-AUC: 0.5884\n",
      "  Epoch 09 | Loss: 0.5754 | Val PR-AUC: 0.5901\n",
      "  Epoch 10 | Loss: 0.5826 | Val PR-AUC: 0.5890\n",
      "  Epoch 11 | Loss: 0.5421 | Val PR-AUC: 0.5913\n",
      "  Epoch 12 | Loss: 0.4972 | Val PR-AUC: 0.5966\n",
      "  Epoch 13 | Loss: 0.4422 | Val PR-AUC: 0.6022\n",
      "  Epoch 14 | Loss: 0.4731 | Val PR-AUC: 0.5902\n",
      "  Epoch 15 | Loss: 0.4415 | Val PR-AUC: 0.6079\n",
      "  Epoch 16 | Loss: 0.4217 | Val PR-AUC: 0.6147\n",
      "  Epoch 17 | Loss: 0.4174 | Val PR-AUC: 0.6448\n",
      "  Epoch 18 | Loss: 0.3696 | Val PR-AUC: 0.6449\n",
      "  Epoch 19 | Loss: 0.4076 | Val PR-AUC: 0.6440\n",
      "  Epoch 20 | Loss: 0.3736 | Val PR-AUC: 0.6415\n",
      "  Epoch 21 | Loss: 0.3610 | Val PR-AUC: 0.6615\n",
      "  Epoch 22 | Loss: 0.3552 | Val PR-AUC: 0.6585\n",
      "  Epoch 23 | Loss: 0.3518 | Val PR-AUC: 0.6586\n",
      "  Epoch 24 | Loss: 0.3162 | Val PR-AUC: 0.6654\n",
      "  Epoch 25 | Loss: 0.3398 | Val PR-AUC: 0.6666\n",
      "  Epoch 26 | Loss: 0.3137 | Val PR-AUC: 0.6735\n",
      "  Epoch 27 | Loss: 0.2638 | Val PR-AUC: 0.6775\n",
      "  Epoch 28 | Loss: 0.3200 | Val PR-AUC: 0.6773\n",
      "  Epoch 29 | Loss: 0.2640 | Val PR-AUC: 0.6918\n",
      "  Epoch 30 | Loss: 0.3180 | Val PR-AUC: 0.6994\n",
      "  Epoch 31 | Loss: 0.2662 | Val PR-AUC: 0.7027\n",
      "  Epoch 32 | Loss: 0.2606 | Val PR-AUC: 0.6948\n",
      "  Epoch 33 | Loss: 0.2760 | Val PR-AUC: 0.6983\n",
      "  Epoch 34 | Loss: 0.2534 | Val PR-AUC: 0.6872\n",
      "  Epoch 35 | Loss: 0.2740 | Val PR-AUC: 0.7004\n",
      "  Epoch 36 | Loss: 0.2502 | Val PR-AUC: 0.6993\n",
      "  Epoch 37 | Loss: 0.2498 | Val PR-AUC: 0.7022\n",
      "  Epoch 38 | Loss: 0.2584 | Val PR-AUC: 0.7024\n",
      "  Epoch 39 | Loss: 0.2334 | Val PR-AUC: 0.6982\n",
      "  Epoch 40 | Loss: 0.2284 | Val PR-AUC: 0.6964\n",
      "Early stopping at epoch 41\n",
      "Best val PR-AUC for this trial: 0.7027\n",
      "\n",
      "=== Trial 29/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.001074\n",
      "  dropout     = 0.349\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 2.4119 | Val PR-AUC: 0.6776\n",
      "  Epoch 02 | Loss: 0.8554 | Val PR-AUC: 0.6909\n",
      "  Epoch 03 | Loss: 0.6358 | Val PR-AUC: 0.6815\n",
      "  Epoch 04 | Loss: 0.4796 | Val PR-AUC: 0.6785\n",
      "  Epoch 05 | Loss: 0.3966 | Val PR-AUC: 0.6959\n",
      "  Epoch 06 | Loss: 0.3701 | Val PR-AUC: 0.7126\n",
      "  Epoch 07 | Loss: 0.3458 | Val PR-AUC: 0.7038\n",
      "  Epoch 08 | Loss: 0.3465 | Val PR-AUC: 0.6919\n",
      "  Epoch 09 | Loss: 0.3001 | Val PR-AUC: 0.7092\n",
      "  Epoch 10 | Loss: 0.3189 | Val PR-AUC: 0.7123\n",
      "  Epoch 11 | Loss: 0.2788 | Val PR-AUC: 0.7066\n",
      "  Epoch 12 | Loss: 0.2891 | Val PR-AUC: 0.7152\n",
      "  Epoch 13 | Loss: 0.2304 | Val PR-AUC: 0.7131\n",
      "  Epoch 14 | Loss: 0.2574 | Val PR-AUC: 0.7162\n",
      "  Epoch 15 | Loss: 0.2417 | Val PR-AUC: 0.7152\n",
      "  Epoch 16 | Loss: 0.2578 | Val PR-AUC: 0.6714\n",
      "  Epoch 17 | Loss: 0.2792 | Val PR-AUC: 0.6878\n",
      "  Epoch 18 | Loss: 0.2360 | Val PR-AUC: 0.7020\n",
      "  Epoch 19 | Loss: 0.2233 | Val PR-AUC: 0.6898\n",
      "  Epoch 20 | Loss: 0.2095 | Val PR-AUC: 0.6981\n",
      "  Epoch 21 | Loss: 0.1941 | Val PR-AUC: 0.6833\n",
      "  Epoch 22 | Loss: 0.1868 | Val PR-AUC: 0.6868\n",
      "  Epoch 23 | Loss: 0.2028 | Val PR-AUC: 0.6886\n",
      "Early stopping at epoch 24\n",
      "Best val PR-AUC for this trial: 0.7162\n",
      "\n",
      "=== Trial 30/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.001912\n",
      "  dropout     = 0.260\n",
      "  weight_decay= 0.0001\n",
      "  Epoch 01 | Loss: 1.1743 | Val PR-AUC: 0.6188\n",
      "  Epoch 02 | Loss: 0.5307 | Val PR-AUC: 0.6870\n",
      "  Epoch 03 | Loss: 0.4070 | Val PR-AUC: 0.6894\n",
      "  Epoch 04 | Loss: 0.2968 | Val PR-AUC: 0.7038\n",
      "  Epoch 05 | Loss: 0.2814 | Val PR-AUC: 0.7057\n",
      "  Epoch 06 | Loss: 0.2846 | Val PR-AUC: 0.7017\n",
      "  Epoch 07 | Loss: 0.2672 | Val PR-AUC: 0.7104\n",
      "  Epoch 08 | Loss: 0.2590 | Val PR-AUC: 0.7011\n",
      "  Epoch 09 | Loss: 0.2275 | Val PR-AUC: 0.7017\n",
      "  Epoch 10 | Loss: 0.2264 | Val PR-AUC: 0.7174\n",
      "  Epoch 11 | Loss: 0.2204 | Val PR-AUC: 0.6983\n",
      "  Epoch 12 | Loss: 0.2095 | Val PR-AUC: 0.6719\n",
      "  Epoch 13 | Loss: 0.2325 | Val PR-AUC: 0.7081\n",
      "  Epoch 14 | Loss: 0.2059 | Val PR-AUC: 0.6822\n",
      "  Epoch 15 | Loss: 0.1736 | Val PR-AUC: 0.6901\n",
      "  Epoch 16 | Loss: 0.1868 | Val PR-AUC: 0.7031\n",
      "  Epoch 17 | Loss: 0.1594 | Val PR-AUC: 0.7104\n",
      "  Epoch 18 | Loss: 0.1920 | Val PR-AUC: 0.7091\n",
      "  Epoch 19 | Loss: 0.1703 | Val PR-AUC: 0.7138\n",
      "Early stopping at epoch 20\n",
      "Best val PR-AUC for this trial: 0.7174\n",
      "Best hyperparameters found:\n",
      "{'lr': 0.0018312664017712875, 'dropout': 0.47483881636962355, 'weight_decay': 0.0001}\n",
      "Best validation PR-AUC: 0.7328759065831\n"
     ]
    }
   ],
   "source": [
    "#number of random configs to try\n",
    "num_trials = 30\n",
    "best_hparams = None\n",
    "best_val_score = -np.inf\n",
    "best_model_state = None\n",
    "\n",
    "for trial in range(1, num_trials + 1):\n",
    "    print(f\"\\n=== Trial {trial}/{num_trials} ===\")\n",
    "\n",
    "    #sample a random hyperparameter configuration\n",
    "    hparams = sample_hparams()\n",
    "    lr           = hparams[\"lr\"]\n",
    "    dropout      = hparams[\"dropout\"]\n",
    "    weight_decay = hparams[\"weight_decay\"]\n",
    "\n",
    "    print(f\"Sampled hyperparameters:\")\n",
    "    print(f\"  lr          = {lr:.6f}\")\n",
    "    print(f\"  dropout     = {dropout:.3f}\")\n",
    "    print(f\"  weight_decay= {weight_decay}\")\n",
    "\n",
    "    #train and evaluate this config on the validation set\n",
    "    val_pr_auc, state_dict = train_eval_one_config(\n",
    "        lr=lr,\n",
    "        dropout=dropout,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    print(f\"Best val PR-AUC for this trial: {val_pr_auc:.4f}\")\n",
    "\n",
    "    #keep track of overall best config\n",
    "    if val_pr_auc > best_val_score:\n",
    "        best_val_score = val_pr_auc\n",
    "        best_hparams = hparams\n",
    "        best_model_state = state_dict\n",
    "\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(best_hparams)\n",
    "print(\"Best validation PR-AUC:\", best_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cf67f289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PR-AUC with best hyperparameters: 0.7972\n"
     ]
    }
   ],
   "source": [
    "#rebuild the best model and load its weights\n",
    "best_model = FraudNet(input_dim, dropout=best_hparams[\"dropout\"]).to(device)\n",
    "best_model.load_state_dict(best_model_state)\n",
    "best_model.eval()\n",
    "\n",
    "#use the best batch_size for the test loader\n",
    "test_loader  = DataLoader(test_dataset, batch_size=2048, shuffle=False)\n",
    "\n",
    "all_logits = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        logits = best_model(X_batch)\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_targets.append(y_batch)\n",
    "\n",
    "all_logits = torch.cat(all_logits)\n",
    "all_targets = torch.cat(all_targets)\n",
    "\n",
    "#converts logits to p\n",
    "probs = torch.sigmoid(all_logits).numpy()\n",
    "targets = all_targets.numpy()\n",
    "\n",
    "#calculate roc auc score on the test set\n",
    "#roc = roc_auc_score(targets, probs)\n",
    "#auc pr score on the test set\n",
    "pr_auc = average_precision_score(targets, probs) \n",
    "\n",
    "print(f\"Test PR-AUC with best hyperparameters: {pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c0930695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[56442   422]\n",
      " [   10    88]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9998    0.9926    0.9962     56864\n",
      "         1.0     0.1725    0.8980    0.2895        98\n",
      "\n",
      "    accuracy                         0.9924     56962\n",
      "   macro avg     0.5862    0.9453    0.6428     56962\n",
      "weighted avg     0.9984    0.9924    0.9950     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#threshold for confusion matrix\n",
    "threshold = 0.5\n",
    "#make predictions\n",
    "preds = (probs >= threshold).astype(int)\n",
    "\n",
    "#print confusion matrix\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(targets, preds))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(targets, preds, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
