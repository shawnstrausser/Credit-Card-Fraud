{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a95f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#sklearn for preprocessing and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "#matplotlib and seaborn to graph\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bb202d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "#load in dataset\n",
    "df = pd.read_csv('creditcard_fraud_detection.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5285e33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "af7ff12a-b98e-4d1e-b68b-5859e35ce79f",
       "rows": [
        [
         "Time",
         "0"
        ],
        [
         "V1",
         "0"
        ],
        [
         "V2",
         "0"
        ],
        [
         "V3",
         "0"
        ],
        [
         "V4",
         "0"
        ],
        [
         "V5",
         "0"
        ],
        [
         "V6",
         "0"
        ],
        [
         "V7",
         "0"
        ],
        [
         "V8",
         "0"
        ],
        [
         "V9",
         "0"
        ],
        [
         "V10",
         "0"
        ],
        [
         "V11",
         "0"
        ],
        [
         "V12",
         "0"
        ],
        [
         "V13",
         "0"
        ],
        [
         "V14",
         "0"
        ],
        [
         "V15",
         "0"
        ],
        [
         "V16",
         "0"
        ],
        [
         "V17",
         "0"
        ],
        [
         "V18",
         "0"
        ],
        [
         "V19",
         "0"
        ],
        [
         "V20",
         "0"
        ],
        [
         "V21",
         "0"
        ],
        [
         "V22",
         "0"
        ],
        [
         "V23",
         "0"
        ],
        [
         "V24",
         "0"
        ],
        [
         "V25",
         "0"
        ],
        [
         "V26",
         "0"
        ],
        [
         "V27",
         "0"
        ],
        [
         "V28",
         "0"
        ],
        [
         "Amount",
         "0"
        ],
        [
         "Class",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 31
       }
      },
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check nas\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4ad7e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001727485630620034\n"
     ]
    }
   ],
   "source": [
    "#calculate proportion of fraud in dataset\n",
    "print(sum(df['Class'])/len(df))\n",
    "#dataset is sparse, much more non fraud than fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf658c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess and split for train test\n",
    "\n",
    "#X is everything but \"Class\" (PCA features, time, amount)\n",
    "X = df.drop('Class', axis = 1).values\n",
    "#y is class (0 = no fraud, 1 = fraud)\n",
    "y= df['Class'].values\n",
    "\n",
    "scalar = StandardScaler()\n",
    "#PCA features are already scaled, but time and amount aren't\n",
    "X_scaled = scalar.fit_transform(X)\n",
    "\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size= 0.2, random_state= 50, \n",
    "                                                    #stratify y since dataset is sparse and we want to ensureki\n",
    "                                                    stratify= y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20e42ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrap dataset in classes for pytorch\n",
    "class CreditFraudDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        #convert np arrays to tensors\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    #return len dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    #return item of X, y at specific index\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 2048\n",
    "\n",
    "#wrap datasets\n",
    "train_dataset = CreditFraudDataset(X_train, y_train)\n",
    "test_dataset  = CreditFraudDataset(X_test, y_test)\n",
    "\n",
    "#initialize loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5375f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FraudNet(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=30, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "    (8): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#set up neural net\n",
    "class FraudNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "\n",
    "            #layer 1, 64 neurons\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            #layer 2, 32 neurons\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            #only one output logit, for fraud or not\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x: (batch_size, input_dim)\n",
    "        logits = self.net(x).squeeze(1)  #(batch_size,)\n",
    "        return logits\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "model = FraudNet(input_dim)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25f6766b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FraudNet(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=30, out_features=64, bias=True)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.3, inplace=False)\n",
       "    (8): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set up device\n",
    "#todo: set up cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90f1af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up bce for model\n",
    "#count number of each class\n",
    "class_counts = np.bincount(y_train)\n",
    "neg, pos = class_counts[0], class_counts[1]\n",
    "#set weights\n",
    "pos_weight = torch.tensor([neg / pos], dtype=torch.float32).to(device)\n",
    "\n",
    "#use BCE to weight fraud more in the model. Model treats missed fraud transactions more harshly in loss function\n",
    "#without weights model can get high performance just by predicting no fraud always, since 99%+ of samples aren't fraud\n",
    "#BCE fixes this by penalizing no fraud much more harshly than no fraud\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "affbb494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 0.8629 | ROC-AUC: 0.9851\n",
      "Epoch 02 | Loss: 0.5430 | ROC-AUC: 0.9861\n",
      "Epoch 03 | Loss: 0.4192 | ROC-AUC: 0.9856\n",
      "Epoch 04 | Loss: 0.3481 | ROC-AUC: 0.9868\n",
      "Epoch 05 | Loss: 0.3125 | ROC-AUC: 0.9853\n",
      "Epoch 06 | Loss: 0.2964 | ROC-AUC: 0.9865\n",
      "Epoch 07 | Loss: 0.2745 | ROC-AUC: 0.9870\n",
      "Epoch 08 | Loss: 0.2381 | ROC-AUC: 0.9878\n",
      "Epoch 09 | Loss: 0.2389 | ROC-AUC: 0.9863\n",
      "Epoch 10 | Loss: 0.2367 | ROC-AUC: 0.9864\n",
      "Epoch 11 | Loss: 0.2217 | ROC-AUC: 0.9838\n",
      "Epoch 12 | Loss: 0.2373 | ROC-AUC: 0.9856\n",
      "Epoch 13 | Loss: 0.2006 | ROC-AUC: 0.9872\n",
      "Epoch 14 | Loss: 0.2154 | ROC-AUC: 0.9858\n",
      "Epoch 15 | Loss: 0.1886 | ROC-AUC: 0.9839\n",
      "Epoch 16 | Loss: 0.1985 | ROC-AUC: 0.9832\n",
      "Epoch 17 | Loss: 0.1876 | ROC-AUC: 0.9843\n",
      "Epoch 18 | Loss: 0.1783 | ROC-AUC: 0.9855\n",
      "Epoch 19 | Loss: 0.1683 | ROC-AUC: 0.9857\n",
      "Epoch 20 | Loss: 0.1564 | ROC-AUC: 0.9837\n"
     ]
    }
   ],
   "source": [
    "#set number of epochs to train for\n",
    "num_epochs = 20\n",
    "\n",
    "\n",
    "#run training loop for each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    #train\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)               #output scores as logits instead of probabilities for bce\n",
    "        loss = criterion(logits, y_batch)     #calc loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    #evaluate for each epoch\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            logits = model(X_batch)\n",
    "            all_logits.append(logits.cpu())\n",
    "            all_targets.append(y_batch)\n",
    "\n",
    "    all_logits = torch.cat(all_logits)\n",
    "    all_targets = torch.cat(all_targets)\n",
    "\n",
    "    #converts logits to p\n",
    "    probs = torch.sigmoid(all_logits).numpy()\n",
    "    targets = all_targets.numpy()\n",
    "\n",
    "    #calculate roc auc score\n",
    "    auc = roc_auc_score(targets, probs)\n",
    "\n",
    "    #print output for epoch\n",
    "    print(f\"Epoch {epoch+1:02d} | Loss: {epoch_loss:.4f} | ROC-AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0930695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[55774  1090]\n",
      " [    8    90]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9999    0.9808    0.9903     56864\n",
      "         1.0     0.0763    0.9184    0.1408        98\n",
      "\n",
      "    accuracy                         0.9807     56962\n",
      "   macro avg     0.5381    0.9496    0.5655     56962\n",
      "weighted avg     0.9983    0.9807    0.9888     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#threshold for confusion matrix\n",
    "threshold = 0.5\n",
    "#make predictions\n",
    "preds = (probs >= threshold).astype(int)\n",
    "\n",
    "#print confusion matrix\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(targets, preds))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(targets, preds, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
