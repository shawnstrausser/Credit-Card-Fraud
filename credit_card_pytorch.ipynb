{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3a95f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "#sklearn for preprocessing and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score\n",
    "#matplotlib and seaborn to graph\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7ca53f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "#check to make sure cuda working\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current device:\", torch.cuda.current_device())\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0bb202d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "#load in dataset\n",
    "df = pd.read_csv('creditcard_fraud_detection.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5285e33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "21016f8f-ef5c-4858-8d30-2112fd470b26",
       "rows": [
        [
         "Time",
         "0"
        ],
        [
         "V1",
         "0"
        ],
        [
         "V2",
         "0"
        ],
        [
         "V3",
         "0"
        ],
        [
         "V4",
         "0"
        ],
        [
         "V5",
         "0"
        ],
        [
         "V6",
         "0"
        ],
        [
         "V7",
         "0"
        ],
        [
         "V8",
         "0"
        ],
        [
         "V9",
         "0"
        ],
        [
         "V10",
         "0"
        ],
        [
         "V11",
         "0"
        ],
        [
         "V12",
         "0"
        ],
        [
         "V13",
         "0"
        ],
        [
         "V14",
         "0"
        ],
        [
         "V15",
         "0"
        ],
        [
         "V16",
         "0"
        ],
        [
         "V17",
         "0"
        ],
        [
         "V18",
         "0"
        ],
        [
         "V19",
         "0"
        ],
        [
         "V20",
         "0"
        ],
        [
         "V21",
         "0"
        ],
        [
         "V22",
         "0"
        ],
        [
         "V23",
         "0"
        ],
        [
         "V24",
         "0"
        ],
        [
         "V25",
         "0"
        ],
        [
         "V26",
         "0"
        ],
        [
         "V27",
         "0"
        ],
        [
         "V28",
         "0"
        ],
        [
         "Amount",
         "0"
        ],
        [
         "Class",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 31
       }
      },
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check nas\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c4ad7e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001727485630620034\n"
     ]
    }
   ],
   "source": [
    "#calculate proportion of fraud in dataset\n",
    "print(sum(df['Class'])/len(df))\n",
    "#dataset is sparse, much more non fraud than fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf658c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess and split for train test\n",
    "\n",
    "#take log of amount\n",
    "df['Log_Amount'] = np.log(df['Amount'])\n",
    "\n",
    "#X is everything but \"Class\", and untransformed amount and time columns\n",
    "X = df.drop(['Class', 'Amount', 'Time'], axis = 1).values\n",
    "#y is class (0 = no fraud, 1 = fraud)\n",
    "y= df['Class'].values\n",
    "\n",
    "scalar = StandardScaler()\n",
    "#PCA features are already scaled, but time and amount aren't\n",
    "X_scaled = scalar.fit_transform(X)\n",
    "\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size= 0.2, random_state= 50, \n",
    "    #stratify y since dataset is sparse and we want to ensureki\n",
    "    stratify= y\n",
    "    )\n",
    "\n",
    "#create validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "20e42ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrap dataset in classes for pytorch\n",
    "class CreditFraudDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        #convert np arrays to tensors\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    #return len dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    #return item of X, y at specific index\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 2048\n",
    "\n",
    "#wrap datasets\n",
    "train_dataset = CreditFraudDataset(X_train, y_train)\n",
    "val_dataset   = CreditFraudDataset(X_val, y_val)\n",
    "test_dataset  = CreditFraudDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b5375f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FraudNet(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=30, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "    (8): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (9): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.3, inplace=False)\n",
      "    (12): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (13): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "    (15): Dropout(p=0.3, inplace=False)\n",
      "    (16): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#set up neural net\n",
    "class FraudNet(nn.Module):\n",
    "    def __init__(self, input_dim, dropout=0.3):  # dropout is now a hyperparameter\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "\n",
    "            #layer 1, 128 neurons\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            #layer 2, 64 neurons\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            #layer 3, 32 neurons\n",
    "            nn.Linear(64,32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            #layer 4, 16 neurons\n",
    "            nn.Linear(32,16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            #only one output logit, for fraud or not\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x: (batch_size, input_dim)\n",
    "        logits = self.net(x).squeeze(1)  #(batch_size,)\n",
    "        return logits\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "#init a temporary model just to inspect the architecture\n",
    "tmp_model = FraudNet(input_dim)\n",
    "print(tmp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "25f6766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up device\n",
    "#todo: set up cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f1af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up bce for model\n",
    "#count number of each class\n",
    "class_counts = np.bincount(y_train)\n",
    "neg, pos = class_counts[0], class_counts[1]\n",
    "#set weights\n",
    "pos_weight = torch.tensor([neg / pos], dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ae0afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bias initilization\n",
    "base_rate = pos / (neg + pos)\n",
    "\n",
    "epsilon = 1e-7\n",
    "base_rate = min(max(base_rate, epsilon), 1 - epsilon)\n",
    "bias_init = math.log(base_rate / (1.0 - base_rate))\n",
    "\n",
    "print(\"Base fraud rate:\", base_rate)\n",
    "print(\"Initial output bias (logit):\", bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affbb494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function wrapper to initialize training loop with different hyperparameters\n",
    "def train_eval_one_config(lr, dropout, batch_size, weight_decay=0.0):\n",
    "    #take hyperparameters as arguments, return best score and best model\n",
    "    \n",
    "    #initialize loaders here, batch size is a hyperparameter so use that\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    #set up model\n",
    "    model = FraudNet(input_dim, dropout=dropout).to(device)\n",
    "\n",
    "    #bias initialization\n",
    "    with torch.no_grad():\n",
    "        model.net[-1].bias.fill_(bias_init)\n",
    "\n",
    "    #set up bce for model\n",
    "    #use BCE to weight fraud more in the model. Model treats missed fraud transactions more harshly in loss function\n",
    "    #take learning rate and weight decay as arguments\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    best_val_pr_auc = -np.inf\n",
    "    best_state_dict = None\n",
    "\n",
    "    #set max epochs and patience\n",
    "    num_epochs = 50\n",
    "    \n",
    "    #early stopping made performance worse, removing it for now\n",
    "    #patience   = 5           #stop if val PR-AUC doesn't improve for 5 epochs\n",
    "    #epochs_no_improve = 0   #epochs without model improving pr auc\n",
    "\n",
    "    #run training loop for each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        #train\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X_batch)               #output scores as logits instead of probabilities for bce\n",
    "            loss = criterion(logits, y_batch)     #calc loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        #evaluate on validation set for each epoch\n",
    "        model.eval()\n",
    "        all_logits = []\n",
    "        all_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                logits = model(X_batch)\n",
    "                all_logits.append(logits.cpu())\n",
    "                all_targets.append(y_batch)\n",
    "\n",
    "        all_logits = torch.cat(all_logits)\n",
    "        all_targets = torch.cat(all_targets)\n",
    "\n",
    "        #converts logits to p\n",
    "        probs = torch.sigmoid(all_logits).numpy()\n",
    "        targets = all_targets.numpy()\n",
    "\n",
    "        #calculate roc auc score\n",
    "        #roc = roc_auc_score(targets, probs)\n",
    "        \n",
    "        #auc pr score (validation metric we care most about)\n",
    "        pr_auc = average_precision_score(targets, probs)\n",
    "\n",
    "        #track best validation PR-AUC for this config\n",
    "        if pr_auc > best_val_pr_auc:\n",
    "            best_val_pr_auc = pr_auc\n",
    "            best_state_dict = model.state_dict()\n",
    "            #if model is improvement, reset counter\n",
    "            #epochs_no_improve = 0\n",
    "        #else:\n",
    "            #else increment counter\n",
    "        #    epochs_no_improve += 1\n",
    "\n",
    "        #if epochs_no_improve >= patience:\n",
    "            #if we hit patience threshold, break\n",
    "        #    print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        #    break\n",
    "        \n",
    "\n",
    "        #print output for epoch (optional, you can comment this out if it's too verbose)\n",
    "        print(f\"  Epoch {epoch+1:02d} | Loss: {epoch_loss:.4f} | Val PR-AUC: {pr_auc:.4f}\")\n",
    "\n",
    "    return best_val_pr_auc, best_state_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "66e4687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter \"ranges\" for random search\n",
    "#we'll *sample* from these instead of trying every combination\n",
    "def sample_hparams():\n",
    "    #learning rate: sample log-uniform between 1e-4 and 3e-3\n",
    "    log_lr_min = math.log10(1e-4)\n",
    "    log_lr_max = math.log10(3e-3)\n",
    "    log_lr = random.uniform(log_lr_min, log_lr_max)\n",
    "    lr = 10 ** log_lr\n",
    "\n",
    "    #dropout: uniform between 0.1 and 0.5\n",
    "    dropout = random.uniform(0.1, 0.5)\n",
    "\n",
    "    #batch size: pick from a small discrete set\n",
    "    batch_size = random.choice([512, 1024, 2048])\n",
    "\n",
    "    #weight decay: small set of options (including no weight decay)\n",
    "    weight_decay = random.choice([0.0, 1e-5, 1e-4])\n",
    "\n",
    "    return {\n",
    "        \"lr\": lr,\n",
    "        \"dropout\": dropout,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"weight_decay\": weight_decay\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3956d284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Trial 1/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000367\n",
      "  dropout     = 0.106\n",
      "  batch_size  = 512\n",
      "  weight_decay= 0.0001\n",
      "  Epoch 01 | Loss: 0.8165 | Val ROC-AUC: 0.9598 | Val PR-AUC: 0.6487\n",
      "  Epoch 02 | Loss: 0.5787 | Val ROC-AUC: 0.9715 | Val PR-AUC: 0.6621\n",
      "  Epoch 03 | Loss: 0.4619 | Val ROC-AUC: 0.9781 | Val PR-AUC: 0.6556\n",
      "  Epoch 04 | Loss: 0.3761 | Val ROC-AUC: 0.9762 | Val PR-AUC: 0.6572\n",
      "  Epoch 05 | Loss: 0.3143 | Val ROC-AUC: 0.9809 | Val PR-AUC: 0.6820\n",
      "  Epoch 06 | Loss: 0.2628 | Val ROC-AUC: 0.9764 | Val PR-AUC: 0.6725\n",
      "  Epoch 07 | Loss: 0.2193 | Val ROC-AUC: 0.9794 | Val PR-AUC: 0.6771\n",
      "  Epoch 08 | Loss: 0.2122 | Val ROC-AUC: 0.9764 | Val PR-AUC: 0.6747\n",
      "  Epoch 09 | Loss: 0.1965 | Val ROC-AUC: 0.9842 | Val PR-AUC: 0.6606\n",
      "  Epoch 10 | Loss: 0.1934 | Val ROC-AUC: 0.9808 | Val PR-AUC: 0.6957\n",
      "  Epoch 11 | Loss: 0.1574 | Val ROC-AUC: 0.9770 | Val PR-AUC: 0.7022\n",
      "  Epoch 12 | Loss: 0.1228 | Val ROC-AUC: 0.9755 | Val PR-AUC: 0.6858\n",
      "  Epoch 13 | Loss: 0.1274 | Val ROC-AUC: 0.9769 | Val PR-AUC: 0.6760\n",
      "  Epoch 14 | Loss: 0.1321 | Val ROC-AUC: 0.9734 | Val PR-AUC: 0.7152\n",
      "  Epoch 15 | Loss: 0.1415 | Val ROC-AUC: 0.9750 | Val PR-AUC: 0.6822\n",
      "  Epoch 16 | Loss: 0.1058 | Val ROC-AUC: 0.9757 | Val PR-AUC: 0.7005\n",
      "  Epoch 17 | Loss: 0.1049 | Val ROC-AUC: 0.9720 | Val PR-AUC: 0.7156\n",
      "  Epoch 18 | Loss: 0.0865 | Val ROC-AUC: 0.9746 | Val PR-AUC: 0.7006\n",
      "  Epoch 19 | Loss: 0.0869 | Val ROC-AUC: 0.9744 | Val PR-AUC: 0.6803\n",
      "  Epoch 20 | Loss: 0.0813 | Val ROC-AUC: 0.9754 | Val PR-AUC: 0.6761\n",
      "  Epoch 21 | Loss: 0.0966 | Val ROC-AUC: 0.9730 | Val PR-AUC: 0.6883\n",
      "Early stopping at epoch 22\n",
      "--> Best val PR-AUC for this trial: 0.7156\n",
      "\n",
      "=== Trial 2/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.001480\n",
      "  dropout     = 0.200\n",
      "  batch_size  = 1024\n",
      "  weight_decay= 0.0001\n",
      "  Epoch 01 | Loss: 0.8412 | Val ROC-AUC: 0.9677 | Val PR-AUC: 0.6592\n",
      "  Epoch 02 | Loss: 0.5118 | Val ROC-AUC: 0.9736 | Val PR-AUC: 0.6700\n",
      "  Epoch 03 | Loss: 0.3799 | Val ROC-AUC: 0.9803 | Val PR-AUC: 0.6868\n",
      "  Epoch 04 | Loss: 0.3278 | Val ROC-AUC: 0.9804 | Val PR-AUC: 0.6911\n",
      "  Epoch 05 | Loss: 0.2671 | Val ROC-AUC: 0.9837 | Val PR-AUC: 0.6545\n",
      "  Epoch 06 | Loss: 0.2835 | Val ROC-AUC: 0.9839 | Val PR-AUC: 0.6757\n",
      "  Epoch 07 | Loss: 0.2383 | Val ROC-AUC: 0.9843 | Val PR-AUC: 0.6721\n",
      "  Epoch 08 | Loss: 0.2047 | Val ROC-AUC: 0.9831 | Val PR-AUC: 0.6915\n",
      "  Epoch 09 | Loss: 0.2017 | Val ROC-AUC: 0.9836 | Val PR-AUC: 0.6668\n",
      "  Epoch 10 | Loss: 0.1738 | Val ROC-AUC: 0.9817 | Val PR-AUC: 0.6515\n",
      "  Epoch 11 | Loss: 0.1594 | Val ROC-AUC: 0.9834 | Val PR-AUC: 0.6737\n",
      "  Epoch 12 | Loss: 0.1601 | Val ROC-AUC: 0.9829 | Val PR-AUC: 0.6900\n",
      "  Epoch 13 | Loss: 0.1910 | Val ROC-AUC: 0.9866 | Val PR-AUC: 0.7042\n",
      "  Epoch 14 | Loss: 0.1798 | Val ROC-AUC: 0.9932 | Val PR-AUC: 0.7133\n",
      "  Epoch 15 | Loss: 0.1634 | Val ROC-AUC: 0.9903 | Val PR-AUC: 0.6847\n",
      "  Epoch 16 | Loss: 0.1540 | Val ROC-AUC: 0.9824 | Val PR-AUC: 0.6795\n",
      "  Epoch 17 | Loss: 0.1416 | Val ROC-AUC: 0.9885 | Val PR-AUC: 0.7087\n",
      "  Epoch 18 | Loss: 0.1373 | Val ROC-AUC: 0.9903 | Val PR-AUC: 0.6691\n",
      "Early stopping at epoch 19\n",
      "--> Best val PR-AUC for this trial: 0.7133\n",
      "\n",
      "=== Trial 3/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.001340\n",
      "  dropout     = 0.494\n",
      "  batch_size  = 1024\n",
      "  weight_decay= 1e-05\n",
      "  Epoch 01 | Loss: 0.9468 | Val ROC-AUC: 0.9690 | Val PR-AUC: 0.6898\n",
      "  Epoch 02 | Loss: 0.6650 | Val ROC-AUC: 0.9763 | Val PR-AUC: 0.6616\n",
      "  Epoch 03 | Loss: 0.5283 | Val ROC-AUC: 0.9791 | Val PR-AUC: 0.6798\n",
      "  Epoch 04 | Loss: 0.4438 | Val ROC-AUC: 0.9818 | Val PR-AUC: 0.6822\n",
      "  Epoch 05 | Loss: 0.3873 | Val ROC-AUC: 0.9825 | Val PR-AUC: 0.6979\n",
      "  Epoch 06 | Loss: 0.3755 | Val ROC-AUC: 0.9813 | Val PR-AUC: 0.6896\n",
      "  Epoch 07 | Loss: 0.3810 | Val ROC-AUC: 0.9822 | Val PR-AUC: 0.6685\n",
      "  Epoch 08 | Loss: 0.3639 | Val ROC-AUC: 0.9822 | Val PR-AUC: 0.7033\n",
      "  Epoch 09 | Loss: 0.3026 | Val ROC-AUC: 0.9825 | Val PR-AUC: 0.7021\n",
      "  Epoch 10 | Loss: 0.2741 | Val ROC-AUC: 0.9813 | Val PR-AUC: 0.7080\n",
      "  Epoch 11 | Loss: 0.3224 | Val ROC-AUC: 0.9824 | Val PR-AUC: 0.6924\n",
      "  Epoch 12 | Loss: 0.3033 | Val ROC-AUC: 0.9837 | Val PR-AUC: 0.7009\n",
      "  Epoch 13 | Loss: 0.2966 | Val ROC-AUC: 0.9836 | Val PR-AUC: 0.7072\n",
      "  Epoch 14 | Loss: 0.2858 | Val ROC-AUC: 0.9843 | Val PR-AUC: 0.7032\n",
      "Early stopping at epoch 15\n",
      "--> Best val PR-AUC for this trial: 0.7080\n",
      "\n",
      "=== Trial 4/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.002927\n",
      "  dropout     = 0.255\n",
      "  batch_size  = 512\n",
      "  weight_decay= 1e-05\n",
      "  Epoch 01 | Loss: 0.6211 | Val ROC-AUC: 0.9851 | Val PR-AUC: 0.6838\n",
      "  Epoch 02 | Loss: 0.3890 | Val ROC-AUC: 0.9814 | Val PR-AUC: 0.6154\n",
      "  Epoch 03 | Loss: 0.3328 | Val ROC-AUC: 0.9808 | Val PR-AUC: 0.6912\n",
      "  Epoch 04 | Loss: 0.2916 | Val ROC-AUC: 0.9812 | Val PR-AUC: 0.6657\n",
      "  Epoch 05 | Loss: 0.3060 | Val ROC-AUC: 0.9890 | Val PR-AUC: 0.6905\n",
      "  Epoch 06 | Loss: 0.2616 | Val ROC-AUC: 0.9891 | Val PR-AUC: 0.7028\n",
      "  Epoch 07 | Loss: 0.2391 | Val ROC-AUC: 0.9906 | Val PR-AUC: 0.6887\n",
      "  Epoch 08 | Loss: 0.2486 | Val ROC-AUC: 0.9838 | Val PR-AUC: 0.7071\n",
      "  Epoch 09 | Loss: 0.2190 | Val ROC-AUC: 0.9796 | Val PR-AUC: 0.6786\n",
      "  Epoch 10 | Loss: 0.2342 | Val ROC-AUC: 0.9863 | Val PR-AUC: 0.7025\n",
      "  Epoch 11 | Loss: 0.2394 | Val ROC-AUC: 0.9809 | Val PR-AUC: 0.6672\n",
      "  Epoch 12 | Loss: 0.2186 | Val ROC-AUC: 0.9907 | Val PR-AUC: 0.6895\n",
      "Early stopping at epoch 13\n",
      "--> Best val PR-AUC for this trial: 0.7071\n",
      "\n",
      "=== Trial 5/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.002737\n",
      "  dropout     = 0.149\n",
      "  batch_size  = 1024\n",
      "  weight_decay= 0.0001\n",
      "  Epoch 01 | Loss: 0.5473 | Val ROC-AUC: 0.9735 | Val PR-AUC: 0.6746\n",
      "  Epoch 02 | Loss: 0.3715 | Val ROC-AUC: 0.9781 | Val PR-AUC: 0.6295\n",
      "  Epoch 03 | Loss: 0.3083 | Val ROC-AUC: 0.9807 | Val PR-AUC: 0.6506\n",
      "  Epoch 04 | Loss: 0.2494 | Val ROC-AUC: 0.9788 | Val PR-AUC: 0.6840\n",
      "  Epoch 05 | Loss: 0.2173 | Val ROC-AUC: 0.9713 | Val PR-AUC: 0.6963\n",
      "  Epoch 06 | Loss: 0.1950 | Val ROC-AUC: 0.9812 | Val PR-AUC: 0.7057\n",
      "  Epoch 07 | Loss: 0.2108 | Val ROC-AUC: 0.9838 | Val PR-AUC: 0.6719\n",
      "  Epoch 08 | Loss: 0.1947 | Val ROC-AUC: 0.9859 | Val PR-AUC: 0.7068\n",
      "  Epoch 09 | Loss: 0.1882 | Val ROC-AUC: 0.9834 | Val PR-AUC: 0.6229\n",
      "  Epoch 10 | Loss: 0.1622 | Val ROC-AUC: 0.9806 | Val PR-AUC: 0.6642\n",
      "  Epoch 11 | Loss: 0.1719 | Val ROC-AUC: 0.9821 | Val PR-AUC: 0.7040\n",
      "  Epoch 12 | Loss: 0.1625 | Val ROC-AUC: 0.9811 | Val PR-AUC: 0.6841\n",
      "Early stopping at epoch 13\n",
      "--> Best val PR-AUC for this trial: 0.7068\n",
      "\n",
      "=== Trial 6/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000426\n",
      "  dropout     = 0.430\n",
      "  batch_size  = 512\n",
      "  weight_decay= 0.0001\n",
      "  Epoch 01 | Loss: 1.3112 | Val ROC-AUC: 0.9544 | Val PR-AUC: 0.6091\n",
      "  Epoch 02 | Loss: 0.9469 | Val ROC-AUC: 0.9700 | Val PR-AUC: 0.6641\n",
      "  Epoch 03 | Loss: 0.7548 | Val ROC-AUC: 0.9793 | Val PR-AUC: 0.6649\n",
      "  Epoch 04 | Loss: 0.6569 | Val ROC-AUC: 0.9780 | Val PR-AUC: 0.6688\n",
      "  Epoch 05 | Loss: 0.5822 | Val ROC-AUC: 0.9787 | Val PR-AUC: 0.6786\n",
      "  Epoch 06 | Loss: 0.5007 | Val ROC-AUC: 0.9784 | Val PR-AUC: 0.6734\n",
      "  Epoch 07 | Loss: 0.4956 | Val ROC-AUC: 0.9779 | Val PR-AUC: 0.6780\n",
      "  Epoch 08 | Loss: 0.4359 | Val ROC-AUC: 0.9797 | Val PR-AUC: 0.6760\n",
      "  Epoch 09 | Loss: 0.4409 | Val ROC-AUC: 0.9806 | Val PR-AUC: 0.6941\n",
      "  Epoch 10 | Loss: 0.4092 | Val ROC-AUC: 0.9819 | Val PR-AUC: 0.6805\n",
      "  Epoch 11 | Loss: 0.3515 | Val ROC-AUC: 0.9817 | Val PR-AUC: 0.6917\n",
      "  Epoch 12 | Loss: 0.3248 | Val ROC-AUC: 0.9827 | Val PR-AUC: 0.6940\n",
      "  Epoch 13 | Loss: 0.3373 | Val ROC-AUC: 0.9813 | Val PR-AUC: 0.6948\n",
      "  Epoch 14 | Loss: 0.3355 | Val ROC-AUC: 0.9821 | Val PR-AUC: 0.6756\n",
      "  Epoch 15 | Loss: 0.3347 | Val ROC-AUC: 0.9807 | Val PR-AUC: 0.7071\n",
      "  Epoch 16 | Loss: 0.3058 | Val ROC-AUC: 0.9818 | Val PR-AUC: 0.6978\n",
      "  Epoch 17 | Loss: 0.3102 | Val ROC-AUC: 0.9810 | Val PR-AUC: 0.6983\n",
      "  Epoch 18 | Loss: 0.2928 | Val ROC-AUC: 0.9821 | Val PR-AUC: 0.7019\n",
      "  Epoch 19 | Loss: 0.2930 | Val ROC-AUC: 0.9790 | Val PR-AUC: 0.7007\n",
      "Early stopping at epoch 20\n",
      "--> Best val PR-AUC for this trial: 0.7071\n",
      "\n",
      "=== Trial 7/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000104\n",
      "  dropout     = 0.125\n",
      "  batch_size  = 512\n",
      "  weight_decay= 1e-05\n",
      "  Epoch 01 | Loss: 1.0975 | Val ROC-AUC: 0.9392 | Val PR-AUC: 0.6212\n",
      "  Epoch 02 | Loss: 0.8260 | Val ROC-AUC: 0.9519 | Val PR-AUC: 0.6221\n",
      "  Epoch 03 | Loss: 0.7391 | Val ROC-AUC: 0.9566 | Val PR-AUC: 0.6150\n",
      "  Epoch 04 | Loss: 0.6899 | Val ROC-AUC: 0.9671 | Val PR-AUC: 0.6196\n",
      "  Epoch 05 | Loss: 0.6293 | Val ROC-AUC: 0.9690 | Val PR-AUC: 0.6326\n",
      "  Epoch 06 | Loss: 0.5750 | Val ROC-AUC: 0.9752 | Val PR-AUC: 0.6512\n",
      "  Epoch 07 | Loss: 0.5287 | Val ROC-AUC: 0.9782 | Val PR-AUC: 0.6545\n",
      "  Epoch 08 | Loss: 0.5001 | Val ROC-AUC: 0.9796 | Val PR-AUC: 0.6555\n",
      "  Epoch 09 | Loss: 0.4559 | Val ROC-AUC: 0.9795 | Val PR-AUC: 0.6620\n",
      "  Epoch 10 | Loss: 0.4120 | Val ROC-AUC: 0.9800 | Val PR-AUC: 0.6770\n",
      "  Epoch 11 | Loss: 0.3863 | Val ROC-AUC: 0.9808 | Val PR-AUC: 0.6571\n",
      "  Epoch 12 | Loss: 0.3646 | Val ROC-AUC: 0.9799 | Val PR-AUC: 0.6609\n",
      "  Epoch 13 | Loss: 0.3453 | Val ROC-AUC: 0.9810 | Val PR-AUC: 0.6729\n",
      "  Epoch 14 | Loss: 0.3294 | Val ROC-AUC: 0.9811 | Val PR-AUC: 0.6653\n",
      "  Epoch 15 | Loss: 0.2959 | Val ROC-AUC: 0.9825 | Val PR-AUC: 0.6951\n",
      "  Epoch 16 | Loss: 0.3011 | Val ROC-AUC: 0.9818 | Val PR-AUC: 0.6787\n",
      "  Epoch 17 | Loss: 0.2701 | Val ROC-AUC: 0.9824 | Val PR-AUC: 0.6753\n",
      "  Epoch 18 | Loss: 0.2480 | Val ROC-AUC: 0.9826 | Val PR-AUC: 0.6728\n",
      "  Epoch 19 | Loss: 0.2641 | Val ROC-AUC: 0.9826 | Val PR-AUC: 0.6677\n",
      "Early stopping at epoch 20\n",
      "--> Best val PR-AUC for this trial: 0.6951\n",
      "\n",
      "=== Trial 8/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000132\n",
      "  dropout     = 0.387\n",
      "  batch_size  = 1024\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 1.5034 | Val ROC-AUC: 0.9370 | Val PR-AUC: 0.4567\n",
      "  Epoch 02 | Loss: 1.1796 | Val ROC-AUC: 0.9547 | Val PR-AUC: 0.5895\n",
      "  Epoch 03 | Loss: 1.0786 | Val ROC-AUC: 0.9648 | Val PR-AUC: 0.6038\n",
      "  Epoch 04 | Loss: 0.9728 | Val ROC-AUC: 0.9615 | Val PR-AUC: 0.6539\n",
      "  Epoch 05 | Loss: 0.9434 | Val ROC-AUC: 0.9694 | Val PR-AUC: 0.6633\n",
      "  Epoch 06 | Loss: 0.9128 | Val ROC-AUC: 0.9706 | Val PR-AUC: 0.6793\n",
      "  Epoch 07 | Loss: 0.8885 | Val ROC-AUC: 0.9725 | Val PR-AUC: 0.6910\n",
      "  Epoch 08 | Loss: 0.8294 | Val ROC-AUC: 0.9751 | Val PR-AUC: 0.6910\n",
      "  Epoch 09 | Loss: 0.8182 | Val ROC-AUC: 0.9792 | Val PR-AUC: 0.6960\n",
      "  Epoch 10 | Loss: 0.8193 | Val ROC-AUC: 0.9777 | Val PR-AUC: 0.6550\n",
      "  Epoch 11 | Loss: 0.7450 | Val ROC-AUC: 0.9814 | Val PR-AUC: 0.6970\n",
      "  Epoch 12 | Loss: 0.7384 | Val ROC-AUC: 0.9805 | Val PR-AUC: 0.6956\n",
      "  Epoch 13 | Loss: 0.7076 | Val ROC-AUC: 0.9818 | Val PR-AUC: 0.6545\n",
      "  Epoch 14 | Loss: 0.6937 | Val ROC-AUC: 0.9811 | Val PR-AUC: 0.6516\n",
      "  Epoch 15 | Loss: 0.6604 | Val ROC-AUC: 0.9822 | Val PR-AUC: 0.6550\n",
      "Early stopping at epoch 16\n",
      "--> Best val PR-AUC for this trial: 0.6970\n",
      "\n",
      "=== Trial 9/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000614\n",
      "  dropout     = 0.103\n",
      "  batch_size  = 2048\n",
      "  weight_decay= 1e-05\n",
      "  Epoch 01 | Loss: 0.8129 | Val ROC-AUC: 0.9608 | Val PR-AUC: 0.5979\n",
      "  Epoch 02 | Loss: 0.6269 | Val ROC-AUC: 0.9698 | Val PR-AUC: 0.6188\n",
      "  Epoch 03 | Loss: 0.5331 | Val ROC-AUC: 0.9737 | Val PR-AUC: 0.6616\n",
      "  Epoch 04 | Loss: 0.4499 | Val ROC-AUC: 0.9807 | Val PR-AUC: 0.6742\n",
      "  Epoch 05 | Loss: 0.3925 | Val ROC-AUC: 0.9791 | Val PR-AUC: 0.6736\n",
      "  Epoch 06 | Loss: 0.3370 | Val ROC-AUC: 0.9851 | Val PR-AUC: 0.6828\n",
      "  Epoch 07 | Loss: 0.2746 | Val ROC-AUC: 0.9863 | Val PR-AUC: 0.6722\n",
      "  Epoch 08 | Loss: 0.2653 | Val ROC-AUC: 0.9891 | Val PR-AUC: 0.6796\n",
      "  Epoch 09 | Loss: 0.2236 | Val ROC-AUC: 0.9853 | Val PR-AUC: 0.6665\n",
      "  Epoch 10 | Loss: 0.2021 | Val ROC-AUC: 0.9878 | Val PR-AUC: 0.6874\n",
      "  Epoch 11 | Loss: 0.1788 | Val ROC-AUC: 0.9848 | Val PR-AUC: 0.6963\n",
      "  Epoch 12 | Loss: 0.1560 | Val ROC-AUC: 0.9787 | Val PR-AUC: 0.6933\n",
      "  Epoch 13 | Loss: 0.1790 | Val ROC-AUC: 0.9817 | Val PR-AUC: 0.7004\n",
      "  Epoch 14 | Loss: 0.1561 | Val ROC-AUC: 0.9780 | Val PR-AUC: 0.7110\n",
      "  Epoch 15 | Loss: 0.1655 | Val ROC-AUC: 0.9818 | Val PR-AUC: 0.6689\n",
      "  Epoch 16 | Loss: 0.1189 | Val ROC-AUC: 0.9839 | Val PR-AUC: 0.7095\n",
      "  Epoch 17 | Loss: 0.1226 | Val ROC-AUC: 0.9796 | Val PR-AUC: 0.6952\n",
      "  Epoch 18 | Loss: 0.1437 | Val ROC-AUC: 0.9803 | Val PR-AUC: 0.6775\n",
      "Early stopping at epoch 19\n",
      "--> Best val PR-AUC for this trial: 0.7110\n",
      "\n",
      "=== Trial 10/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000292\n",
      "  dropout     = 0.438\n",
      "  batch_size  = 2048\n",
      "  weight_decay= 0.0001\n",
      "  Epoch 01 | Loss: 1.2558 | Val ROC-AUC: 0.9324 | Val PR-AUC: 0.2977\n",
      "  Epoch 02 | Loss: 1.0319 | Val ROC-AUC: 0.9623 | Val PR-AUC: 0.4783\n",
      "  Epoch 03 | Loss: 0.9321 | Val ROC-AUC: 0.9676 | Val PR-AUC: 0.5534\n",
      "  Epoch 04 | Loss: 0.8599 | Val ROC-AUC: 0.9703 | Val PR-AUC: 0.5933\n",
      "  Epoch 05 | Loss: 0.8134 | Val ROC-AUC: 0.9748 | Val PR-AUC: 0.6215\n",
      "  Epoch 06 | Loss: 0.7813 | Val ROC-AUC: 0.9752 | Val PR-AUC: 0.6109\n",
      "  Epoch 07 | Loss: 0.7310 | Val ROC-AUC: 0.9756 | Val PR-AUC: 0.6207\n",
      "  Epoch 08 | Loss: 0.7007 | Val ROC-AUC: 0.9762 | Val PR-AUC: 0.6400\n",
      "  Epoch 09 | Loss: 0.6834 | Val ROC-AUC: 0.9759 | Val PR-AUC: 0.6537\n",
      "  Epoch 10 | Loss: 0.6420 | Val ROC-AUC: 0.9758 | Val PR-AUC: 0.6576\n",
      "  Epoch 11 | Loss: 0.6252 | Val ROC-AUC: 0.9761 | Val PR-AUC: 0.6729\n",
      "  Epoch 12 | Loss: 0.6038 | Val ROC-AUC: 0.9762 | Val PR-AUC: 0.6750\n",
      "  Epoch 13 | Loss: 0.5638 | Val ROC-AUC: 0.9777 | Val PR-AUC: 0.6765\n",
      "  Epoch 14 | Loss: 0.5664 | Val ROC-AUC: 0.9794 | Val PR-AUC: 0.6792\n",
      "  Epoch 15 | Loss: 0.5204 | Val ROC-AUC: 0.9791 | Val PR-AUC: 0.6770\n",
      "  Epoch 16 | Loss: 0.5457 | Val ROC-AUC: 0.9804 | Val PR-AUC: 0.6781\n",
      "  Epoch 17 | Loss: 0.4977 | Val ROC-AUC: 0.9798 | Val PR-AUC: 0.6731\n",
      "  Epoch 18 | Loss: 0.5066 | Val ROC-AUC: 0.9811 | Val PR-AUC: 0.6881\n",
      "  Epoch 19 | Loss: 0.4737 | Val ROC-AUC: 0.9815 | Val PR-AUC: 0.6883\n",
      "  Epoch 20 | Loss: 0.4564 | Val ROC-AUC: 0.9805 | Val PR-AUC: 0.6880\n",
      "  Epoch 21 | Loss: 0.4605 | Val ROC-AUC: 0.9803 | Val PR-AUC: 0.6882\n",
      "  Epoch 22 | Loss: 0.4409 | Val ROC-AUC: 0.9792 | Val PR-AUC: 0.6645\n",
      "  Epoch 23 | Loss: 0.4002 | Val ROC-AUC: 0.9795 | Val PR-AUC: 0.6952\n",
      "  Epoch 24 | Loss: 0.4232 | Val ROC-AUC: 0.9793 | Val PR-AUC: 0.6936\n",
      "  Epoch 25 | Loss: 0.4146 | Val ROC-AUC: 0.9801 | Val PR-AUC: 0.6928\n",
      "  Epoch 26 | Loss: 0.3871 | Val ROC-AUC: 0.9804 | Val PR-AUC: 0.6930\n",
      "  Epoch 27 | Loss: 0.3864 | Val ROC-AUC: 0.9815 | Val PR-AUC: 0.6638\n",
      "  Epoch 28 | Loss: 0.3635 | Val ROC-AUC: 0.9809 | Val PR-AUC: 0.6956\n",
      "  Epoch 29 | Loss: 0.3871 | Val ROC-AUC: 0.9821 | Val PR-AUC: 0.6955\n",
      "  Epoch 30 | Loss: 0.3453 | Val ROC-AUC: 0.9815 | Val PR-AUC: 0.6934\n",
      "  Epoch 31 | Loss: 0.3357 | Val ROC-AUC: 0.9819 | Val PR-AUC: 0.6902\n",
      "  Epoch 32 | Loss: 0.3416 | Val ROC-AUC: 0.9822 | Val PR-AUC: 0.6904\n",
      "  Epoch 33 | Loss: 0.3376 | Val ROC-AUC: 0.9822 | Val PR-AUC: 0.6993\n",
      "  Epoch 34 | Loss: 0.3347 | Val ROC-AUC: 0.9815 | Val PR-AUC: 0.7045\n",
      "  Epoch 35 | Loss: 0.3135 | Val ROC-AUC: 0.9820 | Val PR-AUC: 0.7012\n",
      "  Epoch 36 | Loss: 0.3114 | Val ROC-AUC: 0.9820 | Val PR-AUC: 0.7000\n",
      "  Epoch 37 | Loss: 0.3147 | Val ROC-AUC: 0.9823 | Val PR-AUC: 0.7080\n",
      "  Epoch 38 | Loss: 0.2939 | Val ROC-AUC: 0.9828 | Val PR-AUC: 0.6981\n",
      "  Epoch 39 | Loss: 0.3032 | Val ROC-AUC: 0.9819 | Val PR-AUC: 0.6998\n",
      "  Epoch 40 | Loss: 0.3023 | Val ROC-AUC: 0.9812 | Val PR-AUC: 0.7017\n",
      "  Epoch 41 | Loss: 0.2782 | Val ROC-AUC: 0.9810 | Val PR-AUC: 0.7073\n",
      "Early stopping at epoch 42\n",
      "--> Best val PR-AUC for this trial: 0.7080\n",
      "\n",
      "=== Trial 11/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000184\n",
      "  dropout     = 0.320\n",
      "  batch_size  = 512\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 1.3370 | Val ROC-AUC: 0.9600 | Val PR-AUC: 0.4819\n",
      "  Epoch 02 | Loss: 0.9767 | Val ROC-AUC: 0.9681 | Val PR-AUC: 0.5898\n",
      "  Epoch 03 | Loss: 0.8436 | Val ROC-AUC: 0.9730 | Val PR-AUC: 0.6458\n",
      "  Epoch 04 | Loss: 0.7474 | Val ROC-AUC: 0.9732 | Val PR-AUC: 0.6301\n",
      "  Epoch 05 | Loss: 0.6822 | Val ROC-AUC: 0.9764 | Val PR-AUC: 0.6422\n",
      "  Epoch 06 | Loss: 0.6112 | Val ROC-AUC: 0.9775 | Val PR-AUC: 0.6518\n",
      "  Epoch 07 | Loss: 0.5433 | Val ROC-AUC: 0.9780 | Val PR-AUC: 0.6758\n",
      "  Epoch 08 | Loss: 0.5200 | Val ROC-AUC: 0.9797 | Val PR-AUC: 0.6735\n",
      "  Epoch 09 | Loss: 0.4756 | Val ROC-AUC: 0.9801 | Val PR-AUC: 0.6735\n",
      "  Epoch 10 | Loss: 0.4436 | Val ROC-AUC: 0.9806 | Val PR-AUC: 0.6659\n",
      "  Epoch 11 | Loss: 0.4269 | Val ROC-AUC: 0.9802 | Val PR-AUC: 0.6623\n",
      "  Epoch 12 | Loss: 0.4037 | Val ROC-AUC: 0.9819 | Val PR-AUC: 0.6784\n",
      "  Epoch 13 | Loss: 0.3656 | Val ROC-AUC: 0.9817 | Val PR-AUC: 0.6891\n",
      "  Epoch 14 | Loss: 0.3715 | Val ROC-AUC: 0.9815 | Val PR-AUC: 0.6955\n",
      "  Epoch 15 | Loss: 0.3298 | Val ROC-AUC: 0.9827 | Val PR-AUC: 0.6802\n",
      "  Epoch 16 | Loss: 0.3310 | Val ROC-AUC: 0.9828 | Val PR-AUC: 0.6940\n",
      "  Epoch 17 | Loss: 0.3107 | Val ROC-AUC: 0.9837 | Val PR-AUC: 0.6799\n",
      "  Epoch 18 | Loss: 0.3219 | Val ROC-AUC: 0.9836 | Val PR-AUC: 0.6952\n",
      "  Epoch 19 | Loss: 0.3213 | Val ROC-AUC: 0.9829 | Val PR-AUC: 0.6986\n",
      "  Epoch 20 | Loss: 0.3325 | Val ROC-AUC: 0.9836 | Val PR-AUC: 0.6764\n",
      "  Epoch 21 | Loss: 0.2954 | Val ROC-AUC: 0.9844 | Val PR-AUC: 0.7049\n",
      "  Epoch 22 | Loss: 0.2653 | Val ROC-AUC: 0.9853 | Val PR-AUC: 0.7026\n",
      "  Epoch 23 | Loss: 0.2534 | Val ROC-AUC: 0.9847 | Val PR-AUC: 0.6929\n",
      "  Epoch 24 | Loss: 0.3148 | Val ROC-AUC: 0.9854 | Val PR-AUC: 0.6958\n",
      "  Epoch 25 | Loss: 0.2611 | Val ROC-AUC: 0.9854 | Val PR-AUC: 0.7068\n",
      "  Epoch 26 | Loss: 0.2627 | Val ROC-AUC: 0.9852 | Val PR-AUC: 0.6866\n",
      "  Epoch 27 | Loss: 0.2681 | Val ROC-AUC: 0.9851 | Val PR-AUC: 0.6832\n",
      "  Epoch 28 | Loss: 0.2755 | Val ROC-AUC: 0.9849 | Val PR-AUC: 0.6887\n",
      "  Epoch 29 | Loss: 0.2606 | Val ROC-AUC: 0.9855 | Val PR-AUC: 0.7070\n",
      "  Epoch 30 | Loss: 0.2313 | Val ROC-AUC: 0.9847 | Val PR-AUC: 0.6950\n",
      "  Epoch 31 | Loss: 0.2621 | Val ROC-AUC: 0.9867 | Val PR-AUC: 0.6966\n",
      "  Epoch 32 | Loss: 0.2226 | Val ROC-AUC: 0.9857 | Val PR-AUC: 0.6929\n",
      "  Epoch 33 | Loss: 0.2192 | Val ROC-AUC: 0.9848 | Val PR-AUC: 0.7042\n",
      "  Epoch 34 | Loss: 0.2182 | Val ROC-AUC: 0.9852 | Val PR-AUC: 0.7104\n",
      "  Epoch 35 | Loss: 0.2311 | Val ROC-AUC: 0.9846 | Val PR-AUC: 0.7125\n",
      "  Epoch 36 | Loss: 0.2107 | Val ROC-AUC: 0.9848 | Val PR-AUC: 0.7015\n",
      "  Epoch 37 | Loss: 0.2284 | Val ROC-AUC: 0.9825 | Val PR-AUC: 0.7005\n",
      "  Epoch 38 | Loss: 0.2410 | Val ROC-AUC: 0.9844 | Val PR-AUC: 0.7045\n",
      "  Epoch 39 | Loss: 0.1941 | Val ROC-AUC: 0.9836 | Val PR-AUC: 0.6911\n",
      "Early stopping at epoch 40\n",
      "--> Best val PR-AUC for this trial: 0.7125\n",
      "\n",
      "=== Trial 12/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000155\n",
      "  dropout     = 0.139\n",
      "  batch_size  = 2048\n",
      "  weight_decay= 0.0001\n",
      "  Epoch 01 | Loss: 1.2872 | Val ROC-AUC: 0.9216 | Val PR-AUC: 0.6318\n",
      "  Epoch 02 | Loss: 0.9230 | Val ROC-AUC: 0.9490 | Val PR-AUC: 0.6560\n",
      "  Epoch 03 | Loss: 0.8220 | Val ROC-AUC: 0.9551 | Val PR-AUC: 0.6563\n",
      "  Epoch 04 | Loss: 0.7868 | Val ROC-AUC: 0.9589 | Val PR-AUC: 0.6603\n",
      "  Epoch 05 | Loss: 0.7657 | Val ROC-AUC: 0.9617 | Val PR-AUC: 0.6556\n",
      "  Epoch 06 | Loss: 0.7254 | Val ROC-AUC: 0.9634 | Val PR-AUC: 0.6627\n",
      "  Epoch 07 | Loss: 0.7030 | Val ROC-AUC: 0.9615 | Val PR-AUC: 0.6685\n",
      "  Epoch 08 | Loss: 0.6740 | Val ROC-AUC: 0.9635 | Val PR-AUC: 0.6476\n",
      "  Epoch 09 | Loss: 0.6574 | Val ROC-AUC: 0.9668 | Val PR-AUC: 0.6442\n",
      "  Epoch 10 | Loss: 0.6251 | Val ROC-AUC: 0.9668 | Val PR-AUC: 0.6344\n",
      "  Epoch 11 | Loss: 0.6044 | Val ROC-AUC: 0.9677 | Val PR-AUC: 0.6385\n",
      "Early stopping at epoch 12\n",
      "--> Best val PR-AUC for this trial: 0.6685\n",
      "\n",
      "=== Trial 13/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.001076\n",
      "  dropout     = 0.354\n",
      "  batch_size  = 2048\n",
      "  weight_decay= 1e-05\n",
      "  Epoch 01 | Loss: 0.8732 | Val ROC-AUC: 0.9697 | Val PR-AUC: 0.6426\n",
      "  Epoch 02 | Loss: 0.6672 | Val ROC-AUC: 0.9722 | Val PR-AUC: 0.6579\n",
      "  Epoch 03 | Loss: 0.5495 | Val ROC-AUC: 0.9676 | Val PR-AUC: 0.6734\n",
      "  Epoch 04 | Loss: 0.5010 | Val ROC-AUC: 0.9807 | Val PR-AUC: 0.6843\n",
      "  Epoch 05 | Loss: 0.4297 | Val ROC-AUC: 0.9814 | Val PR-AUC: 0.6932\n",
      "  Epoch 06 | Loss: 0.3736 | Val ROC-AUC: 0.9872 | Val PR-AUC: 0.6958\n",
      "  Epoch 07 | Loss: 0.3540 | Val ROC-AUC: 0.9891 | Val PR-AUC: 0.6870\n",
      "  Epoch 08 | Loss: 0.3092 | Val ROC-AUC: 0.9899 | Val PR-AUC: 0.6835\n",
      "  Epoch 09 | Loss: 0.2969 | Val ROC-AUC: 0.9903 | Val PR-AUC: 0.6968\n",
      "  Epoch 10 | Loss: 0.2959 | Val ROC-AUC: 0.9881 | Val PR-AUC: 0.6740\n",
      "  Epoch 11 | Loss: 0.2862 | Val ROC-AUC: 0.9902 | Val PR-AUC: 0.7051\n",
      "  Epoch 12 | Loss: 0.2513 | Val ROC-AUC: 0.9863 | Val PR-AUC: 0.6981\n",
      "  Epoch 13 | Loss: 0.2422 | Val ROC-AUC: 0.9911 | Val PR-AUC: 0.7000\n",
      "  Epoch 14 | Loss: 0.2111 | Val ROC-AUC: 0.9904 | Val PR-AUC: 0.6957\n",
      "  Epoch 15 | Loss: 0.2517 | Val ROC-AUC: 0.9895 | Val PR-AUC: 0.7078\n",
      "  Epoch 16 | Loss: 0.1953 | Val ROC-AUC: 0.9868 | Val PR-AUC: 0.7148\n",
      "  Epoch 17 | Loss: 0.2054 | Val ROC-AUC: 0.9868 | Val PR-AUC: 0.7032\n",
      "  Epoch 18 | Loss: 0.2102 | Val ROC-AUC: 0.9922 | Val PR-AUC: 0.7056\n",
      "  Epoch 19 | Loss: 0.2439 | Val ROC-AUC: 0.9923 | Val PR-AUC: 0.6890\n",
      "  Epoch 20 | Loss: 0.2070 | Val ROC-AUC: 0.9928 | Val PR-AUC: 0.7060\n",
      "Early stopping at epoch 21\n",
      "--> Best val PR-AUC for this trial: 0.7148\n",
      "\n",
      "=== Trial 14/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000222\n",
      "  dropout     = 0.193\n",
      "  batch_size  = 512\n",
      "  weight_decay= 0.0001\n",
      "  Epoch 01 | Loss: 1.0878 | Val ROC-AUC: 0.9718 | Val PR-AUC: 0.6677\n",
      "  Epoch 02 | Loss: 0.7938 | Val ROC-AUC: 0.9762 | Val PR-AUC: 0.6903\n",
      "  Epoch 03 | Loss: 0.6719 | Val ROC-AUC: 0.9847 | Val PR-AUC: 0.7013\n",
      "  Epoch 04 | Loss: 0.5810 | Val ROC-AUC: 0.9848 | Val PR-AUC: 0.6532\n",
      "  Epoch 05 | Loss: 0.4995 | Val ROC-AUC: 0.9884 | Val PR-AUC: 0.7035\n",
      "  Epoch 06 | Loss: 0.4574 | Val ROC-AUC: 0.9874 | Val PR-AUC: 0.6917\n",
      "  Epoch 07 | Loss: 0.3949 | Val ROC-AUC: 0.9871 | Val PR-AUC: 0.6926\n",
      "  Epoch 08 | Loss: 0.3777 | Val ROC-AUC: 0.9889 | Val PR-AUC: 0.6994\n",
      "  Epoch 09 | Loss: 0.3454 | Val ROC-AUC: 0.9862 | Val PR-AUC: 0.6868\n",
      "Early stopping at epoch 10\n",
      "--> Best val PR-AUC for this trial: 0.7035\n",
      "\n",
      "=== Trial 15/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.002326\n",
      "  dropout     = 0.198\n",
      "  batch_size  = 2048\n",
      "  weight_decay= 0.0001\n",
      "  Epoch 01 | Loss: 0.7481 | Val ROC-AUC: 0.9769 | Val PR-AUC: 0.6780\n",
      "  Epoch 02 | Loss: 0.4850 | Val ROC-AUC: 0.9745 | Val PR-AUC: 0.6484\n",
      "  Epoch 03 | Loss: 0.3454 | Val ROC-AUC: 0.9756 | Val PR-AUC: 0.6785\n",
      "  Epoch 04 | Loss: 0.2994 | Val ROC-AUC: 0.9774 | Val PR-AUC: 0.6998\n",
      "  Epoch 05 | Loss: 0.2474 | Val ROC-AUC: 0.9784 | Val PR-AUC: 0.6643\n",
      "  Epoch 06 | Loss: 0.2370 | Val ROC-AUC: 0.9781 | Val PR-AUC: 0.6867\n",
      "  Epoch 07 | Loss: 0.2190 | Val ROC-AUC: 0.9794 | Val PR-AUC: 0.6623\n",
      "  Epoch 08 | Loss: 0.2024 | Val ROC-AUC: 0.9774 | Val PR-AUC: 0.6931\n",
      "Early stopping at epoch 9\n",
      "--> Best val PR-AUC for this trial: 0.6998\n",
      "\n",
      "=== Trial 16/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000227\n",
      "  dropout     = 0.217\n",
      "  batch_size  = 512\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 1.1591 | Val ROC-AUC: 0.9567 | Val PR-AUC: 0.6871\n",
      "  Epoch 02 | Loss: 0.7625 | Val ROC-AUC: 0.9689 | Val PR-AUC: 0.7085\n",
      "  Epoch 03 | Loss: 0.6672 | Val ROC-AUC: 0.9738 | Val PR-AUC: 0.7140\n",
      "  Epoch 04 | Loss: 0.6007 | Val ROC-AUC: 0.9783 | Val PR-AUC: 0.6552\n",
      "  Epoch 05 | Loss: 0.5480 | Val ROC-AUC: 0.9776 | Val PR-AUC: 0.6668\n",
      "  Epoch 06 | Loss: 0.5059 | Val ROC-AUC: 0.9786 | Val PR-AUC: 0.6735\n",
      "  Epoch 07 | Loss: 0.4501 | Val ROC-AUC: 0.9772 | Val PR-AUC: 0.6705\n",
      "Early stopping at epoch 8\n",
      "--> Best val PR-AUC for this trial: 0.7140\n",
      "\n",
      "=== Trial 17/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.001111\n",
      "  dropout     = 0.385\n",
      "  batch_size  = 1024\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 0.8609 | Val ROC-AUC: 0.9652 | Val PR-AUC: 0.6545\n",
      "  Epoch 02 | Loss: 0.6149 | Val ROC-AUC: 0.9854 | Val PR-AUC: 0.6699\n",
      "  Epoch 03 | Loss: 0.4759 | Val ROC-AUC: 0.9879 | Val PR-AUC: 0.6822\n",
      "  Epoch 04 | Loss: 0.3966 | Val ROC-AUC: 0.9862 | Val PR-AUC: 0.6662\n",
      "  Epoch 05 | Loss: 0.3786 | Val ROC-AUC: 0.9846 | Val PR-AUC: 0.6890\n",
      "  Epoch 06 | Loss: 0.3467 | Val ROC-AUC: 0.9798 | Val PR-AUC: 0.6920\n",
      "  Epoch 07 | Loss: 0.3025 | Val ROC-AUC: 0.9852 | Val PR-AUC: 0.6995\n",
      "  Epoch 08 | Loss: 0.3035 | Val ROC-AUC: 0.9846 | Val PR-AUC: 0.6989\n",
      "  Epoch 09 | Loss: 0.2706 | Val ROC-AUC: 0.9888 | Val PR-AUC: 0.6838\n",
      "  Epoch 10 | Loss: 0.2713 | Val ROC-AUC: 0.9905 | Val PR-AUC: 0.6936\n",
      "  Epoch 11 | Loss: 0.2533 | Val ROC-AUC: 0.9886 | Val PR-AUC: 0.7021\n",
      "  Epoch 12 | Loss: 0.2601 | Val ROC-AUC: 0.9827 | Val PR-AUC: 0.7014\n",
      "  Epoch 13 | Loss: 0.2489 | Val ROC-AUC: 0.9825 | Val PR-AUC: 0.6864\n",
      "  Epoch 14 | Loss: 0.2545 | Val ROC-AUC: 0.9767 | Val PR-AUC: 0.6974\n",
      "  Epoch 15 | Loss: 0.2347 | Val ROC-AUC: 0.9716 | Val PR-AUC: 0.6958\n",
      "Early stopping at epoch 16\n",
      "--> Best val PR-AUC for this trial: 0.7021\n",
      "\n",
      "=== Trial 18/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000152\n",
      "  dropout     = 0.361\n",
      "  batch_size  = 2048\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 1.6305 | Val ROC-AUC: 0.9156 | Val PR-AUC: 0.3494\n",
      "  Epoch 02 | Loss: 1.3307 | Val ROC-AUC: 0.9447 | Val PR-AUC: 0.5911\n",
      "  Epoch 03 | Loss: 1.1674 | Val ROC-AUC: 0.9450 | Val PR-AUC: 0.6060\n",
      "  Epoch 04 | Loss: 1.0172 | Val ROC-AUC: 0.9608 | Val PR-AUC: 0.6088\n",
      "  Epoch 05 | Loss: 0.9507 | Val ROC-AUC: 0.9614 | Val PR-AUC: 0.6448\n",
      "  Epoch 06 | Loss: 0.9062 | Val ROC-AUC: 0.9673 | Val PR-AUC: 0.6618\n",
      "  Epoch 07 | Loss: 0.8947 | Val ROC-AUC: 0.9677 | Val PR-AUC: 0.6659\n",
      "  Epoch 08 | Loss: 0.8371 | Val ROC-AUC: 0.9701 | Val PR-AUC: 0.6777\n",
      "  Epoch 09 | Loss: 0.8315 | Val ROC-AUC: 0.9734 | Val PR-AUC: 0.6805\n",
      "  Epoch 10 | Loss: 0.8178 | Val ROC-AUC: 0.9735 | Val PR-AUC: 0.6779\n",
      "  Epoch 11 | Loss: 0.7681 | Val ROC-AUC: 0.9713 | Val PR-AUC: 0.6876\n",
      "  Epoch 12 | Loss: 0.7672 | Val ROC-AUC: 0.9793 | Val PR-AUC: 0.6913\n",
      "  Epoch 13 | Loss: 0.7659 | Val ROC-AUC: 0.9798 | Val PR-AUC: 0.6820\n",
      "  Epoch 14 | Loss: 0.7406 | Val ROC-AUC: 0.9804 | Val PR-AUC: 0.6948\n",
      "  Epoch 15 | Loss: 0.7104 | Val ROC-AUC: 0.9814 | Val PR-AUC: 0.6884\n",
      "  Epoch 16 | Loss: 0.7085 | Val ROC-AUC: 0.9806 | Val PR-AUC: 0.6802\n",
      "  Epoch 17 | Loss: 0.6775 | Val ROC-AUC: 0.9840 | Val PR-AUC: 0.6900\n",
      "  Epoch 18 | Loss: 0.6816 | Val ROC-AUC: 0.9838 | Val PR-AUC: 0.6711\n",
      "  Epoch 19 | Loss: 0.6372 | Val ROC-AUC: 0.9815 | Val PR-AUC: 0.6949\n",
      "  Epoch 20 | Loss: 0.6333 | Val ROC-AUC: 0.9825 | Val PR-AUC: 0.6679\n",
      "  Epoch 21 | Loss: 0.6322 | Val ROC-AUC: 0.9849 | Val PR-AUC: 0.6758\n",
      "  Epoch 22 | Loss: 0.6057 | Val ROC-AUC: 0.9836 | Val PR-AUC: 0.6947\n",
      "  Epoch 23 | Loss: 0.5917 | Val ROC-AUC: 0.9838 | Val PR-AUC: 0.6960\n",
      "  Epoch 24 | Loss: 0.5914 | Val ROC-AUC: 0.9837 | Val PR-AUC: 0.6760\n",
      "  Epoch 25 | Loss: 0.5591 | Val ROC-AUC: 0.9840 | Val PR-AUC: 0.6734\n",
      "  Epoch 26 | Loss: 0.5696 | Val ROC-AUC: 0.9850 | Val PR-AUC: 0.6590\n",
      "  Epoch 27 | Loss: 0.5518 | Val ROC-AUC: 0.9844 | Val PR-AUC: 0.6645\n",
      "Early stopping at epoch 28\n",
      "--> Best val PR-AUC for this trial: 0.6960\n",
      "\n",
      "=== Trial 19/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000124\n",
      "  dropout     = 0.317\n",
      "  batch_size  = 1024\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 1.3542 | Val ROC-AUC: 0.9531 | Val PR-AUC: 0.3627\n",
      "  Epoch 02 | Loss: 1.0737 | Val ROC-AUC: 0.9644 | Val PR-AUC: 0.4491\n",
      "  Epoch 03 | Loss: 0.9205 | Val ROC-AUC: 0.9689 | Val PR-AUC: 0.5728\n",
      "  Epoch 04 | Loss: 0.8540 | Val ROC-AUC: 0.9751 | Val PR-AUC: 0.6043\n",
      "  Epoch 05 | Loss: 0.7913 | Val ROC-AUC: 0.9760 | Val PR-AUC: 0.6186\n",
      "  Epoch 06 | Loss: 0.7594 | Val ROC-AUC: 0.9774 | Val PR-AUC: 0.6457\n",
      "  Epoch 07 | Loss: 0.7163 | Val ROC-AUC: 0.9781 | Val PR-AUC: 0.6582\n",
      "  Epoch 08 | Loss: 0.6859 | Val ROC-AUC: 0.9792 | Val PR-AUC: 0.6394\n",
      "  Epoch 09 | Loss: 0.6653 | Val ROC-AUC: 0.9806 | Val PR-AUC: 0.6246\n",
      "  Epoch 10 | Loss: 0.6199 | Val ROC-AUC: 0.9800 | Val PR-AUC: 0.6519\n",
      "  Epoch 11 | Loss: 0.6110 | Val ROC-AUC: 0.9794 | Val PR-AUC: 0.6387\n",
      "Early stopping at epoch 12\n",
      "--> Best val PR-AUC for this trial: 0.6582\n",
      "\n",
      "=== Trial 20/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000401\n",
      "  dropout     = 0.130\n",
      "  batch_size  = 512\n",
      "  weight_decay= 1e-05\n",
      "  Epoch 01 | Loss: 0.7803 | Val ROC-AUC: 0.9879 | Val PR-AUC: 0.6363\n",
      "  Epoch 02 | Loss: 0.5364 | Val ROC-AUC: 0.9852 | Val PR-AUC: 0.6564\n",
      "  Epoch 03 | Loss: 0.4214 | Val ROC-AUC: 0.9862 | Val PR-AUC: 0.6606\n",
      "  Epoch 04 | Loss: 0.3481 | Val ROC-AUC: 0.9861 | Val PR-AUC: 0.6702\n",
      "  Epoch 05 | Loss: 0.3018 | Val ROC-AUC: 0.9846 | Val PR-AUC: 0.6850\n",
      "  Epoch 06 | Loss: 0.2855 | Val ROC-AUC: 0.9863 | Val PR-AUC: 0.6972\n",
      "  Epoch 07 | Loss: 0.2366 | Val ROC-AUC: 0.9883 | Val PR-AUC: 0.6936\n",
      "  Epoch 08 | Loss: 0.2357 | Val ROC-AUC: 0.9876 | Val PR-AUC: 0.6784\n",
      "  Epoch 09 | Loss: 0.2098 | Val ROC-AUC: 0.9889 | Val PR-AUC: 0.6707\n",
      "  Epoch 10 | Loss: 0.2102 | Val ROC-AUC: 0.9885 | Val PR-AUC: 0.6813\n",
      "Early stopping at epoch 11\n",
      "--> Best val PR-AUC for this trial: 0.6972\n",
      "\n",
      "=== Trial 21/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000208\n",
      "  dropout     = 0.262\n",
      "  batch_size  = 2048\n",
      "  weight_decay= 1e-05\n",
      "  Epoch 01 | Loss: 1.0968 | Val ROC-AUC: 0.9347 | Val PR-AUC: 0.6936\n",
      "  Epoch 02 | Loss: 0.8248 | Val ROC-AUC: 0.9471 | Val PR-AUC: 0.6847\n",
      "  Epoch 03 | Loss: 0.7893 | Val ROC-AUC: 0.9574 | Val PR-AUC: 0.6548\n",
      "  Epoch 04 | Loss: 0.7297 | Val ROC-AUC: 0.9667 | Val PR-AUC: 0.6122\n",
      "  Epoch 05 | Loss: 0.6972 | Val ROC-AUC: 0.9705 | Val PR-AUC: 0.6163\n",
      "Early stopping at epoch 6\n",
      "--> Best val PR-AUC for this trial: 0.6936\n",
      "\n",
      "=== Trial 22/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000130\n",
      "  dropout     = 0.203\n",
      "  batch_size  = 2048\n",
      "  weight_decay= 1e-05\n",
      "  Epoch 01 | Loss: 1.1034 | Val ROC-AUC: 0.9609 | Val PR-AUC: 0.3098\n",
      "  Epoch 02 | Loss: 0.9317 | Val ROC-AUC: 0.9691 | Val PR-AUC: 0.4451\n",
      "  Epoch 03 | Loss: 0.8616 | Val ROC-AUC: 0.9680 | Val PR-AUC: 0.5471\n",
      "  Epoch 04 | Loss: 0.8262 | Val ROC-AUC: 0.9731 | Val PR-AUC: 0.5959\n",
      "  Epoch 05 | Loss: 0.7844 | Val ROC-AUC: 0.9742 | Val PR-AUC: 0.6273\n",
      "  Epoch 06 | Loss: 0.7690 | Val ROC-AUC: 0.9718 | Val PR-AUC: 0.6389\n",
      "  Epoch 07 | Loss: 0.7468 | Val ROC-AUC: 0.9723 | Val PR-AUC: 0.6667\n",
      "  Epoch 08 | Loss: 0.7132 | Val ROC-AUC: 0.9744 | Val PR-AUC: 0.6697\n",
      "  Epoch 09 | Loss: 0.6843 | Val ROC-AUC: 0.9745 | Val PR-AUC: 0.6748\n",
      "  Epoch 10 | Loss: 0.6624 | Val ROC-AUC: 0.9762 | Val PR-AUC: 0.6792\n",
      "  Epoch 11 | Loss: 0.6365 | Val ROC-AUC: 0.9782 | Val PR-AUC: 0.6870\n",
      "  Epoch 12 | Loss: 0.6166 | Val ROC-AUC: 0.9802 | Val PR-AUC: 0.6690\n",
      "  Epoch 13 | Loss: 0.6072 | Val ROC-AUC: 0.9819 | Val PR-AUC: 0.6705\n",
      "  Epoch 14 | Loss: 0.5695 | Val ROC-AUC: 0.9803 | Val PR-AUC: 0.6918\n",
      "  Epoch 15 | Loss: 0.5551 | Val ROC-AUC: 0.9813 | Val PR-AUC: 0.6747\n",
      "  Epoch 16 | Loss: 0.5418 | Val ROC-AUC: 0.9820 | Val PR-AUC: 0.6767\n",
      "  Epoch 17 | Loss: 0.5210 | Val ROC-AUC: 0.9808 | Val PR-AUC: 0.6757\n",
      "  Epoch 18 | Loss: 0.4937 | Val ROC-AUC: 0.9805 | Val PR-AUC: 0.6659\n",
      "Early stopping at epoch 19\n",
      "--> Best val PR-AUC for this trial: 0.6918\n",
      "\n",
      "=== Trial 23/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000114\n",
      "  dropout     = 0.354\n",
      "  batch_size  = 2048\n",
      "  weight_decay= 1e-05\n",
      "  Epoch 01 | Loss: 1.9012 | Val ROC-AUC: 0.9128 | Val PR-AUC: 0.1324\n",
      "  Epoch 02 | Loss: 1.4069 | Val ROC-AUC: 0.9401 | Val PR-AUC: 0.3455\n",
      "  Epoch 03 | Loss: 1.2204 | Val ROC-AUC: 0.9421 | Val PR-AUC: 0.4115\n",
      "  Epoch 04 | Loss: 1.0828 | Val ROC-AUC: 0.9477 | Val PR-AUC: 0.4764\n",
      "  Epoch 05 | Loss: 1.0545 | Val ROC-AUC: 0.9461 | Val PR-AUC: 0.5037\n",
      "  Epoch 06 | Loss: 0.9352 | Val ROC-AUC: 0.9464 | Val PR-AUC: 0.5265\n",
      "  Epoch 07 | Loss: 0.9283 | Val ROC-AUC: 0.9507 | Val PR-AUC: 0.5895\n",
      "  Epoch 08 | Loss: 0.8903 | Val ROC-AUC: 0.9515 | Val PR-AUC: 0.6054\n",
      "  Epoch 09 | Loss: 0.8629 | Val ROC-AUC: 0.9524 | Val PR-AUC: 0.6214\n",
      "  Epoch 10 | Loss: 0.8449 | Val ROC-AUC: 0.9537 | Val PR-AUC: 0.6290\n",
      "  Epoch 11 | Loss: 0.8224 | Val ROC-AUC: 0.9576 | Val PR-AUC: 0.6364\n",
      "  Epoch 12 | Loss: 0.8100 | Val ROC-AUC: 0.9619 | Val PR-AUC: 0.6437\n",
      "  Epoch 13 | Loss: 0.7775 | Val ROC-AUC: 0.9642 | Val PR-AUC: 0.6506\n",
      "  Epoch 14 | Loss: 0.7605 | Val ROC-AUC: 0.9668 | Val PR-AUC: 0.6401\n",
      "  Epoch 15 | Loss: 0.7486 | Val ROC-AUC: 0.9667 | Val PR-AUC: 0.6336\n",
      "  Epoch 16 | Loss: 0.7099 | Val ROC-AUC: 0.9658 | Val PR-AUC: 0.6526\n",
      "  Epoch 17 | Loss: 0.7012 | Val ROC-AUC: 0.9674 | Val PR-AUC: 0.6514\n",
      "  Epoch 18 | Loss: 0.6880 | Val ROC-AUC: 0.9730 | Val PR-AUC: 0.6453\n",
      "  Epoch 19 | Loss: 0.6961 | Val ROC-AUC: 0.9687 | Val PR-AUC: 0.6559\n",
      "  Epoch 20 | Loss: 0.6719 | Val ROC-AUC: 0.9730 | Val PR-AUC: 0.6436\n",
      "  Epoch 21 | Loss: 0.6644 | Val ROC-AUC: 0.9750 | Val PR-AUC: 0.6405\n",
      "  Epoch 22 | Loss: 0.6283 | Val ROC-AUC: 0.9767 | Val PR-AUC: 0.6456\n",
      "  Epoch 23 | Loss: 0.6186 | Val ROC-AUC: 0.9782 | Val PR-AUC: 0.6497\n",
      "Early stopping at epoch 24\n",
      "--> Best val PR-AUC for this trial: 0.6559\n",
      "\n",
      "=== Trial 24/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000182\n",
      "  dropout     = 0.467\n",
      "  batch_size  = 1024\n",
      "  weight_decay= 1e-05\n",
      "  Epoch 01 | Loss: 1.4158 | Val ROC-AUC: 0.9426 | Val PR-AUC: 0.2011\n",
      "  Epoch 02 | Loss: 1.0521 | Val ROC-AUC: 0.9594 | Val PR-AUC: 0.3827\n",
      "  Epoch 03 | Loss: 0.9570 | Val ROC-AUC: 0.9604 | Val PR-AUC: 0.5362\n",
      "  Epoch 04 | Loss: 0.8756 | Val ROC-AUC: 0.9561 | Val PR-AUC: 0.5945\n",
      "  Epoch 05 | Loss: 0.8290 | Val ROC-AUC: 0.9609 | Val PR-AUC: 0.6225\n",
      "  Epoch 06 | Loss: 0.7820 | Val ROC-AUC: 0.9543 | Val PR-AUC: 0.6438\n",
      "  Epoch 07 | Loss: 0.7633 | Val ROC-AUC: 0.9750 | Val PR-AUC: 0.6198\n",
      "  Epoch 08 | Loss: 0.7131 | Val ROC-AUC: 0.9692 | Val PR-AUC: 0.6628\n",
      "  Epoch 09 | Loss: 0.7023 | Val ROC-AUC: 0.9732 | Val PR-AUC: 0.6343\n",
      "  Epoch 10 | Loss: 0.6800 | Val ROC-AUC: 0.9746 | Val PR-AUC: 0.6474\n",
      "  Epoch 11 | Loss: 0.6791 | Val ROC-AUC: 0.9800 | Val PR-AUC: 0.6634\n",
      "  Epoch 12 | Loss: 0.6272 | Val ROC-AUC: 0.9797 | Val PR-AUC: 0.6671\n",
      "  Epoch 13 | Loss: 0.6079 | Val ROC-AUC: 0.9805 | Val PR-AUC: 0.6787\n",
      "  Epoch 14 | Loss: 0.5949 | Val ROC-AUC: 0.9783 | Val PR-AUC: 0.6673\n",
      "  Epoch 15 | Loss: 0.5730 | Val ROC-AUC: 0.9820 | Val PR-AUC: 0.6712\n",
      "  Epoch 16 | Loss: 0.5432 | Val ROC-AUC: 0.9802 | Val PR-AUC: 0.6861\n",
      "  Epoch 17 | Loss: 0.5381 | Val ROC-AUC: 0.9793 | Val PR-AUC: 0.6890\n",
      "  Epoch 18 | Loss: 0.5208 | Val ROC-AUC: 0.9804 | Val PR-AUC: 0.6866\n",
      "  Epoch 19 | Loss: 0.5292 | Val ROC-AUC: 0.9803 | Val PR-AUC: 0.6973\n",
      "  Epoch 20 | Loss: 0.5192 | Val ROC-AUC: 0.9802 | Val PR-AUC: 0.6870\n",
      "  Epoch 21 | Loss: 0.4907 | Val ROC-AUC: 0.9798 | Val PR-AUC: 0.6836\n",
      "  Epoch 22 | Loss: 0.4642 | Val ROC-AUC: 0.9801 | Val PR-AUC: 0.6881\n",
      "  Epoch 23 | Loss: 0.4709 | Val ROC-AUC: 0.9815 | Val PR-AUC: 0.6972\n",
      "Early stopping at epoch 24\n",
      "--> Best val PR-AUC for this trial: 0.6973\n",
      "\n",
      "=== Trial 25/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000209\n",
      "  dropout     = 0.475\n",
      "  batch_size  = 512\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 1.1563 | Val ROC-AUC: 0.9481 | Val PR-AUC: 0.5435\n",
      "  Epoch 02 | Loss: 0.9784 | Val ROC-AUC: 0.9609 | Val PR-AUC: 0.5935\n",
      "  Epoch 03 | Loss: 0.8414 | Val ROC-AUC: 0.9621 | Val PR-AUC: 0.5980\n",
      "  Epoch 04 | Loss: 0.7736 | Val ROC-AUC: 0.9640 | Val PR-AUC: 0.6324\n",
      "  Epoch 05 | Loss: 0.6909 | Val ROC-AUC: 0.9656 | Val PR-AUC: 0.6281\n",
      "  Epoch 06 | Loss: 0.6629 | Val ROC-AUC: 0.9685 | Val PR-AUC: 0.6562\n",
      "  Epoch 07 | Loss: 0.6258 | Val ROC-AUC: 0.9701 | Val PR-AUC: 0.6601\n",
      "  Epoch 08 | Loss: 0.5557 | Val ROC-AUC: 0.9695 | Val PR-AUC: 0.6680\n",
      "  Epoch 09 | Loss: 0.5389 | Val ROC-AUC: 0.9705 | Val PR-AUC: 0.6674\n",
      "  Epoch 10 | Loss: 0.4987 | Val ROC-AUC: 0.9716 | Val PR-AUC: 0.6708\n",
      "  Epoch 11 | Loss: 0.5011 | Val ROC-AUC: 0.9737 | Val PR-AUC: 0.6747\n",
      "  Epoch 12 | Loss: 0.4578 | Val ROC-AUC: 0.9746 | Val PR-AUC: 0.6856\n",
      "  Epoch 13 | Loss: 0.4698 | Val ROC-AUC: 0.9765 | Val PR-AUC: 0.6868\n",
      "  Epoch 14 | Loss: 0.4394 | Val ROC-AUC: 0.9768 | Val PR-AUC: 0.6816\n",
      "  Epoch 15 | Loss: 0.4028 | Val ROC-AUC: 0.9768 | Val PR-AUC: 0.6646\n",
      "  Epoch 16 | Loss: 0.4007 | Val ROC-AUC: 0.9778 | Val PR-AUC: 0.6911\n",
      "  Epoch 17 | Loss: 0.3953 | Val ROC-AUC: 0.9787 | Val PR-AUC: 0.6955\n",
      "  Epoch 18 | Loss: 0.3735 | Val ROC-AUC: 0.9792 | Val PR-AUC: 0.6980\n",
      "  Epoch 19 | Loss: 0.3714 | Val ROC-AUC: 0.9791 | Val PR-AUC: 0.6939\n",
      "  Epoch 20 | Loss: 0.3693 | Val ROC-AUC: 0.9794 | Val PR-AUC: 0.6960\n",
      "  Epoch 21 | Loss: 0.3548 | Val ROC-AUC: 0.9788 | Val PR-AUC: 0.6971\n",
      "  Epoch 22 | Loss: 0.3367 | Val ROC-AUC: 0.9789 | Val PR-AUC: 0.6958\n",
      "  Epoch 23 | Loss: 0.3315 | Val ROC-AUC: 0.9776 | Val PR-AUC: 0.7054\n",
      "  Epoch 24 | Loss: 0.3314 | Val ROC-AUC: 0.9790 | Val PR-AUC: 0.7001\n",
      "  Epoch 25 | Loss: 0.3194 | Val ROC-AUC: 0.9791 | Val PR-AUC: 0.6982\n",
      "  Epoch 26 | Loss: 0.3518 | Val ROC-AUC: 0.9790 | Val PR-AUC: 0.6945\n",
      "  Epoch 27 | Loss: 0.3338 | Val ROC-AUC: 0.9795 | Val PR-AUC: 0.7041\n",
      "Early stopping at epoch 28\n",
      "--> Best val PR-AUC for this trial: 0.7054\n",
      "\n",
      "=== Trial 26/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000174\n",
      "  dropout     = 0.170\n",
      "  batch_size  = 1024\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 0.9655 | Val ROC-AUC: 0.9692 | Val PR-AUC: 0.7010\n",
      "  Epoch 02 | Loss: 0.6668 | Val ROC-AUC: 0.9755 | Val PR-AUC: 0.7067\n",
      "  Epoch 03 | Loss: 0.5996 | Val ROC-AUC: 0.9759 | Val PR-AUC: 0.7088\n",
      "  Epoch 04 | Loss: 0.5719 | Val ROC-AUC: 0.9801 | Val PR-AUC: 0.6662\n",
      "  Epoch 05 | Loss: 0.5480 | Val ROC-AUC: 0.9808 | Val PR-AUC: 0.7019\n",
      "  Epoch 06 | Loss: 0.4980 | Val ROC-AUC: 0.9796 | Val PR-AUC: 0.6981\n",
      "  Epoch 07 | Loss: 0.4685 | Val ROC-AUC: 0.9761 | Val PR-AUC: 0.6910\n",
      "Early stopping at epoch 8\n",
      "--> Best val PR-AUC for this trial: 0.7088\n",
      "\n",
      "=== Trial 27/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000647\n",
      "  dropout     = 0.382\n",
      "  batch_size  = 512\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 0.9274 | Val ROC-AUC: 0.9815 | Val PR-AUC: 0.6652\n",
      "  Epoch 02 | Loss: 0.6601 | Val ROC-AUC: 0.9746 | Val PR-AUC: 0.6656\n",
      "  Epoch 03 | Loss: 0.5280 | Val ROC-AUC: 0.9793 | Val PR-AUC: 0.6876\n",
      "  Epoch 04 | Loss: 0.4548 | Val ROC-AUC: 0.9792 | Val PR-AUC: 0.6915\n",
      "  Epoch 05 | Loss: 0.4172 | Val ROC-AUC: 0.9787 | Val PR-AUC: 0.6873\n",
      "  Epoch 06 | Loss: 0.3514 | Val ROC-AUC: 0.9781 | Val PR-AUC: 0.6855\n",
      "  Epoch 07 | Loss: 0.3443 | Val ROC-AUC: 0.9775 | Val PR-AUC: 0.6911\n",
      "  Epoch 08 | Loss: 0.3268 | Val ROC-AUC: 0.9787 | Val PR-AUC: 0.6884\n",
      "  Epoch 09 | Loss: 0.2850 | Val ROC-AUC: 0.9790 | Val PR-AUC: 0.7011\n",
      "  Epoch 10 | Loss: 0.2989 | Val ROC-AUC: 0.9800 | Val PR-AUC: 0.6859\n",
      "  Epoch 11 | Loss: 0.2995 | Val ROC-AUC: 0.9781 | Val PR-AUC: 0.7067\n",
      "  Epoch 12 | Loss: 0.2724 | Val ROC-AUC: 0.9763 | Val PR-AUC: 0.6898\n",
      "  Epoch 13 | Loss: 0.2589 | Val ROC-AUC: 0.9763 | Val PR-AUC: 0.6715\n",
      "  Epoch 14 | Loss: 0.2574 | Val ROC-AUC: 0.9758 | Val PR-AUC: 0.6952\n",
      "  Epoch 15 | Loss: 0.2712 | Val ROC-AUC: 0.9782 | Val PR-AUC: 0.6820\n",
      "Early stopping at epoch 16\n",
      "--> Best val PR-AUC for this trial: 0.7067\n",
      "\n",
      "=== Trial 28/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.002750\n",
      "  dropout     = 0.404\n",
      "  batch_size  = 512\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 0.7742 | Val ROC-AUC: 0.9748 | Val PR-AUC: 0.6637\n",
      "  Epoch 02 | Loss: 0.4232 | Val ROC-AUC: 0.9853 | Val PR-AUC: 0.6869\n",
      "  Epoch 03 | Loss: 0.3831 | Val ROC-AUC: 0.9812 | Val PR-AUC: 0.6462\n",
      "  Epoch 04 | Loss: 0.4115 | Val ROC-AUC: 0.9809 | Val PR-AUC: 0.6614\n",
      "  Epoch 05 | Loss: 0.3498 | Val ROC-AUC: 0.9795 | Val PR-AUC: 0.6484\n",
      "  Epoch 06 | Loss: 0.3214 | Val ROC-AUC: 0.9804 | Val PR-AUC: 0.6653\n",
      "  Epoch 07 | Loss: 0.2968 | Val ROC-AUC: 0.9826 | Val PR-AUC: 0.6924\n",
      "  Epoch 08 | Loss: 0.2846 | Val ROC-AUC: 0.9828 | Val PR-AUC: 0.7055\n",
      "  Epoch 09 | Loss: 0.2875 | Val ROC-AUC: 0.9851 | Val PR-AUC: 0.7168\n",
      "  Epoch 10 | Loss: 0.2627 | Val ROC-AUC: 0.9791 | Val PR-AUC: 0.6920\n",
      "  Epoch 11 | Loss: 0.2697 | Val ROC-AUC: 0.9828 | Val PR-AUC: 0.6976\n",
      "  Epoch 12 | Loss: 0.2497 | Val ROC-AUC: 0.9805 | Val PR-AUC: 0.6987\n",
      "  Epoch 13 | Loss: 0.2884 | Val ROC-AUC: 0.9811 | Val PR-AUC: 0.7049\n",
      "Early stopping at epoch 14\n",
      "--> Best val PR-AUC for this trial: 0.7168\n",
      "\n",
      "=== Trial 29/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.000187\n",
      "  dropout     = 0.484\n",
      "  batch_size  = 1024\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 1.4557 | Val ROC-AUC: 0.9347 | Val PR-AUC: 0.5149\n",
      "  Epoch 02 | Loss: 1.2005 | Val ROC-AUC: 0.9584 | Val PR-AUC: 0.5667\n",
      "  Epoch 03 | Loss: 1.1056 | Val ROC-AUC: 0.9618 | Val PR-AUC: 0.5720\n",
      "  Epoch 04 | Loss: 0.9861 | Val ROC-AUC: 0.9629 | Val PR-AUC: 0.5877\n",
      "  Epoch 05 | Loss: 0.9230 | Val ROC-AUC: 0.9673 | Val PR-AUC: 0.6132\n",
      "  Epoch 06 | Loss: 0.8846 | Val ROC-AUC: 0.9678 | Val PR-AUC: 0.6294\n",
      "  Epoch 07 | Loss: 0.8292 | Val ROC-AUC: 0.9701 | Val PR-AUC: 0.6448\n",
      "  Epoch 08 | Loss: 0.8245 | Val ROC-AUC: 0.9715 | Val PR-AUC: 0.6435\n",
      "  Epoch 09 | Loss: 0.7438 | Val ROC-AUC: 0.9740 | Val PR-AUC: 0.6265\n",
      "  Epoch 10 | Loss: 0.7057 | Val ROC-AUC: 0.9753 | Val PR-AUC: 0.6233\n",
      "  Epoch 11 | Loss: 0.6955 | Val ROC-AUC: 0.9758 | Val PR-AUC: 0.6391\n",
      "Early stopping at epoch 12\n",
      "--> Best val PR-AUC for this trial: 0.6448\n",
      "\n",
      "=== Trial 30/30 ===\n",
      "Sampled hyperparameters:\n",
      "  lr          = 0.001371\n",
      "  dropout     = 0.388\n",
      "  batch_size  = 1024\n",
      "  weight_decay= 0.0\n",
      "  Epoch 01 | Loss: 1.0186 | Val ROC-AUC: 0.9797 | Val PR-AUC: 0.6454\n",
      "  Epoch 02 | Loss: 0.6537 | Val ROC-AUC: 0.9762 | Val PR-AUC: 0.6578\n",
      "  Epoch 03 | Loss: 0.5055 | Val ROC-AUC: 0.9793 | Val PR-AUC: 0.6804\n",
      "  Epoch 04 | Loss: 0.4208 | Val ROC-AUC: 0.9812 | Val PR-AUC: 0.6610\n",
      "  Epoch 05 | Loss: 0.3783 | Val ROC-AUC: 0.9799 | Val PR-AUC: 0.6897\n",
      "  Epoch 06 | Loss: 0.3306 | Val ROC-AUC: 0.9809 | Val PR-AUC: 0.6975\n",
      "  Epoch 07 | Loss: 0.3299 | Val ROC-AUC: 0.9777 | Val PR-AUC: 0.6821\n",
      "  Epoch 08 | Loss: 0.3153 | Val ROC-AUC: 0.9830 | Val PR-AUC: 0.6822\n",
      "  Epoch 09 | Loss: 0.2861 | Val ROC-AUC: 0.9855 | Val PR-AUC: 0.7170\n",
      "  Epoch 10 | Loss: 0.2900 | Val ROC-AUC: 0.9880 | Val PR-AUC: 0.7030\n",
      "  Epoch 11 | Loss: 0.2602 | Val ROC-AUC: 0.9843 | Val PR-AUC: 0.7006\n",
      "  Epoch 12 | Loss: 0.2530 | Val ROC-AUC: 0.9870 | Val PR-AUC: 0.7003\n",
      "  Epoch 13 | Loss: 0.2430 | Val ROC-AUC: 0.9893 | Val PR-AUC: 0.7050\n",
      "Early stopping at epoch 14\n",
      "--> Best val PR-AUC for this trial: 0.7170\n",
      "\n",
      "=== Best hyperparameters found (random search) ===\n",
      "{'lr': 0.001371288427107175, 'dropout': 0.3882141159791872, 'batch_size': 1024, 'weight_decay': 0.0}\n",
      "Best validation PR-AUC: 0.7170475547689619\n"
     ]
    }
   ],
   "source": [
    "#number of random configs to try\n",
    "num_trials = 30  # increase to 2030 if you have time / GPU\n",
    "\n",
    "best_hparams = None\n",
    "best_val_score = -np.inf\n",
    "best_model_state = None\n",
    "\n",
    "for trial in range(1, num_trials + 1):\n",
    "    print(f\"\\n=== Trial {trial}/{num_trials} ===\")\n",
    "\n",
    "    #sample a random hyperparameter configuration\n",
    "    hparams = sample_hparams()\n",
    "    lr           = hparams[\"lr\"]\n",
    "    dropout      = hparams[\"dropout\"]\n",
    "    batch_size   = hparams[\"batch_size\"]\n",
    "    weight_decay = hparams[\"weight_decay\"]\n",
    "\n",
    "    print(f\"Sampled hyperparameters:\")\n",
    "    print(f\"  lr          = {lr:.6f}\")\n",
    "    print(f\"  dropout     = {dropout:.3f}\")\n",
    "    print(f\"  batch_size  = {batch_size}\")\n",
    "    print(f\"  weight_decay= {weight_decay}\")\n",
    "\n",
    "    #train and evaluate this config on the validation set\n",
    "    val_pr_auc, state_dict = train_eval_one_config(\n",
    "        lr=lr,\n",
    "        dropout=dropout,\n",
    "        batch_size=batch_size,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    print(f\"Best val PR-AUC for this trial: {val_pr_auc:.4f}\")\n",
    "\n",
    "    #keep track of overall best config\n",
    "    if val_pr_auc > best_val_score:\n",
    "        best_val_score = val_pr_auc\n",
    "        best_hparams = hparams\n",
    "        best_model_state = state_dict\n",
    "\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(best_hparams)\n",
    "print(\"Best validation PR-AUC:\", best_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf67f289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test set performance with best hyperparameters ===\n",
      "Test ROC-AUC: 0.9800\n",
      "Test PR-AUC : 0.8081\n"
     ]
    }
   ],
   "source": [
    "#rebuild the best model and load its weights\n",
    "best_model = FraudNet(input_dim, dropout=best_hparams[\"dropout\"]).to(device)\n",
    "best_model.load_state_dict(best_model_state)\n",
    "best_model.eval()\n",
    "\n",
    "#use the best batch_size for the test loader\n",
    "test_loader  = DataLoader(test_dataset, batch_size=best_hparams[\"batch_size\"], shuffle=False)\n",
    "\n",
    "all_logits = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        logits = best_model(X_batch)\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_targets.append(y_batch)\n",
    "\n",
    "all_logits = torch.cat(all_logits)\n",
    "all_targets = torch.cat(all_targets)\n",
    "\n",
    "#converts logits to p\n",
    "probs = torch.sigmoid(all_logits).numpy()\n",
    "targets = all_targets.numpy()\n",
    "\n",
    "#calculate roc auc score on the test set\n",
    "#roc = roc_auc_score(targets, probs)\n",
    "#auc pr score on the test set\n",
    "pr_auc = average_precision_score(targets, probs) \n",
    "\n",
    "print(f\"Test PR-AUC with best hyperparameters: {pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c0930695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[54659  2205]\n",
      " [    7    91]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9999    0.9612    0.9802     56864\n",
      "         1.0     0.0396    0.9286    0.0760        98\n",
      "\n",
      "    accuracy                         0.9612     56962\n",
      "   macro avg     0.5198    0.9449    0.5281     56962\n",
      "weighted avg     0.9982    0.9612    0.9786     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#threshold for confusion matrix\n",
    "threshold = 0.5\n",
    "#make predictions\n",
    "preds = (probs >= threshold).astype(int)\n",
    "\n",
    "#print confusion matrix\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(targets, preds))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(targets, preds, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
